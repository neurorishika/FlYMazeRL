
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GRNNLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_reward_set.csv
Model: GRNN_1x2_RNN_acceptreject_symmetric_qp_no-punishment_2022_10_04_02_23_57_505457
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6942	Validation Loss: 0.6903
Epoch 500: 	Training Loss: 0.6263	Validation Loss: 0.6199
Epoch 1000: 	Training Loss: 0.6255	Validation Loss: 0.6192
Epoch 1500: 	Training Loss: 0.6256	Validation Loss: 0.6230
Epoch 2000: 	Training Loss: 0.6331	Validation Loss: 0.6236
Epoch 2500: 	Training Loss: 0.6253	Validation Loss: 0.6194
Epoch 3000: 	Training Loss: 0.6267	Validation Loss: 0.6193
Epoch 3500: 	Training Loss: 0.6251	Validation Loss: 0.6186
Epoch 4000: 	Training Loss: 0.6244	Validation Loss: 0.6178
Epoch 4500: 	Training Loss: 0.6241	Validation Loss: 0.6177
Epoch 5000: 	Training Loss: 0.6314	Validation Loss: 0.6243
Epoch 5500: 	Training Loss: 0.6236	Validation Loss: 0.6186
Epoch 6000: 	Training Loss: 0.6268	Validation Loss: 0.6204
Early stopping at epoch 6304
Best validation loss: 0.6175
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6886	Validation Loss: 0.6864
Epoch 500: 	Training Loss: 0.6292	Validation Loss: 0.6176
Epoch 1000: 	Training Loss: 0.6266	Validation Loss: 0.6197
Epoch 1500: 	Training Loss: 0.6317	Validation Loss: 0.6222
Epoch 2000: 	Training Loss: 0.6295	Validation Loss: 0.6183
Epoch 2500: 	Training Loss: 0.6319	Validation Loss: 0.6182
Early stopping at epoch 2997
Best validation loss: 0.6157
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.7001	Validation Loss: 0.6982
Epoch 500: 	Training Loss: 0.6261	Validation Loss: 0.6224
Epoch 1000: 	Training Loss: 0.6251	Validation Loss: 0.6229
Epoch 1500: 	Training Loss: 0.6305	Validation Loss: 0.6303
Epoch 2000: 	Training Loss: 0.6296	Validation Loss: 0.6305
Epoch 2500: 	Training Loss: 0.6296	Validation Loss: 0.6302
Epoch 3000: 	Training Loss: 0.6289	Validation Loss: 0.6297
Epoch 3500: 	Training Loss: 0.6273	Validation Loss: 0.6301
Epoch 4000: 	Training Loss: 0.6290	Validation Loss: 0.6305
Epoch 4500: 	Training Loss: 0.6263	Validation Loss: 0.6257
Epoch 5000: 	Training Loss: 0.6638	Validation Loss: 0.6620
Epoch 5500: 	Training Loss: 0.6269	Validation Loss: 0.6283
Epoch 6000: 	Training Loss: 0.6272	Validation Loss: 0.6284
Early stopping at epoch 6459
Best validation loss: 0.6199
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6833	Validation Loss: 0.6762
Epoch 500: 	Training Loss: 0.6544	Validation Loss: 0.6242
Epoch 1000: 	Training Loss: 0.6374	Validation Loss: 0.6059
Epoch 1500: 	Training Loss: 0.6414	Validation Loss: 0.6091
Epoch 2000: 	Training Loss: 0.6391	Validation Loss: 0.6034
Epoch 2500: 	Training Loss: 0.6313	Validation Loss: 0.5999
Early stopping at epoch 2890
Best validation loss: 0.5940
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6888	Validation Loss: 0.6886
Epoch 500: 	Training Loss: 0.6164	Validation Loss: 0.6486
Epoch 1000: 	Training Loss: 0.6635	Validation Loss: 0.6530
Epoch 1500: 	Training Loss: 0.6279	Validation Loss: 0.6529
Epoch 2000: 	Training Loss: 0.6152	Validation Loss: 0.6522
Epoch 2500: 	Training Loss: 0.6153	Validation Loss: 0.6522
Early stopping at epoch 2697
Best validation loss: 0.6422
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/GRNN_1x2_RNN_acceptreject_symmetric_qp_no-punishment_2022_10_04_02_23_57_505457/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u18>
Subject: Job 126235133: <GRNNx2-3-1> in cluster <Janelia> Done

Job <GRNNx2-3-1> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Tue Oct  4 02:23:20 2022
Job was executed on host(s) <e10u18>, in queue <local>, as user <mohantas> in cluster <Janelia> at Tue Oct  4 02:23:38 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Tue Oct  4 02:23:38 2022
Terminated at Tue Oct  4 03:57:43 2022
Results reported at Tue Oct  4 03:57:43 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_rajagopalan.py --agent GRNN --num_reservoir 1 --reservoir_size 2 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric yes --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   11192.79 sec.
    Max Memory :                                 263 MB
    Average Memory :                             241.83 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15097.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   5662 sec.
    Turnaround time :                            5663 sec.

The output (if any) is above this job summary.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GRNNLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_reward_set.csv
Model: GRNN_1x2_RNN_acceptreject_symmetric_qp_no-punishment_2022_10_08_20_12_09_106931
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6895	Validation Loss: 0.6804
Epoch 500: 	Training Loss: 0.6037	Validation Loss: 0.5848
Epoch 1000: 	Training Loss: 0.6138	Validation Loss: 0.5927
Epoch 1500: 	Training Loss: 0.6048	Validation Loss: 0.5843
Epoch 2000: 	Training Loss: 0.6041	Validation Loss: 0.5850
Epoch 2500: 	Training Loss: 0.6033	Validation Loss: 0.5847
Early stopping at epoch 2586
Best validation loss: 0.5828
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6780	Validation Loss: 0.6694
Epoch 500: 	Training Loss: 0.5948	Validation Loss: 0.6233
Epoch 1000: 	Training Loss: 0.5938	Validation Loss: 0.6224
Epoch 1500: 	Training Loss: 0.5935	Validation Loss: 0.6220
Epoch 2000: 	Training Loss: 0.5954	Validation Loss: 0.6209
Epoch 2500: 	Training Loss: 0.5938	Validation Loss: 0.6207
Early stopping at epoch 2993
Best validation loss: 0.6189
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6932	Validation Loss: 0.6910
Epoch 500: 	Training Loss: 0.5911	Validation Loss: 0.6353
Epoch 1000: 	Training Loss: 0.5909	Validation Loss: 0.6358
Epoch 1500: 	Training Loss: 0.5908	Validation Loss: 0.6351
Epoch 2000: 	Training Loss: 0.5910	Validation Loss: 0.6347
Epoch 2500: 	Training Loss: 0.5908	Validation Loss: 0.6346
Early stopping at epoch 2734
Best validation loss: 0.6335
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6928	Validation Loss: 0.6863
Epoch 500: 	Training Loss: 0.5931	Validation Loss: 0.6227
Epoch 1000: 	Training Loss: 0.5929	Validation Loss: 0.6229
Epoch 1500: 	Training Loss: 0.5932	Validation Loss: 0.6216
Epoch 2000: 	Training Loss: 0.5945	Validation Loss: 0.6259
Epoch 2500: 	Training Loss: 0.5935	Validation Loss: 0.6210
Epoch 3000: 	Training Loss: 0.5934	Validation Loss: 0.6206
Early stopping at epoch 3159
Best validation loss: 0.6198
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6735	Validation Loss: 0.6729
Epoch 500: 	Training Loss: 0.5942	Validation Loss: 0.6310
Epoch 1000: 	Training Loss: 0.5915	Validation Loss: 0.6279
Epoch 1500: 	Training Loss: 0.5916	Validation Loss: 0.6266
Epoch 2000: 	Training Loss: 0.5915	Validation Loss: 0.6269
Epoch 2500: 	Training Loss: 0.5913	Validation Loss: 0.6268
Early stopping at epoch 2665
Best validation loss: 0.6250
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/GRNN_1x2_RNN_acceptreject_symmetric_qp_no-punishment_2022_10_08_20_12_09_106931/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u09>
Subject: Job 126381297: <GRNNx2-3-1> in cluster <Janelia> Done

Job <GRNNx2-3-1> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Sat Oct  8 20:11:30 2022
Job was executed on host(s) <e10u09>, in queue <local>, as user <mohantas> in cluster <Janelia> at Sat Oct  8 20:11:30 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Sat Oct  8 20:11:30 2022
Terminated at Sun Oct  9 05:32:17 2022
Results reported at Sun Oct  9 05:32:17 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_mohanta.py --agent GRNN --num_reservoir 1 --reservoir_size 2 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric yes --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   764845.62 sec.
    Max Memory :                                 301 MB
    Average Memory :                             251.78 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15059.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                60
    Run time :                                   33648 sec.
    Turnaround time :                            33647 sec.

The output (if any) is above this job summary.

