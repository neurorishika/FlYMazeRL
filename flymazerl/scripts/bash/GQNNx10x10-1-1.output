
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_reward_set.csv
Model: GQNN_10-10_relu_acceptreject_symmetric_qp_no-punishment_2022_10_04_02_25_23_590102
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.7084	Validation Loss: 0.6916
Epoch 500: 	Training Loss: 0.6164	Validation Loss: 0.6672
Epoch 1000: 	Training Loss: 0.6227	Validation Loss: 0.6799
Epoch 1500: 	Training Loss: 0.6174	Validation Loss: 0.6748
Epoch 2000: 	Training Loss: 0.6171	Validation Loss: 0.6792
Epoch 2500: 	Training Loss: 0.6169	Validation Loss: 0.6706
Early stopping at epoch 2569
Best validation loss: 0.6638
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6398	Validation Loss: 0.6129
Epoch 500: 	Training Loss: 0.6391	Validation Loss: 0.6135
Epoch 1000: 	Training Loss: 0.6323	Validation Loss: 0.6114
Epoch 1500: 	Training Loss: 0.6302	Validation Loss: 0.6131
Epoch 2000: 	Training Loss: 0.6299	Validation Loss: 0.6101
Epoch 2500: 	Training Loss: 0.6289	Validation Loss: 0.6117
Epoch 3000: 	Training Loss: 0.6931	Validation Loss: 0.6930
Epoch 3500: 	Training Loss: 0.6930	Validation Loss: 0.6932
Epoch 4000: 	Training Loss: 0.6924	Validation Loss: 0.6944
Epoch 4500: 	Training Loss: 0.6924	Validation Loss: 0.6945
Early stopping at epoch 4505
Best validation loss: 0.6057
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6267	Validation Loss: 0.6291
Epoch 500: 	Training Loss: 0.6259	Validation Loss: 0.6317
Epoch 1000: 	Training Loss: 0.6255	Validation Loss: 0.6304
Epoch 1500: 	Training Loss: 0.6261	Validation Loss: 0.6345
Epoch 2000: 	Training Loss: 0.6246	Validation Loss: 0.6282
Epoch 2500: 	Training Loss: 0.6292	Validation Loss: 0.6399
Early stopping at epoch 2529
Best validation loss: 0.6262
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6257	Validation Loss: 0.6313
Epoch 500: 	Training Loss: 0.6224	Validation Loss: 0.6373
Epoch 1000: 	Training Loss: 0.6268	Validation Loss: 0.6470
Epoch 1500: 	Training Loss: 0.6305	Validation Loss: 0.6370
Epoch 2000: 	Training Loss: 0.6258	Validation Loss: 0.6335
Epoch 2500: 	Training Loss: 0.6270	Validation Loss: 0.6338
Epoch 3000: 	Training Loss: 0.6237	Validation Loss: 0.6386
Early stopping at epoch 3116
Best validation loss: 0.6299
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6184	Validation Loss: 0.6715
Epoch 500: 	Training Loss: 0.6137	Validation Loss: 0.6675
Epoch 1000: 	Training Loss: 0.6158	Validation Loss: 0.6718
Epoch 1500: 	Training Loss: 0.6153	Validation Loss: 0.6718
Epoch 2000: 	Training Loss: 0.6143	Validation Loss: 0.6692
Epoch 2500: 	Training Loss: 0.6188	Validation Loss: 0.6743
Early stopping at epoch 2546
Best validation loss: 0.6629
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/GQNN_10-10_relu_acceptreject_symmetric_qp_no-punishment_2022_10_04_02_25_23_590102/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u27>
Subject: Job 126235741: <GQNNx10x10-1-1> in cluster <Janelia> Done

Job <GQNNx10x10-1-1> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Tue Oct  4 02:24:59 2022
Job was executed on host(s) <e10u27>, in queue <local>, as user <mohantas> in cluster <Janelia> at Tue Oct  4 02:24:59 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Tue Oct  4 02:24:59 2022
Terminated at Tue Oct  4 08:42:42 2022
Results reported at Tue Oct  4 08:42:42 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_rajagopalan.py --agent GQNN --hidden_state_sizes 10 10 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric yes --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   45104.11 sec.
    Max Memory :                                 258 MB
    Average Memory :                             242.56 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15102.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   22665 sec.
    Turnaround time :                            22663 sec.

The output (if any) is above this job summary.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_reward_set.csv
Model: GQNN_10-10_relu_acceptreject_symmetric_qp_no-punishment_2022_10_08_20_15_19_609470
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6774	Validation Loss: 0.6455
Epoch 500: 	Training Loss: 0.6025	Validation Loss: 0.5910
Epoch 1000: 	Training Loss: 0.6015	Validation Loss: 0.5910
Epoch 1500: 	Training Loss: 0.6044	Validation Loss: 0.5917
Epoch 2000: 	Training Loss: 0.6026	Validation Loss: 0.5918
Epoch 2500: 	Training Loss: 0.6016	Validation Loss: 0.5923
Early stopping at epoch 2943
Best validation loss: 0.5897
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6053	Validation Loss: 0.5847
Epoch 500: 	Training Loss: 0.6048	Validation Loss: 0.5862
Epoch 1000: 	Training Loss: 0.6047	Validation Loss: 0.5857
Epoch 1500: 	Training Loss: 0.6045	Validation Loss: 0.5856
Epoch 2000: 	Training Loss: 0.6044	Validation Loss: 0.5869
Epoch 2500: 	Training Loss: 0.6025	Validation Loss: 0.5858
Epoch 3000: 	Training Loss: 0.6028	Validation Loss: 0.5838
Epoch 3500: 	Training Loss: 0.6027	Validation Loss: 0.5850
Early stopping at epoch 3812
Best validation loss: 0.5831
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5953	Validation Loss: 0.6242
Epoch 500: 	Training Loss: 0.5944	Validation Loss: 0.6246
Epoch 1000: 	Training Loss: 0.6046	Validation Loss: 0.6194
Epoch 1500: 	Training Loss: 0.5940	Validation Loss: 0.6188
Epoch 2000: 	Training Loss: 0.5944	Validation Loss: 0.6213
Epoch 2500: 	Training Loss: 0.5941	Validation Loss: 0.6215
Epoch 3000: 	Training Loss: 0.5949	Validation Loss: 0.6195
Epoch 3500: 	Training Loss: 0.6300	Validation Loss: 0.6629
Epoch 4000: 	Training Loss: 0.5938	Validation Loss: 0.6193
Early stopping at epoch 4185
Best validation loss: 0.6175
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5971	Validation Loss: 0.6100
Epoch 500: 	Training Loss: 0.5961	Validation Loss: 0.6112
Epoch 1000: 	Training Loss: 0.5972	Validation Loss: 0.6154
Epoch 1500: 	Training Loss: 0.5959	Validation Loss: 0.6098
Epoch 2000: 	Training Loss: 0.5963	Validation Loss: 0.6109
Epoch 2500: 	Training Loss: 0.5973	Validation Loss: 0.6091
Epoch 3000: 	Training Loss: 0.6213	Validation Loss: 0.6146
Epoch 3500: 	Training Loss: 0.5970	Validation Loss: 0.6104
Early stopping at epoch 3966
Best validation loss: 0.6074
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6063	Validation Loss: 0.5725
Epoch 500: 	Training Loss: 0.6061	Validation Loss: 0.5743
Epoch 1000: 	Training Loss: 0.6062	Validation Loss: 0.5738
Epoch 1500: 	Training Loss: 0.6072	Validation Loss: 0.5743
Epoch 2000: 	Training Loss: 0.6055	Validation Loss: 0.5752
Epoch 2500: 	Training Loss: 0.6056	Validation Loss: 0.5742
Epoch 3000: 	Training Loss: 0.6056	Validation Loss: 0.5741
Early stopping at epoch 3179
Best validation loss: 0.5713
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/GQNN_10-10_relu_acceptreject_symmetric_qp_no-punishment_2022_10_08_20_15_19_609470/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u18>
Subject: Job 126381363: <GQNNx10x10-1-1> in cluster <Janelia> Done

Job <GQNNx10x10-1-1> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Sat Oct  8 20:15:00 2022
Job was executed on host(s) <e10u18>, in queue <local>, as user <mohantas> in cluster <Janelia> at Sat Oct  8 20:15:00 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Sat Oct  8 20:15:00 2022
Terminated at Mon Oct 10 05:17:25 2022
Results reported at Mon Oct 10 05:17:25 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_mohanta.py --agent GQNN --hidden_state_sizes 10 10 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric yes --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   236163.42 sec.
    Max Memory :                                 333 MB
    Average Memory :                             264.26 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15027.00 MB
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                14
    Run time :                                   118946 sec.
    Turnaround time :                            118945 sec.

The output (if any) is above this job summary.

