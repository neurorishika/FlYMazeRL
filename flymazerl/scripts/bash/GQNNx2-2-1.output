
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_reward_set.csv
Model: GQNN_2_relu_acceptreject_symmetric_qp_no-punishment_2022_10_04_02_24_58_112950
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.7043	Validation Loss: 0.7000
Epoch 500: 	Training Loss: 0.6266	Validation Loss: 0.6397
Epoch 1000: 	Training Loss: 0.6265	Validation Loss: 0.6404
Epoch 1500: 	Training Loss: 0.6271	Validation Loss: 0.6403
Epoch 2000: 	Training Loss: 0.6263	Validation Loss: 0.6404
Epoch 2500: 	Training Loss: 0.6265	Validation Loss: 0.6404
Early stopping at epoch 2819
Best validation loss: 0.6382
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6290	Validation Loss: 0.6326
Epoch 500: 	Training Loss: 0.6280	Validation Loss: 0.6360
Epoch 1000: 	Training Loss: 0.6280	Validation Loss: 0.6357
Epoch 1500: 	Training Loss: 0.6285	Validation Loss: 0.6343
Epoch 2000: 	Training Loss: 0.6281	Validation Loss: 0.6355
Epoch 2500: 	Training Loss: 0.6281	Validation Loss: 0.6347
Early stopping at epoch 2500
Best validation loss: 0.6326
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6316	Validation Loss: 0.6267
Epoch 500: 	Training Loss: 0.6296	Validation Loss: 0.6295
Epoch 1000: 	Training Loss: 0.6301	Validation Loss: 0.6297
Epoch 1500: 	Training Loss: 0.6300	Validation Loss: 0.6287
Epoch 2000: 	Training Loss: 0.6295	Validation Loss: 0.6287
Epoch 2500: 	Training Loss: 0.6296	Validation Loss: 0.6288
Early stopping at epoch 2500
Best validation loss: 0.6267
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6230	Validation Loss: 0.6570
Epoch 500: 	Training Loss: 0.6218	Validation Loss: 0.6576
Epoch 1000: 	Training Loss: 0.6217	Validation Loss: 0.6591
Epoch 1500: 	Training Loss: 0.6224	Validation Loss: 0.6574
Epoch 2000: 	Training Loss: 0.6214	Validation Loss: 0.6581
Epoch 2500: 	Training Loss: 0.6214	Validation Loss: 0.6583
Early stopping at epoch 2501
Best validation loss: 0.6546
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6290	Validation Loss: 0.6324
Epoch 500: 	Training Loss: 0.6282	Validation Loss: 0.6341
Epoch 1000: 	Training Loss: 0.6284	Validation Loss: 0.6331
Epoch 1500: 	Training Loss: 0.6287	Validation Loss: 0.6338
Epoch 2000: 	Training Loss: 0.6288	Validation Loss: 0.6334
Epoch 2500: 	Training Loss: 0.6284	Validation Loss: 0.6335
Early stopping at epoch 2500
Best validation loss: 0.6324
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/GQNN_2_relu_acceptreject_symmetric_qp_no-punishment_2022_10_04_02_24_58_112950/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u04>
Subject: Job 126235663: <GQNNx2-2-1> in cluster <Janelia> Done

Job <GQNNx2-2-1> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Tue Oct  4 02:24:48 2022
Job was executed on host(s) <e10u04>, in queue <local>, as user <mohantas> in cluster <Janelia> at Tue Oct  4 02:24:49 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Tue Oct  4 02:24:49 2022
Terminated at Tue Oct  4 06:29:49 2022
Results reported at Tue Oct  4 06:29:49 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_rajagopalan.py --agent GQNN --hidden_state_sizes 2 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric yes --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   29272.80 sec.
    Max Memory :                                 256 MB
    Average Memory :                             242.48 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15104.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   14699 sec.
    Turnaround time :                            14701 sec.

The output (if any) is above this job summary.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_reward_set.csv
Model: GQNN_2_relu_acceptreject_symmetric_qp_no-punishment_2022_10_08_20_14_53_766047
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6990	Validation Loss: 0.6931
Epoch 500: 	Training Loss: 0.6159	Validation Loss: 0.5917
Epoch 1000: 	Training Loss: 0.6060	Validation Loss: 0.5791
Epoch 1500: 	Training Loss: 0.6058	Validation Loss: 0.5794
Epoch 2000: 	Training Loss: 0.6054	Validation Loss: 0.5802
Epoch 2500: 	Training Loss: 0.6053	Validation Loss: 0.5799
Epoch 3000: 	Training Loss: 0.6050	Validation Loss: 0.5802
Early stopping at epoch 3447
Best validation loss: 0.5781
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5930	Validation Loss: 0.6310
Epoch 500: 	Training Loss: 0.5928	Validation Loss: 0.6319
Epoch 1000: 	Training Loss: 0.5921	Validation Loss: 0.6359
Epoch 1500: 	Training Loss: 0.5921	Validation Loss: 0.6308
Epoch 2000: 	Training Loss: 0.5932	Validation Loss: 0.6315
Epoch 2500: 	Training Loss: 0.5918	Validation Loss: 0.6325
Early stopping at epoch 2533
Best validation loss: 0.6305
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5931	Validation Loss: 0.6294
Epoch 500: 	Training Loss: 0.5927	Validation Loss: 0.6295
Epoch 1000: 	Training Loss: 0.5927	Validation Loss: 0.6296
Epoch 1500: 	Training Loss: 0.5928	Validation Loss: 0.6296
Epoch 2000: 	Training Loss: 0.5925	Validation Loss: 0.6298
Epoch 2500: 	Training Loss: 0.5924	Validation Loss: 0.6304
Early stopping at epoch 2502
Best validation loss: 0.6293
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5990	Validation Loss: 0.6053
Epoch 500: 	Training Loss: 0.5988	Validation Loss: 0.6057
Epoch 1000: 	Training Loss: 0.5987	Validation Loss: 0.6056
Epoch 1500: 	Training Loss: 0.5989	Validation Loss: 0.6062
Epoch 2000: 	Training Loss: 0.5986	Validation Loss: 0.6064
Epoch 2500: 	Training Loss: 0.5987	Validation Loss: 0.6050
Epoch 3000: 	Training Loss: 0.5987	Validation Loss: 0.6063
Epoch 3500: 	Training Loss: 0.5989	Validation Loss: 0.6060
Early stopping at epoch 3947
Best validation loss: 0.6044
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6026	Validation Loss: 0.5926
Epoch 500: 	Training Loss: 0.6026	Validation Loss: 0.5922
Epoch 1000: 	Training Loss: 0.6021	Validation Loss: 0.5921
Epoch 1500: 	Training Loss: 0.6020	Validation Loss: 0.5923
Epoch 2000: 	Training Loss: 0.6020	Validation Loss: 0.5924
Epoch 2500: 	Training Loss: 0.6021	Validation Loss: 0.5926
Early stopping at epoch 2706
Best validation loss: 0.5917
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/GQNN_2_relu_acceptreject_symmetric_qp_no-punishment_2022_10_08_20_14_53_766047/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u13>
Subject: Job 126381344: <GQNNx2-2-1> in cluster <Janelia> Done

Job <GQNNx2-2-1> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Sat Oct  8 20:14:49 2022
Job was executed on host(s) <e10u13>, in queue <local>, as user <mohantas> in cluster <Janelia> at Sat Oct  8 20:14:49 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Sat Oct  8 20:14:49 2022
Terminated at Sun Oct  9 16:05:30 2022
Results reported at Sun Oct  9 16:05:30 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_mohanta.py --agent GQNN --hidden_state_sizes 2 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric yes --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   141754.45 sec.
    Max Memory :                                 319 MB
    Average Memory :                             256.89 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15041.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   71440 sec.
    Turnaround time :                            71441 sec.

The output (if any) is above this job summary.

