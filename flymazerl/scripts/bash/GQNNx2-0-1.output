
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_reward_set.csv
Model: GQNN_2_relu_acceptreject_symmetric_qp_no-punishment_2022_10_04_02_24_51_308125
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.7063	Validation Loss: 0.7067
Epoch 500: 	Training Loss: 0.6421	Validation Loss: 0.5851
Epoch 1000: 	Training Loss: 0.6421	Validation Loss: 0.5853
Epoch 1500: 	Training Loss: 0.6420	Validation Loss: 0.5860
Epoch 2000: 	Training Loss: 0.6420	Validation Loss: 0.5863
Epoch 2500: 	Training Loss: 0.6422	Validation Loss: 0.5925
Early stopping at epoch 2781
Best validation loss: 0.5828
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6241	Validation Loss: 0.6562
Epoch 500: 	Training Loss: 0.6221	Validation Loss: 0.6562
Epoch 1000: 	Training Loss: 0.6219	Validation Loss: 0.6568
Epoch 1500: 	Training Loss: 0.6218	Validation Loss: 0.6565
Epoch 2000: 	Training Loss: 0.6218	Validation Loss: 0.6571
Epoch 2500: 	Training Loss: 0.6220	Validation Loss: 0.6559
Early stopping at epoch 2510
Best validation loss: 0.6554
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6232	Validation Loss: 0.6539
Epoch 500: 	Training Loss: 0.6224	Validation Loss: 0.6549
Epoch 1000: 	Training Loss: 0.6224	Validation Loss: 0.6549
Epoch 1500: 	Training Loss: 0.6228	Validation Loss: 0.6545
Epoch 2000: 	Training Loss: 0.6227	Validation Loss: 0.6544
Epoch 2500: 	Training Loss: 0.6230	Validation Loss: 0.6549
Early stopping at epoch 2500
Best validation loss: 0.6539
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6336	Validation Loss: 0.6255
Epoch 500: 	Training Loss: 0.6301	Validation Loss: 0.6276
Epoch 1000: 	Training Loss: 0.6301	Validation Loss: 0.6275
Epoch 1500: 	Training Loss: 0.6297	Validation Loss: 0.6270
Epoch 2000: 	Training Loss: 0.6296	Validation Loss: 0.6260
Epoch 2500: 	Training Loss: 0.6300	Validation Loss: 0.6267
Early stopping at epoch 2501
Best validation loss: 0.6229
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6299	Validation Loss: 0.6329
Epoch 500: 	Training Loss: 0.6289	Validation Loss: 0.6331
Epoch 1000: 	Training Loss: 0.6286	Validation Loss: 0.6320
Epoch 1500: 	Training Loss: 0.6287	Validation Loss: 0.6325
Epoch 2000: 	Training Loss: 0.6286	Validation Loss: 0.6325
Epoch 2500: 	Training Loss: 0.6287	Validation Loss: 0.6327
Early stopping at epoch 2502
Best validation loss: 0.6316
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/GQNN_2_relu_acceptreject_symmetric_qp_no-punishment_2022_10_04_02_24_51_308125/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u04>
Subject: Job 126235652: <GQNNx2-0-1> in cluster <Janelia> Done

Job <GQNNx2-0-1> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Tue Oct  4 02:24:47 2022
Job was executed on host(s) <e10u04>, in queue <local>, as user <mohantas> in cluster <Janelia> at Tue Oct  4 02:24:47 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Tue Oct  4 02:24:47 2022
Terminated at Tue Oct  4 06:40:47 2022
Results reported at Tue Oct  4 06:40:47 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_rajagopalan.py --agent GQNN --hidden_state_sizes 2 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric yes --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   30597.27 sec.
    Max Memory :                                 254 MB
    Average Memory :                             241.23 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15106.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   15358 sec.
    Turnaround time :                            15360 sec.

The output (if any) is above this job summary.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_reward_set.csv
Model: GQNN_2_relu_acceptreject_symmetric_qp_no-punishment_2022_10_08_20_14_55_799187
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6622	Validation Loss: 0.6546
Epoch 500: 	Training Loss: 0.6006	Validation Loss: 0.5995
Epoch 1000: 	Training Loss: 0.6003	Validation Loss: 0.5989
Epoch 1500: 	Training Loss: 0.6002	Validation Loss: 0.6011
Epoch 2000: 	Training Loss: 0.6004	Validation Loss: 0.5991
Epoch 2500: 	Training Loss: 0.6004	Validation Loss: 0.5988
Early stopping at epoch 2539
Best validation loss: 0.5982
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5959	Validation Loss: 0.6238
Epoch 500: 	Training Loss: 0.5943	Validation Loss: 0.6235
Epoch 1000: 	Training Loss: 0.5941	Validation Loss: 0.6241
Epoch 1500: 	Training Loss: 0.5939	Validation Loss: 0.6233
Epoch 2000: 	Training Loss: 0.5941	Validation Loss: 0.6233
Epoch 2500: 	Training Loss: 0.5941	Validation Loss: 0.6234
Epoch 3000: 	Training Loss: 0.5938	Validation Loss: 0.6243
Epoch 3500: 	Training Loss: 0.5942	Validation Loss: 0.6236
Early stopping at epoch 3541
Best validation loss: 0.6233
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5921	Validation Loss: 0.6307
Epoch 500: 	Training Loss: 0.5923	Validation Loss: 0.6309
Epoch 1000: 	Training Loss: 0.5922	Validation Loss: 0.6323
Epoch 1500: 	Training Loss: 0.5929	Validation Loss: 0.6307
Epoch 2000: 	Training Loss: 0.5920	Validation Loss: 0.6306
Epoch 2500: 	Training Loss: 0.5919	Validation Loss: 0.6321
Early stopping at epoch 2505
Best validation loss: 0.6306
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6013	Validation Loss: 0.5969
Epoch 500: 	Training Loss: 0.6008	Validation Loss: 0.5972
Epoch 1000: 	Training Loss: 0.6019	Validation Loss: 0.5965
Epoch 1500: 	Training Loss: 0.6013	Validation Loss: 0.5969
Epoch 2000: 	Training Loss: 0.6013	Validation Loss: 0.5969
Epoch 2500: 	Training Loss: 0.6010	Validation Loss: 0.5968
Early stopping at epoch 2502
Best validation loss: 0.5962
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5919	Validation Loss: 0.6322
Epoch 500: 	Training Loss: 0.5914	Validation Loss: 0.6333
Epoch 1000: 	Training Loss: 0.5918	Validation Loss: 0.6356
Epoch 1500: 	Training Loss: 0.5916	Validation Loss: 0.6353
Epoch 2000: 	Training Loss: 0.5915	Validation Loss: 0.6329
Epoch 2500: 	Training Loss: 0.5921	Validation Loss: 0.6336
Early stopping at epoch 2500
Best validation loss: 0.6322
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/GQNN_2_relu_acceptreject_symmetric_qp_no-punishment_2022_10_08_20_14_55_799187/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u03>
Subject: Job 126381342: <GQNNx2-0-1> in cluster <Janelia> Done

Job <GQNNx2-0-1> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Sat Oct  8 20:14:48 2022
Job was executed on host(s) <e10u03>, in queue <local>, as user <mohantas> in cluster <Janelia> at Sat Oct  8 20:14:50 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Sat Oct  8 20:14:50 2022
Terminated at Sun Oct  9 23:08:03 2022
Results reported at Sun Oct  9 23:08:03 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_mohanta.py --agent GQNN --hidden_state_sizes 2 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric yes --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   191873.83 sec.
    Max Memory :                                 301 MB
    Average Memory :                             249.95 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15059.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   96795 sec.
    Turnaround time :                            96795 sec.

The output (if any) is above this job summary.

