
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_reward_set.csv
Model: GQNN_100-100-100_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_04_02_25_48_828375
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6683	Validation Loss: 0.6871
Epoch 500: 	Training Loss: 0.6743	Validation Loss: 0.6812
Epoch 1000: 	Training Loss: 0.6747	Validation Loss: 0.6814
Epoch 1500: 	Training Loss: 0.8544	Validation Loss: 0.8227
Epoch 2000: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 2500: 	Training Loss: 0.6565	Validation Loss: 0.6808
Early stopping at epoch 2887
Best validation loss: 0.6528
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6478	Validation Loss: 0.6186
Epoch 500: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 1000: 	Training Loss: 0.6991	Validation Loss: 0.7137
Epoch 1500: 	Training Loss: 0.6698	Validation Loss: 0.6307
Epoch 2000: 	Training Loss: 0.6710	Validation Loss: 0.6876
Epoch 2500: 	Training Loss: 0.6714	Validation Loss: 0.6878
Early stopping at epoch 2539
Best validation loss: 0.6078
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6350	Validation Loss: 0.6390
Epoch 500: 	Training Loss: 0.6932	Validation Loss: 0.6932
Epoch 1000: 	Training Loss: 0.6453	Validation Loss: 0.6463
Epoch 1500: 	Training Loss: 0.6416	Validation Loss: 0.6449
Epoch 2000: 	Training Loss: 0.6924	Validation Loss: 0.6927
Epoch 2500: 	Training Loss: 0.6741	Validation Loss: 0.6826
Early stopping at epoch 2550
Best validation loss: 0.6281
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6298	Validation Loss: 0.6435
Epoch 500: 	Training Loss: 0.6931	Validation Loss: 0.6932
Epoch 1000: 	Training Loss: 0.6623	Validation Loss: 0.6590
Epoch 1500: 	Training Loss: 0.6656	Validation Loss: 0.6653
Epoch 2000: 	Training Loss: 0.6544	Validation Loss: 0.6557
Epoch 2500: 	Training Loss: 0.6374	Validation Loss: 0.6588
Early stopping at epoch 2543
Best validation loss: 0.6415
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6315	Validation Loss: 0.6394
Epoch 500: 	Training Loss: 0.6554	Validation Loss: 0.6604
Epoch 1000: 	Training Loss: 0.6740	Validation Loss: 0.6797
Epoch 1500: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 2000: 	Training Loss: 0.6336	Validation Loss: 0.6501
Epoch 2500: 	Training Loss: 0.6622	Validation Loss: 0.6586
Early stopping at epoch 2502
Best validation loss: 0.6314
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/GQNN_100-100-100_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_04_02_25_48_828375/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u02>
Subject: Job 126236050: <GQNNx100x100x100-3-0> in cluster <Janelia> Done

Job <GQNNx100x100x100-3-0> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Tue Oct  4 02:25:34 2022
Job was executed on host(s) <e10u02>, in queue <local>, as user <mohantas> in cluster <Janelia> at Tue Oct  4 02:25:38 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Tue Oct  4 02:25:38 2022
Terminated at Tue Oct  4 07:40:27 2022
Results reported at Tue Oct  4 07:40:27 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_rajagopalan.py --agent GQNN --hidden_state_sizes 100 100 100 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric no --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   37618.29 sec.
    Max Memory :                                 264 MB
    Average Memory :                             250.63 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15096.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   18893 sec.
    Turnaround time :                            18893 sec.

The output (if any) is above this job summary.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_reward_set.csv
Model: GQNN_100-100-100_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_08_20_15_43_740224
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6677	Validation Loss: 0.6035
Epoch 500: 	Training Loss: nan	Validation Loss: nan
Epoch 1000: 	Training Loss: nan	Validation Loss: nan
Epoch 1500: 	Training Loss: nan	Validation Loss: nan
Epoch 2000: 	Training Loss: nan	Validation Loss: nan
Epoch 2500: 	Training Loss: nan	Validation Loss: nan
Early stopping at epoch 2512
Best validation loss: 0.5494
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6066	Validation Loss: 0.6265
Epoch 500: 	Training Loss: 0.6472	Validation Loss: 0.6428
Epoch 1000: 	Training Loss: 0.5976	Validation Loss: 0.6125
Epoch 1500: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 2000: 	Training Loss: 0.6451	Validation Loss: 0.6417
Epoch 2500: 	Training Loss: 0.6497	Validation Loss: 0.6513
Epoch 3000: 	Training Loss: nan	Validation Loss: nan
Early stopping at epoch 3473
Best validation loss: 0.6122
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6100	Validation Loss: 0.5819
Epoch 500: 	Training Loss: nan	Validation Loss: nan
Epoch 1000: 	Training Loss: nan	Validation Loss: nan
Epoch 1500: 	Training Loss: nan	Validation Loss: nan
Epoch 2000: 	Training Loss: nan	Validation Loss: nan
Epoch 2500: 	Training Loss: nan	Validation Loss: nan
Early stopping at epoch 2516
Best validation loss: 0.5791
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5987	Validation Loss: 0.6259
Epoch 500: 	Training Loss: 0.6204	Validation Loss: 0.6455
Epoch 1000: 	Training Loss: nan	Validation Loss: nan
Epoch 1500: 	Training Loss: nan	Validation Loss: nan
Epoch 2000: 	Training Loss: nan	Validation Loss: nan
Epoch 2500: 	Training Loss: nan	Validation Loss: nan
Early stopping at epoch 2515
Best validation loss: 0.6201
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5995	Validation Loss: 0.6080
Epoch 500: 	Training Loss: 0.6433	Validation Loss: 0.6464
Epoch 1000: 	Training Loss: 0.6435	Validation Loss: 0.6478
Epoch 1500: 	Training Loss: 0.6226	Validation Loss: 0.6204
Epoch 2000: 	Training Loss: 0.6082	Validation Loss: 0.6113
Epoch 2500: 	Training Loss: nan	Validation Loss: nan
Epoch 3000: 	Training Loss: nan	Validation Loss: nan
Epoch 3500: 	Training Loss: nan	Validation Loss: nan
Early stopping at epoch 3857
Best validation loss: 0.6057
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/GQNN_100-100-100_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_08_20_15_43_740224/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u19>
Subject: Job 126381413: <GQNNx100x100x100-3-0> in cluster <Janelia> Done

Job <GQNNx100x100x100-3-0> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Sat Oct  8 20:15:33 2022
Job was executed on host(s) <e10u19>, in queue <local>, as user <mohantas> in cluster <Janelia> at Sat Oct  8 20:15:34 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Sat Oct  8 20:15:34 2022
Terminated at Mon Oct 10 08:07:35 2022
Results reported at Mon Oct 10 08:07:35 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_mohanta.py --agent GQNN --hidden_state_sizes 100 100 100 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric no --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   256861.17 sec.
    Max Memory :                                 359 MB
    Average Memory :                             313.14 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15001.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   129124 sec.
    Turnaround time :                            129122 sec.

The output (if any) is above this job summary.

