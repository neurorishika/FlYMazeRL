
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_reward_set.csv
Model: GQNN_5_relu_acceptreject_symmetric_qp_no-punishment_2022_10_04_02_25_14_618282
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6754	Validation Loss: 0.6742
Epoch 500: 	Training Loss: 0.6281	Validation Loss: 0.6355
Epoch 1000: 	Training Loss: 0.6265	Validation Loss: 0.6376
Epoch 1500: 	Training Loss: 0.6244	Validation Loss: 0.6388
Epoch 2000: 	Training Loss: 0.6241	Validation Loss: 0.6391
Epoch 2500: 	Training Loss: 0.6245	Validation Loss: 0.6386
Early stopping at epoch 2951
Best validation loss: 0.6342
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6323	Validation Loss: 0.6327
Epoch 500: 	Training Loss: 0.6316	Validation Loss: 0.6246
Epoch 1000: 	Training Loss: 0.6308	Validation Loss: 0.6274
Epoch 1500: 	Training Loss: 0.6303	Validation Loss: 0.6252
Epoch 2000: 	Training Loss: 0.6297	Validation Loss: 0.6277
Epoch 2500: 	Training Loss: 0.6284	Validation Loss: 0.6368
Epoch 3000: 	Training Loss: 0.6277	Validation Loss: 0.6384
Epoch 3500: 	Training Loss: 0.6278	Validation Loss: 0.6380
Epoch 4000: 	Training Loss: 0.6278	Validation Loss: 0.6375
Epoch 4500: 	Training Loss: 0.6267	Validation Loss: 0.6458
Epoch 5000: 	Training Loss: 0.6275	Validation Loss: 0.6457
Epoch 5500: 	Training Loss: 0.6277	Validation Loss: 0.6422
Early stopping at epoch 5624
Best validation loss: 0.6118
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6176	Validation Loss: 0.6780
Epoch 500: 	Training Loss: 0.6129	Validation Loss: 0.6695
Epoch 1000: 	Training Loss: 0.6134	Validation Loss: 0.6734
Epoch 1500: 	Training Loss: 0.6133	Validation Loss: 0.6693
Epoch 2000: 	Training Loss: 0.6199	Validation Loss: 0.6770
Epoch 2500: 	Training Loss: 0.6111	Validation Loss: 0.6712
Epoch 3000: 	Training Loss: 0.6127	Validation Loss: 0.6725
Epoch 3500: 	Training Loss: 0.6137	Validation Loss: 0.6755
Epoch 4000: 	Training Loss: 0.6166	Validation Loss: 0.6718
Early stopping at epoch 4332
Best validation loss: 0.6663
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6186	Validation Loss: 0.6476
Epoch 500: 	Training Loss: 0.6238	Validation Loss: 0.6599
Epoch 1000: 	Training Loss: 0.6229	Validation Loss: 0.6614
Epoch 1500: 	Training Loss: 0.6209	Validation Loss: 0.6599
Epoch 2000: 	Training Loss: 0.6514	Validation Loss: 0.6669
Epoch 2500: 	Training Loss: 0.6510	Validation Loss: 0.6677
Early stopping at epoch 2502
Best validation loss: 0.6469
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6280	Validation Loss: 0.6127
Epoch 500: 	Training Loss: 0.6293	Validation Loss: 0.6152
Epoch 1000: 	Training Loss: 0.6375	Validation Loss: 0.6324
Epoch 1500: 	Training Loss: 0.6314	Validation Loss: 0.6257
Epoch 2000: 	Training Loss: 0.6309	Validation Loss: 0.6249
Epoch 2500: 	Training Loss: 0.6311	Validation Loss: 0.6248
Early stopping at epoch 2674
Best validation loss: 0.6104
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/GQNN_5_relu_acceptreject_symmetric_qp_no-punishment_2022_10_04_02_25_14_618282/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u14>
Subject: Job 126235674: <GQNNx5-3-1> in cluster <Janelia> Done

Job <GQNNx5-3-1> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Tue Oct  4 02:24:51 2022
Job was executed on host(s) <e10u14>, in queue <local>, as user <mohantas> in cluster <Janelia> at Tue Oct  4 02:24:52 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Tue Oct  4 02:24:52 2022
Terminated at Tue Oct  4 08:23:18 2022
Results reported at Tue Oct  4 08:23:18 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_rajagopalan.py --agent GQNN --hidden_state_sizes 5 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric yes --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   42826.00 sec.
    Max Memory :                                 258 MB
    Average Memory :                             240.91 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15102.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   21509 sec.
    Turnaround time :                            21507 sec.

The output (if any) is above this job summary.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_reward_set.csv
Model: GQNN_5_relu_acceptreject_symmetric_qp_no-punishment_2022_10_08_20_15_08_479541
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6793	Validation Loss: 0.6655
Epoch 500: 	Training Loss: 0.5979	Validation Loss: 0.6045
Epoch 1000: 	Training Loss: 0.5985	Validation Loss: 0.6037
Epoch 1500: 	Training Loss: 0.5982	Validation Loss: 0.6046
Epoch 2000: 	Training Loss: 0.5979	Validation Loss: 0.6049
Epoch 2500: 	Training Loss: 0.5987	Validation Loss: 0.6078
Epoch 3000: 	Training Loss: 0.5978	Validation Loss: 0.6035
Epoch 3500: 	Training Loss: 0.5980	Validation Loss: 0.6023
Epoch 4000: 	Training Loss: 0.5980	Validation Loss: 0.6067
Early stopping at epoch 4031
Best validation loss: 0.6018
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6002	Validation Loss: 0.5956
Epoch 500: 	Training Loss: 0.6007	Validation Loss: 0.5928
Epoch 1000: 	Training Loss: 0.6008	Validation Loss: 0.5928
Epoch 1500: 	Training Loss: 0.6005	Validation Loss: 0.5933
Epoch 2000: 	Training Loss: 0.6017	Validation Loss: 0.5959
Epoch 2500: 	Training Loss: 0.6009	Validation Loss: 0.5964
Early stopping at epoch 2505
Best validation loss: 0.5912
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5952	Validation Loss: 0.6181
Epoch 500: 	Training Loss: 0.5948	Validation Loss: 0.6186
Epoch 1000: 	Training Loss: 0.5944	Validation Loss: 0.6173
Epoch 1500: 	Training Loss: 0.5953	Validation Loss: 0.6156
Epoch 2000: 	Training Loss: 0.5947	Validation Loss: 0.6154
Epoch 2500: 	Training Loss: 0.5945	Validation Loss: 0.6153
Early stopping at epoch 2585
Best validation loss: 0.6152
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6014	Validation Loss: 0.5912
Epoch 500: 	Training Loss: 0.6008	Validation Loss: 0.5916
Epoch 1000: 	Training Loss: 0.6012	Validation Loss: 0.5923
Epoch 1500: 	Training Loss: 0.6012	Validation Loss: 0.5922
Epoch 2000: 	Training Loss: 0.6011	Validation Loss: 0.5917
Epoch 2500: 	Training Loss: 0.6011	Validation Loss: 0.5932
Early stopping at epoch 2502
Best validation loss: 0.5909
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5963	Validation Loss: 0.6118
Epoch 500: 	Training Loss: 0.5962	Validation Loss: 0.6121
Epoch 1000: 	Training Loss: 0.5959	Validation Loss: 0.6110
Epoch 1500: 	Training Loss: 0.5958	Validation Loss: 0.6113
Epoch 2000: 	Training Loss: 0.5968	Validation Loss: 0.6143
Epoch 2500: 	Training Loss: 0.5958	Validation Loss: 0.6111
Epoch 3000: 	Training Loss: 0.5957	Validation Loss: 0.6111
Epoch 3500: 	Training Loss: 0.5954	Validation Loss: 0.6125
Epoch 4000: 	Training Loss: 0.5956	Validation Loss: 0.6119
Epoch 4500: 	Training Loss: 0.5954	Validation Loss: 0.6116
Epoch 5000: 	Training Loss: 0.5953	Validation Loss: 0.6117
Epoch 5500: 	Training Loss: 0.5957	Validation Loss: 0.6128
Epoch 6000: 	Training Loss: 0.5954	Validation Loss: 0.6112
Epoch 6500: 	Training Loss: 0.5955	Validation Loss: 0.6118
Epoch 7000: 	Training Loss: 0.5957	Validation Loss: 0.6120
Epoch 7500: 	Training Loss: 0.5953	Validation Loss: 0.6111
Epoch 8000: 	Training Loss: 0.5951	Validation Loss: 0.6119
Epoch 8500: 	Training Loss: 0.5953	Validation Loss: 0.6115
Epoch 9000: 	Training Loss: 0.5958	Validation Loss: 0.6117
Epoch 9500: 	Training Loss: 0.5953	Validation Loss: 0.6120
Early stopping at epoch 9974
Best validation loss: 0.6101
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/GQNN_5_relu_acceptreject_symmetric_qp_no-punishment_2022_10_08_20_15_08_479541/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u03>
Subject: Job 126381349: <GQNNx5-3-1> in cluster <Janelia> Done

Job <GQNNx5-3-1> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Sat Oct  8 20:14:52 2022
Job was executed on host(s) <e10u03>, in queue <local>, as user <mohantas> in cluster <Janelia> at Sat Oct  8 20:14:52 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Sat Oct  8 20:14:52 2022
Terminated at Mon Oct 10 14:00:57 2022
Results reported at Mon Oct 10 14:00:57 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_mohanta.py --agent GQNN --hidden_state_sizes 5 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric yes --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   298113.97 sec.
    Max Memory :                                 385 MB
    Average Memory :                             263.82 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               14975.00 MB
    Max Swap :                                   -
    Max Processes :                              6
    Max Threads :                                15
    Run time :                                   150360 sec.
    Turnaround time :                            150365 sec.

The output (if any) is above this job summary.

