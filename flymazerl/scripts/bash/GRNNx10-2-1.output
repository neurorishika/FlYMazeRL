
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GRNNLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_reward_set.csv
Model: GRNN_1x10_RNN_acceptreject_symmetric_qp_no-punishment_2022_10_04_02_23_52_653609
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6850	Validation Loss: 0.6789
Epoch 500: 	Training Loss: 0.6461	Validation Loss: 0.6623
Epoch 1000: 	Training Loss: 0.5947	Validation Loss: 0.6694
Epoch 1500: 	Training Loss: 0.6191	Validation Loss: 0.6446
Epoch 2000: 	Training Loss: 0.6068	Validation Loss: 0.6533
Epoch 2500: 	Training Loss: 0.5957	Validation Loss: 0.6763
Early stopping at epoch 2552
Best validation loss: 0.6370
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6886	Validation Loss: 0.6822
Epoch 500: 	Training Loss: 0.5783	Validation Loss: 0.6697
Epoch 1000: 	Training Loss: 0.6643	Validation Loss: 0.6699
Epoch 1500: 	Training Loss: 0.6554	Validation Loss: 0.6626
Epoch 2000: 	Training Loss: 0.6467	Validation Loss: 0.6491
Epoch 2500: 	Training Loss: 0.6479	Validation Loss: 0.6553
Early stopping at epoch 2587
Best validation loss: 0.6379
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6863	Validation Loss: 0.6693
Epoch 500: 	Training Loss: 0.6083	Validation Loss: 0.6174
Epoch 1000: 	Training Loss: 0.6320	Validation Loss: 0.5993
Epoch 1500: 	Training Loss: 0.6411	Validation Loss: 0.6079
Epoch 2000: 	Training Loss: 0.6354	Validation Loss: 0.6164
Epoch 2500: 	Training Loss: 0.6132	Validation Loss: 0.6080
Early stopping at epoch 2532
Best validation loss: 0.5878
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6863	Validation Loss: 0.6792
Epoch 500: 	Training Loss: 0.6039	Validation Loss: 0.6403
Epoch 1000: 	Training Loss: 0.6380	Validation Loss: 0.6454
Epoch 1500: 	Training Loss: 0.6176	Validation Loss: 0.6662
Epoch 2000: 	Training Loss: 0.6451	Validation Loss: 0.6584
Epoch 2500: 	Training Loss: 0.6519	Validation Loss: 0.6576
Early stopping at epoch 2866
Best validation loss: 0.6301
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6874	Validation Loss: 0.6791
Epoch 500: 	Training Loss: 0.6346	Validation Loss: 0.6487
Epoch 1000: 	Training Loss: 0.6347	Validation Loss: 0.6431
Epoch 1500: 	Training Loss: 0.6511	Validation Loss: 0.6617
Epoch 2000: 	Training Loss: 0.6510	Validation Loss: 0.6635
Epoch 2500: 	Training Loss: 0.6535	Validation Loss: 0.6482
Early stopping at epoch 2643
Best validation loss: 0.6324
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/GRNN_1x10_RNN_acceptreject_symmetric_qp_no-punishment_2022_10_04_02_23_52_653609/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u04>
Subject: Job 126235163: <GRNNx10-2-1> in cluster <Janelia> Done

Job <GRNNx10-2-1> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Tue Oct  4 02:23:26 2022
Job was executed on host(s) <e10u04>, in queue <local>, as user <mohantas> in cluster <Janelia> at Tue Oct  4 02:23:26 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Tue Oct  4 02:23:26 2022
Terminated at Tue Oct  4 03:33:50 2022
Results reported at Tue Oct  4 03:33:50 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_rajagopalan.py --agent GRNN --num_reservoir 1 --reservoir_size 10 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric yes --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   8350.19 sec.
    Max Memory :                                 237 MB
    Average Memory :                             227.06 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15123.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   4224 sec.
    Turnaround time :                            4224 sec.

The output (if any) is above this job summary.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GRNNLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_reward_set.csv
Model: GRNN_1x10_RNN_acceptreject_symmetric_qp_no-punishment_2022_10_08_20_12_07_101088
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6568	Validation Loss: 0.5677
Epoch 500: 	Training Loss: 0.6071	Validation Loss: 0.5483
Epoch 1000: 	Training Loss: 0.6132	Validation Loss: 0.5501
Epoch 1500: 	Training Loss: 0.6270	Validation Loss: 0.5583
Epoch 2000: 	Training Loss: 0.6260	Validation Loss: 0.5612
Epoch 2500: 	Training Loss: 0.6145	Validation Loss: 0.5557
Early stopping at epoch 2725
Best validation loss: 0.5446
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6443	Validation Loss: 0.6320
Epoch 500: 	Training Loss: 0.5969	Validation Loss: 0.6125
Epoch 1000: 	Training Loss: 0.6053	Validation Loss: 0.6160
Epoch 1500: 	Training Loss: 0.5980	Validation Loss: 0.6150
Epoch 2000: 	Training Loss: 0.6394	Validation Loss: 0.6258
Epoch 2500: 	Training Loss: 0.6118	Validation Loss: 0.6253
Early stopping at epoch 2589
Best validation loss: 0.6063
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6503	Validation Loss: 0.6295
Epoch 500: 	Training Loss: 0.6079	Validation Loss: 0.6238
Epoch 1000: 	Training Loss: 0.6161	Validation Loss: 0.6322
Epoch 1500: 	Training Loss: 0.6092	Validation Loss: 0.6306
Epoch 2000: 	Training Loss: 0.6035	Validation Loss: 0.6188
Epoch 2500: 	Training Loss: 0.6174	Validation Loss: 0.6308
Epoch 3000: 	Training Loss: 0.6136	Validation Loss: 0.6211
Early stopping at epoch 3118
Best validation loss: 0.6060
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6515	Validation Loss: 0.5910
Epoch 500: 	Training Loss: 0.6029	Validation Loss: 0.5776
Epoch 1000: 	Training Loss: 0.6103	Validation Loss: 0.5765
Epoch 1500: 	Training Loss: 0.6142	Validation Loss: 0.5817
Epoch 2000: 	Training Loss: 0.6325	Validation Loss: 0.6042
Epoch 2500: 	Training Loss: 0.6126	Validation Loss: 0.5816
Early stopping at epoch 2551
Best validation loss: 0.5674
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6642	Validation Loss: 0.6164
Epoch 500: 	Training Loss: 0.6028	Validation Loss: 0.6055
Epoch 1000: 	Training Loss: 0.6021	Validation Loss: 0.6053
Epoch 1500: 	Training Loss: 0.5994	Validation Loss: 0.6042
Epoch 2000: 	Training Loss: 0.6068	Validation Loss: 0.6076
Epoch 2500: 	Training Loss: 0.6038	Validation Loss: 0.6031
Early stopping at epoch 2542
Best validation loss: 0.5991
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/GRNN_1x10_RNN_acceptreject_symmetric_qp_no-punishment_2022_10_08_20_12_07_101088/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u25>
Subject: Job 126381308: <GRNNx10-2-1> in cluster <Janelia> Done

Job <GRNNx10-2-1> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Sat Oct  8 20:11:36 2022
Job was executed on host(s) <e10u25>, in queue <local>, as user <mohantas> in cluster <Janelia> at Sat Oct  8 20:11:38 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Sat Oct  8 20:11:38 2022
Terminated at Sun Oct  9 00:17:10 2022
Results reported at Sun Oct  9 00:17:10 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_mohanta.py --agent GRNN --num_reservoir 1 --reservoir_size 10 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric yes --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   28968.18 sec.
    Max Memory :                                 307 MB
    Average Memory :                             255.34 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15053.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   14737 sec.
    Turnaround time :                            14734 sec.

The output (if any) is above this job summary.

