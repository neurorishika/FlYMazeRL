
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_reward_set.csv
Model: GQNN_5_relu_acceptreject_symmetric_qp_no-punishment_2022_10_04_02_25_14_618287
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6878	Validation Loss: 0.6832
Epoch 500: 	Training Loss: 0.6301	Validation Loss: 0.6236
Epoch 1000: 	Training Loss: 0.6295	Validation Loss: 0.6230
Epoch 1500: 	Training Loss: 0.6294	Validation Loss: 0.6223
Epoch 2000: 	Training Loss: 0.6298	Validation Loss: 0.6229
Epoch 2500: 	Training Loss: 0.6287	Validation Loss: 0.6208
Epoch 3000: 	Training Loss: 0.6275	Validation Loss: 0.6214
Epoch 3500: 	Training Loss: 0.6355	Validation Loss: 0.6181
Epoch 4000: 	Training Loss: 0.6320	Validation Loss: 0.6217
Epoch 4500: 	Training Loss: 0.6289	Validation Loss: 0.6230
Epoch 5000: 	Training Loss: 0.6280	Validation Loss: 0.6264
Epoch 5500: 	Training Loss: 0.6277	Validation Loss: 0.6254
Epoch 6000: 	Training Loss: 0.6499	Validation Loss: 0.6445
Early stopping at epoch 6241
Best validation loss: 0.6150
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6296	Validation Loss: 0.6311
Epoch 500: 	Training Loss: 0.6327	Validation Loss: 0.6342
Epoch 1000: 	Training Loss: 0.6264	Validation Loss: 0.6343
Epoch 1500: 	Training Loss: 0.6254	Validation Loss: 0.6347
Epoch 2000: 	Training Loss: 0.6248	Validation Loss: 0.6355
Epoch 2500: 	Training Loss: 0.6254	Validation Loss: 0.6360
Early stopping at epoch 2511
Best validation loss: 0.6301
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6222	Validation Loss: 0.6568
Epoch 500: 	Training Loss: 0.6243	Validation Loss: 0.6671
Epoch 1000: 	Training Loss: 0.6226	Validation Loss: 0.6573
Epoch 1500: 	Training Loss: 0.6216	Validation Loss: 0.6590
Epoch 2000: 	Training Loss: 0.6197	Validation Loss: 0.6570
Epoch 2500: 	Training Loss: 0.6186	Validation Loss: 0.6568
Epoch 3000: 	Training Loss: 0.6190	Validation Loss: 0.6588
Early stopping at epoch 3451
Best validation loss: 0.6548
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6329	Validation Loss: 0.6205
Epoch 500: 	Training Loss: 0.6304	Validation Loss: 0.6165
Epoch 1000: 	Training Loss: 0.6298	Validation Loss: 0.6165
Epoch 1500: 	Training Loss: 0.6372	Validation Loss: 0.6268
Epoch 2000: 	Training Loss: 0.6386	Validation Loss: 0.6327
Epoch 2500: 	Training Loss: 0.6279	Validation Loss: 0.6276
Early stopping at epoch 2925
Best validation loss: 0.6159
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6272	Validation Loss: 0.6304
Epoch 500: 	Training Loss: 0.6321	Validation Loss: 0.6449
Epoch 1000: 	Training Loss: 0.6297	Validation Loss: 0.6409
Epoch 1500: 	Training Loss: 0.6257	Validation Loss: 0.6362
Epoch 2000: 	Training Loss: 0.6244	Validation Loss: 0.6368
Epoch 2500: 	Training Loss: 0.6240	Validation Loss: 0.6389
Early stopping at epoch 2807
Best validation loss: 0.6293
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/GQNN_5_relu_acceptreject_symmetric_qp_no-punishment_2022_10_04_02_25_14_618287/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u14>
Subject: Job 126235672: <GQNNx5-1-1> in cluster <Janelia> Done

Job <GQNNx5-1-1> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Tue Oct  4 02:24:50 2022
Job was executed on host(s) <e10u14>, in queue <local>, as user <mohantas> in cluster <Janelia> at Tue Oct  4 02:24:50 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Tue Oct  4 02:24:50 2022
Terminated at Tue Oct  4 08:35:32 2022
Results reported at Tue Oct  4 08:35:32 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_rajagopalan.py --agent GQNN --hidden_state_sizes 5 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric yes --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   44288.93 sec.
    Max Memory :                                 261 MB
    Average Memory :                             244.02 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15099.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   22242 sec.
    Turnaround time :                            22242 sec.

The output (if any) is above this job summary.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_reward_set.csv
Model: GQNN_5_relu_acceptreject_symmetric_qp_no-punishment_2022_10_08_20_14_57_207573
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6807	Validation Loss: 0.6643
Epoch 500: 	Training Loss: 0.6034	Validation Loss: 0.5824
Epoch 1000: 	Training Loss: 0.6030	Validation Loss: 0.5829
Epoch 1500: 	Training Loss: 0.6035	Validation Loss: 0.5828
Epoch 2000: 	Training Loss: 0.6031	Validation Loss: 0.5825
Epoch 2500: 	Training Loss: 0.6034	Validation Loss: 0.5829
Early stopping at epoch 2520
Best validation loss: 0.5822
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5997	Validation Loss: 0.6014
Epoch 500: 	Training Loss: 0.5988	Validation Loss: 0.6009
Epoch 1000: 	Training Loss: 0.5992	Validation Loss: 0.6020
Epoch 1500: 	Training Loss: 0.5984	Validation Loss: 0.6008
Epoch 2000: 	Training Loss: 0.5990	Validation Loss: 0.6013
Epoch 2500: 	Training Loss: 0.5983	Validation Loss: 0.6013
Early stopping at epoch 2882
Best validation loss: 0.6006
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6087	Validation Loss: 0.5655
Epoch 500: 	Training Loss: 0.6078	Validation Loss: 0.5652
Epoch 1000: 	Training Loss: 0.6073	Validation Loss: 0.5677
Epoch 1500: 	Training Loss: 0.6075	Validation Loss: 0.5712
Epoch 2000: 	Training Loss: 0.6086	Validation Loss: 0.5657
Epoch 2500: 	Training Loss: 0.6085	Validation Loss: 0.5654
Epoch 3000: 	Training Loss: 0.6077	Validation Loss: 0.5650
Early stopping at epoch 3028
Best validation loss: 0.5645
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6011	Validation Loss: 0.5925
Epoch 500: 	Training Loss: 0.6013	Validation Loss: 0.5946
Epoch 1000: 	Training Loss: 0.6012	Validation Loss: 0.5929
Epoch 1500: 	Training Loss: 0.6008	Validation Loss: 0.5925
Epoch 2000: 	Training Loss: 0.6008	Validation Loss: 0.5926
Epoch 2500: 	Training Loss: 0.6007	Validation Loss: 0.5927
Early stopping at epoch 2506
Best validation loss: 0.5923
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5923	Validation Loss: 0.6271
Epoch 500: 	Training Loss: 0.5925	Validation Loss: 0.6309
Epoch 1000: 	Training Loss: 0.5922	Validation Loss: 0.6325
Epoch 1500: 	Training Loss: 0.5918	Validation Loss: 0.6277
Epoch 2000: 	Training Loss: 0.5915	Validation Loss: 0.6282
Epoch 2500: 	Training Loss: 0.5914	Validation Loss: 0.6279
Epoch 3000: 	Training Loss: 0.5917	Validation Loss: 0.6276
Epoch 3500: 	Training Loss: 0.5914	Validation Loss: 0.6272
Epoch 4000: 	Training Loss: 0.5917	Validation Loss: 0.6280
Epoch 4500: 	Training Loss: 0.5919	Validation Loss: 0.6275
Early stopping at epoch 4782
Best validation loss: 0.6269
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/GQNN_5_relu_acceptreject_symmetric_qp_no-punishment_2022_10_08_20_14_57_207573/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u03>
Subject: Job 126381347: <GQNNx5-1-1> in cluster <Janelia> Done

Job <GQNNx5-1-1> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Sat Oct  8 20:14:51 2022
Job was executed on host(s) <e10u03>, in queue <local>, as user <mohantas> in cluster <Janelia> at Sat Oct  8 20:14:52 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Sat Oct  8 20:14:52 2022
Terminated at Mon Oct 10 03:09:39 2022
Results reported at Mon Oct 10 03:09:39 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_mohanta.py --agent GQNN --hidden_state_sizes 5 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric yes --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   220609.78 sec.
    Max Memory :                                 323 MB
    Average Memory :                             257.66 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15037.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   111288 sec.
    Turnaround time :                            111288 sec.

The output (if any) is above this job summary.

