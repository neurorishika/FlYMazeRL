
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_reward_set.csv
Model: GQNN_10-10_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_04_02_25_29_515326
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6923	Validation Loss: 0.6856
Epoch 500: 	Training Loss: 0.6251	Validation Loss: 0.6489
Epoch 1000: 	Training Loss: 0.6302	Validation Loss: 0.6509
Epoch 1500: 	Training Loss: 0.6288	Validation Loss: 0.6555
Epoch 2000: 	Training Loss: 0.6195	Validation Loss: 0.6469
Epoch 2500: 	Training Loss: 0.6326	Validation Loss: 0.6574
Epoch 3000: 	Training Loss: 0.6177	Validation Loss: 0.6566
Epoch 3500: 	Training Loss: 0.6230	Validation Loss: 0.6552
Epoch 4000: 	Training Loss: 0.6183	Validation Loss: 0.6541
Epoch 4500: 	Training Loss: 0.6215	Validation Loss: 0.6543
Early stopping at epoch 4526
Best validation loss: 0.6407
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6187	Validation Loss: 0.6563
Epoch 500: 	Training Loss: 0.6197	Validation Loss: 0.6654
Epoch 1000: 	Training Loss: 0.6157	Validation Loss: 0.6637
Epoch 1500: 	Training Loss: 0.6120	Validation Loss: 0.6630
Epoch 2000: 	Training Loss: 0.6330	Validation Loss: 0.6795
Epoch 2500: 	Training Loss: 0.6763	Validation Loss: 0.6751
Epoch 3000: 	Training Loss: 0.6370	Validation Loss: 0.6791
Epoch 3500: 	Training Loss: 0.6745	Validation Loss: 0.6753
Epoch 4000: 	Training Loss: 0.6301	Validation Loss: 0.6673
Epoch 4500: 	Training Loss: 0.6288	Validation Loss: 0.6686
Epoch 5000: 	Training Loss: 0.6518	Validation Loss: 0.6756
Epoch 5500: 	Training Loss: 0.6184	Validation Loss: 0.6648
Epoch 6000: 	Training Loss: 0.6755	Validation Loss: 0.6779
Epoch 6500: 	Training Loss: 0.6651	Validation Loss: 0.6810
Early stopping at epoch 6652
Best validation loss: 0.6534
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6284	Validation Loss: 0.6334
Epoch 500: 	Training Loss: 0.6337	Validation Loss: 0.6441
Epoch 1000: 	Training Loss: 0.6317	Validation Loss: 0.6319
Epoch 1500: 	Training Loss: 0.6323	Validation Loss: 0.6441
Epoch 2000: 	Training Loss: 0.6763	Validation Loss: 0.6757
Epoch 2500: 	Training Loss: 0.6757	Validation Loss: 0.6724
Early stopping at epoch 2502
Best validation loss: 0.6240
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6405	Validation Loss: 0.6439
Epoch 500: 	Training Loss: 0.6298	Validation Loss: 0.6423
Epoch 1000: 	Training Loss: 0.6291	Validation Loss: 0.6337
Epoch 1500: 	Training Loss: 0.6618	Validation Loss: 0.6784
Epoch 2000: 	Training Loss: 0.6380	Validation Loss: 0.6397
Epoch 2500: 	Training Loss: 0.6746	Validation Loss: 0.6552
Early stopping at epoch 2501
Best validation loss: 0.6280
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6337	Validation Loss: 0.6031
Epoch 500: 	Training Loss: 0.6369	Validation Loss: 0.6115
Epoch 1000: 	Training Loss: 0.6314	Validation Loss: 0.6081
Epoch 1500: 	Training Loss: 0.6671	Validation Loss: 0.6529
Epoch 2000: 	Training Loss: 0.6520	Validation Loss: 0.6477
Epoch 2500: 	Training Loss: 0.6381	Validation Loss: 0.6118
Early stopping at epoch 2522
Best validation loss: 0.6018
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/GQNN_10-10_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_04_02_25_29_515326/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u14>
Subject: Job 126236006: <GQNNx10x10-0-0> in cluster <Janelia> Done

Job <GQNNx10x10-0-0> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Tue Oct  4 02:25:26 2022
Job was executed on host(s) <e10u14>, in queue <local>, as user <mohantas> in cluster <Janelia> at Tue Oct  4 02:25:26 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Tue Oct  4 02:25:26 2022
Terminated at Tue Oct  4 07:56:20 2022
Results reported at Tue Oct  4 07:56:20 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_rajagopalan.py --agent GQNN --hidden_state_sizes 10 10 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric no --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   39551.73 sec.
    Max Memory :                                 264 MB
    Average Memory :                             245.46 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15096.00 MB
    Max Swap :                                   -
    Max Processes :                              6
    Max Threads :                                15
    Run time :                                   19853 sec.
    Turnaround time :                            19854 sec.

The output (if any) is above this job summary.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_reward_set.csv
Model: GQNN_10-10_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_08_20_15_30_796342
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6766	Validation Loss: 0.6477
Epoch 500: 	Training Loss: 0.6047	Validation Loss: 0.5758
Epoch 1000: 	Training Loss: 0.6049	Validation Loss: 0.5762
Epoch 1500: 	Training Loss: 0.6089	Validation Loss: 0.5777
Epoch 2000: 	Training Loss: 0.6094	Validation Loss: 0.5779
Epoch 2500: 	Training Loss: 0.6112	Validation Loss: 0.5828
Epoch 3000: 	Training Loss: 0.6137	Validation Loss: 0.5866
Early stopping at epoch 3056
Best validation loss: 0.5736
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5997	Validation Loss: 0.5968
Epoch 500: 	Training Loss: 0.6199	Validation Loss: 0.5975
Epoch 1000: 	Training Loss: 0.6035	Validation Loss: 0.6407
Epoch 1500: 	Training Loss: 0.5999	Validation Loss: 0.5982
Epoch 2000: 	Training Loss: 0.5996	Validation Loss: 0.5959
Epoch 2500: 	Training Loss: 0.6068	Validation Loss: 0.6295
Early stopping at epoch 2507
Best validation loss: 0.5937
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6004	Validation Loss: 0.5929
Epoch 500: 	Training Loss: 0.6076	Validation Loss: 0.5936
Epoch 1000: 	Training Loss: 0.5999	Validation Loss: 0.5912
Epoch 1500: 	Training Loss: 0.6024	Validation Loss: 0.5949
Epoch 2000: 	Training Loss: 0.6031	Validation Loss: 0.5929
Epoch 2500: 	Training Loss: 0.5999	Validation Loss: 0.5926
Early stopping at epoch 2569
Best validation loss: 0.5884
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5966	Validation Loss: 0.6068
Epoch 500: 	Training Loss: 0.6138	Validation Loss: 0.6267
Epoch 1000: 	Training Loss: 0.5962	Validation Loss: 0.6080
Epoch 1500: 	Training Loss: 0.5981	Validation Loss: 0.6102
Epoch 2000: 	Training Loss: 0.5996	Validation Loss: 0.6134
Epoch 2500: 	Training Loss: 0.6004	Validation Loss: 0.6097
Early stopping at epoch 2542
Best validation loss: 0.6044
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6137	Validation Loss: 0.5566
Epoch 500: 	Training Loss: 0.6645	Validation Loss: 0.6492
Epoch 1000: 	Training Loss: 0.6123	Validation Loss: 0.5565
Epoch 1500: 	Training Loss: 0.6237	Validation Loss: 0.5646
Epoch 2000: 	Training Loss: 0.6139	Validation Loss: 0.5576
Epoch 2500: 	Training Loss: 0.6115	Validation Loss: 0.5575
Early stopping at epoch 2501
Best validation loss: 0.5524
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/GQNN_10-10_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_08_20_15_30_796342/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u14>
Subject: Job 126381398: <GQNNx10x10-0-0> in cluster <Janelia> Done

Job <GQNNx10x10-0-0> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Sat Oct  8 20:15:25 2022
Job was executed on host(s) <e10u14>, in queue <local>, as user <mohantas> in cluster <Janelia> at Sat Oct  8 20:15:25 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Sat Oct  8 20:15:25 2022
Terminated at Sun Oct  9 13:10:24 2022
Results reported at Sun Oct  9 13:10:24 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_mohanta.py --agent GQNN --hidden_state_sizes 10 10 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric no --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   120812.41 sec.
    Max Memory :                                 303 MB
    Average Memory :                             255.18 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15057.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   60899 sec.
    Turnaround time :                            60899 sec.

The output (if any) is above this job summary.

