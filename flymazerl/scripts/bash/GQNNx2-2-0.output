
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_reward_set.csv
Model: GQNN_2_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_04_02_25_30_645046
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6717	Validation Loss: 0.6593
Epoch 500: 	Training Loss: 0.6357	Validation Loss: 0.6106
Epoch 1000: 	Training Loss: 0.6348	Validation Loss: 0.6109
Epoch 1500: 	Training Loss: 0.6351	Validation Loss: 0.6117
Epoch 2000: 	Training Loss: 0.6344	Validation Loss: 0.6124
Epoch 2500: 	Training Loss: 0.6346	Validation Loss: 0.6112
Epoch 3000: 	Training Loss: 0.6339	Validation Loss: 0.6110
Early stopping at epoch 3012
Best validation loss: 0.6101
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6336	Validation Loss: 0.6181
Epoch 500: 	Training Loss: 0.6324	Validation Loss: 0.6185
Epoch 1000: 	Training Loss: 0.6321	Validation Loss: 0.6183
Epoch 1500: 	Training Loss: 0.6322	Validation Loss: 0.6182
Epoch 2000: 	Training Loss: 0.6316	Validation Loss: 0.6179
Epoch 2500: 	Training Loss: 0.6318	Validation Loss: 0.6178
Epoch 3000: 	Training Loss: 0.6325	Validation Loss: 0.6172
Epoch 3500: 	Training Loss: 0.6316	Validation Loss: 0.6181
Epoch 4000: 	Training Loss: 0.6320	Validation Loss: 0.6191
Epoch 4500: 	Training Loss: 0.6318	Validation Loss: 0.6176
Epoch 5000: 	Training Loss: 0.6317	Validation Loss: 0.6176
Epoch 5500: 	Training Loss: 0.6319	Validation Loss: 0.6174
Early stopping at epoch 5613
Best validation loss: 0.6171
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6301	Validation Loss: 0.6287
Epoch 500: 	Training Loss: 0.6272	Validation Loss: 0.6306
Epoch 1000: 	Training Loss: 0.6264	Validation Loss: 0.6324
Epoch 1500: 	Training Loss: 0.6267	Validation Loss: 0.6372
Epoch 2000: 	Training Loss: 0.6267	Validation Loss: 0.6356
Epoch 2500: 	Training Loss: 0.6270	Validation Loss: 0.6398
Early stopping at epoch 2501
Best validation loss: 0.6270
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6304	Validation Loss: 0.6266
Epoch 500: 	Training Loss: 0.6254	Validation Loss: 0.6337
Epoch 1000: 	Training Loss: 0.6256	Validation Loss: 0.6346
Epoch 1500: 	Training Loss: 0.6297	Validation Loss: 0.6398
Epoch 2000: 	Training Loss: 0.6251	Validation Loss: 0.6347
Epoch 2500: 	Training Loss: 0.6259	Validation Loss: 0.6332
Early stopping at epoch 2500
Best validation loss: 0.6266
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6368	Validation Loss: 0.6008
Epoch 500: 	Training Loss: 0.6348	Validation Loss: 0.6016
Epoch 1000: 	Training Loss: 0.6346	Validation Loss: 0.6019
Epoch 1500: 	Training Loss: 0.6368	Validation Loss: 0.6022
Epoch 2000: 	Training Loss: 0.6357	Validation Loss: 0.6034
Epoch 2500: 	Training Loss: 0.6350	Validation Loss: 0.6020
Epoch 3000: 	Training Loss: 0.6347	Validation Loss: 0.6030
Early stopping at epoch 3048
Best validation loss: 0.5994
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/GQNN_2_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_04_02_25_30_645046/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u11>
Subject: Job 126235928: <GQNNx2-2-0> in cluster <Janelia> Done

Job <GQNNx2-2-0> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Tue Oct  4 02:25:16 2022
Job was executed on host(s) <e10u11>, in queue <local>, as user <mohantas> in cluster <Janelia> at Tue Oct  4 02:25:17 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Tue Oct  4 02:25:17 2022
Terminated at Tue Oct  4 06:08:28 2022
Results reported at Tue Oct  4 06:08:28 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_rajagopalan.py --agent GQNN --hidden_state_sizes 2 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric no --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   26657.67 sec.
    Max Memory :                                 256 MB
    Average Memory :                             236.34 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15104.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   13391 sec.
    Turnaround time :                            13392 sec.

The output (if any) is above this job summary.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_reward_set.csv
Model: GQNN_2_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_08_20_15_23_670943
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.7077	Validation Loss: 0.6957
Epoch 500: 	Training Loss: 0.6050	Validation Loss: 0.5855
Epoch 1000: 	Training Loss: 0.6048	Validation Loss: 0.5902
Epoch 1500: 	Training Loss: 0.6047	Validation Loss: 0.5824
Epoch 2000: 	Training Loss: 0.6042	Validation Loss: 0.5850
Epoch 2500: 	Training Loss: 0.6039	Validation Loss: 0.5827
Epoch 3000: 	Training Loss: 0.6043	Validation Loss: 0.5827
Epoch 3500: 	Training Loss: 0.6042	Validation Loss: 0.5822
Epoch 4000: 	Training Loss: 0.6048	Validation Loss: 0.5829
Early stopping at epoch 4483
Best validation loss: 0.5820
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6030	Validation Loss: 0.5896
Epoch 500: 	Training Loss: 0.6032	Validation Loss: 0.5975
Epoch 1000: 	Training Loss: 0.6026	Validation Loss: 0.5907
Epoch 1500: 	Training Loss: 0.6037	Validation Loss: 0.5908
Epoch 2000: 	Training Loss: 0.6020	Validation Loss: 0.5928
Epoch 2500: 	Training Loss: 0.6027	Validation Loss: 0.5930
Early stopping at epoch 2500
Best validation loss: 0.5896
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6088	Validation Loss: 0.5806
Epoch 500: 	Training Loss: 0.6069	Validation Loss: 0.5762
Epoch 1000: 	Training Loss: 0.6072	Validation Loss: 0.5747
Epoch 1500: 	Training Loss: 0.6068	Validation Loss: 0.5724
Epoch 2000: 	Training Loss: 0.6060	Validation Loss: 0.5857
Epoch 2500: 	Training Loss: 0.6074	Validation Loss: 0.5724
Early stopping at epoch 2958
Best validation loss: 0.5710
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5962	Validation Loss: 0.6206
Epoch 500: 	Training Loss: 0.5951	Validation Loss: 0.6202
Epoch 1000: 	Training Loss: 0.5948	Validation Loss: 0.6247
Epoch 1500: 	Training Loss: 0.5964	Validation Loss: 0.6219
Epoch 2000: 	Training Loss: 0.5954	Validation Loss: 0.6223
Epoch 2500: 	Training Loss: 0.5944	Validation Loss: 0.6212
Epoch 3000: 	Training Loss: 0.5949	Validation Loss: 0.6225
Epoch 3500: 	Training Loss: 0.5940	Validation Loss: 0.6204
Epoch 4000: 	Training Loss: 0.5944	Validation Loss: 0.6206
Epoch 4500: 	Training Loss: 0.5944	Validation Loss: 0.6207
Epoch 5000: 	Training Loss: 0.5942	Validation Loss: 0.6202
Epoch 5500: 	Training Loss: 0.5957	Validation Loss: 0.6224
Early stopping at epoch 5690
Best validation loss: 0.6198
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6068	Validation Loss: 0.5805
Epoch 500: 	Training Loss: 0.6055	Validation Loss: 0.5778
Epoch 1000: 	Training Loss: 0.6040	Validation Loss: 0.5836
Epoch 1500: 	Training Loss: 0.6062	Validation Loss: 0.5802
Epoch 2000: 	Training Loss: 0.6045	Validation Loss: 0.5771
Epoch 2500: 	Training Loss: 0.6049	Validation Loss: 0.5774
Early stopping at epoch 2924
Best validation loss: 0.5770
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/GQNN_2_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_08_20_15_23_670943/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u22>
Subject: Job 126381380: <GQNNx2-2-0> in cluster <Janelia> Done

Job <GQNNx2-2-0> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Sat Oct  8 20:15:15 2022
Job was executed on host(s) <e10u22>, in queue <local>, as user <mohantas> in cluster <Janelia> at Sat Oct  8 20:15:17 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Sat Oct  8 20:15:17 2022
Terminated at Mon Oct 10 01:20:52 2022
Results reported at Mon Oct 10 01:20:52 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_mohanta.py --agent GQNN --hidden_state_sizes 2 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric no --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   208043.19 sec.
    Max Memory :                                 354 MB
    Average Memory :                             266.66 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15006.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                14
    Run time :                                   104735 sec.
    Turnaround time :                            104737 sec.

The output (if any) is above this job summary.

