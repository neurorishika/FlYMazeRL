
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_reward_set.csv
Model: GQNN_100-100_relu_acceptreject_symmetric_qp_no-punishment_2022_10_04_02_25_07_415208
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6662	Validation Loss: 0.6449
Epoch 500: 	Training Loss: 0.6336	Validation Loss: 0.6173
Epoch 1000: 	Training Loss: 0.6633	Validation Loss: 0.6281
Epoch 1500: 	Training Loss: 0.6441	Validation Loss: 0.6226
Epoch 2000: 	Training Loss: 0.6419	Validation Loss: 0.6251
Epoch 2500: 	Training Loss: 0.6351	Validation Loss: 0.6150
Early stopping at epoch 2811
Best validation loss: 0.6091
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6289	Validation Loss: 0.6682
Epoch 500: 	Training Loss: 0.6179	Validation Loss: 0.6621
Epoch 1000: 	Training Loss: 0.6185	Validation Loss: 0.6614
Epoch 1500: 	Training Loss: 0.6155	Validation Loss: 0.6639
Epoch 2000: 	Training Loss: 0.6149	Validation Loss: 0.6656
Epoch 2500: 	Training Loss: 0.6259	Validation Loss: 0.6641
Epoch 3000: 	Training Loss: 0.6512	Validation Loss: 0.6680
Early stopping at epoch 3120
Best validation loss: 0.6559
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6206	Validation Loss: 0.6653
Epoch 500: 	Training Loss: 0.6173	Validation Loss: 0.6656
Epoch 1000: 	Training Loss: 0.6513	Validation Loss: 0.6683
Epoch 1500: 	Training Loss: 0.6458	Validation Loss: 0.6705
Epoch 2000: 	Training Loss: 0.6174	Validation Loss: 0.6687
Epoch 2500: 	Training Loss: 0.6164	Validation Loss: 0.6686
Early stopping at epoch 2813
Best validation loss: 0.6594
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6333	Validation Loss: 0.6284
Epoch 500: 	Training Loss: 0.8412	Validation Loss: 0.8764
Epoch 1000: 	Training Loss: 0.8412	Validation Loss: 0.8764
Epoch 1500: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 2000: 	Training Loss: 0.6277	Validation Loss: 0.6277
Epoch 2500: 	Training Loss: 0.6279	Validation Loss: 0.6274
Early stopping at epoch 2503
Best validation loss: 0.6243
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6321	Validation Loss: 0.6205
Epoch 500: 	Training Loss: 0.6344	Validation Loss: 0.6258
Epoch 1000: 	Training Loss: 0.6315	Validation Loss: 0.6298
Epoch 1500: 	Training Loss: 0.6320	Validation Loss: 0.6340
Epoch 2000: 	Training Loss: 0.6798	Validation Loss: 0.6632
Epoch 2500: 	Training Loss: 0.6578	Validation Loss: 0.6374
Early stopping at epoch 2546
Best validation loss: 0.6165
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/GQNN_100-100_relu_acceptreject_symmetric_qp_no-punishment_2022_10_04_02_25_07_415208/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u30>
Subject: Job 126235752: <GQNNx100x100-3-1> in cluster <Janelia> Done

Job <GQNNx100x100-3-1> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Tue Oct  4 02:25:02 2022
Job was executed on host(s) <e10u30>, in queue <local>, as user <mohantas> in cluster <Janelia> at Tue Oct  4 02:25:02 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Tue Oct  4 02:25:02 2022
Terminated at Tue Oct  4 11:54:31 2022
Results reported at Tue Oct  4 11:54:31 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_rajagopalan.py --agent GQNN --hidden_state_sizes 100 100 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric yes --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   67946.93 sec.
    Max Memory :                                 256 MB
    Average Memory :                             243.98 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15104.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   34167 sec.
    Turnaround time :                            34169 sec.

The output (if any) is above this job summary.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_reward_set.csv
Model: GQNN_100-100_relu_acceptreject_symmetric_qp_no-punishment_2022_10_08_20_15_19_609470
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6420	Validation Loss: 0.5790
Epoch 500: 	Training Loss: 0.6119	Validation Loss: 0.5625
Epoch 1000: 	Training Loss: 0.6112	Validation Loss: 0.5620
Epoch 1500: 	Training Loss: 0.6111	Validation Loss: 0.5619
Epoch 2000: 	Training Loss: 0.6088	Validation Loss: 0.5657
Epoch 2500: 	Training Loss: 0.8217	Validation Loss: 0.6733
Epoch 3000: 	Training Loss: 0.6088	Validation Loss: 0.5619
Epoch 3500: 	Training Loss: 0.6091	Validation Loss: 0.5617
Epoch 4000: 	Training Loss: 0.6091	Validation Loss: 0.5622
Epoch 4500: 	Training Loss: 0.6104	Validation Loss: 0.5628
Epoch 5000: 	Training Loss: 0.6094	Validation Loss: 0.5628
Epoch 5500: 	Training Loss: 0.6095	Validation Loss: 0.5623
Epoch 6000: 	Training Loss: 0.6085	Validation Loss: 0.5612
Early stopping at epoch 6285
Best validation loss: 0.5602
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6020	Validation Loss: 0.5967
Epoch 500: 	Training Loss: 0.6019	Validation Loss: 0.5975
Epoch 1000: 	Training Loss: 0.6048	Validation Loss: 0.5997
Epoch 1500: 	Training Loss: 0.6012	Validation Loss: 0.5987
Epoch 2000: 	Training Loss: 0.5995	Validation Loss: 0.5974
Epoch 2500: 	Training Loss: 0.6005	Validation Loss: 0.6015
Early stopping at epoch 2609
Best validation loss: 0.5949
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6033	Validation Loss: 0.5863
Epoch 500: 	Training Loss: 0.6088	Validation Loss: 0.5889
Epoch 1000: 	Training Loss: 0.6032	Validation Loss: 0.5949
Epoch 1500: 	Training Loss: 0.6024	Validation Loss: 0.5934
Epoch 2000: 	Training Loss: 0.6122	Validation Loss: 0.5880
Epoch 2500: 	Training Loss: 0.6026	Validation Loss: 0.5879
Epoch 3000: 	Training Loss: 0.6055	Validation Loss: 0.5946
Epoch 3500: 	Training Loss: 0.6228	Validation Loss: 0.5987
Epoch 4000: 	Training Loss: 0.6026	Validation Loss: 0.5941
Early stopping at epoch 4106
Best validation loss: 0.5858
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6010	Validation Loss: 0.5997
Epoch 500: 	Training Loss: 0.5996	Validation Loss: 0.6043
Epoch 1000: 	Training Loss: 0.6015	Validation Loss: 0.6008
Epoch 1500: 	Training Loss: 0.5994	Validation Loss: 0.5998
Epoch 2000: 	Training Loss: 0.5995	Validation Loss: 0.6022
Epoch 2500: 	Training Loss: 0.5996	Validation Loss: 0.6042
Early stopping at epoch 2778
Best validation loss: 0.5980
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6011	Validation Loss: 0.5993
Epoch 500: 	Training Loss: 0.6007	Validation Loss: 0.5995
Epoch 1000: 	Training Loss: 0.5988	Validation Loss: 0.5993
Epoch 1500: 	Training Loss: 0.5993	Validation Loss: 0.6001
Epoch 2000: 	Training Loss: 0.6081	Validation Loss: 0.6026
Epoch 2500: 	Training Loss: 0.6024	Validation Loss: 0.6011
Early stopping at epoch 2635
Best validation loss: 0.5978
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/GQNN_100-100_relu_acceptreject_symmetric_qp_no-punishment_2022_10_08_20_15_19_609470/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u18>
Subject: Job 126381369: <GQNNx100x100-3-1> in cluster <Janelia> Done

Job <GQNNx100x100-3-1> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Sat Oct  8 20:15:03 2022
Job was executed on host(s) <e10u18>, in queue <local>, as user <mohantas> in cluster <Janelia> at Sat Oct  8 20:15:05 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Sat Oct  8 20:15:05 2022
Terminated at Mon Oct 10 11:06:26 2022
Results reported at Mon Oct 10 11:06:26 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_mohanta.py --agent GQNN --hidden_state_sizes 100 100 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric yes --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   277697.78 sec.
    Max Memory :                                 378 MB
    Average Memory :                             283.96 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               14982.00 MB
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                14
    Run time :                                   139886 sec.
    Turnaround time :                            139883 sec.

The output (if any) is above this job summary.

