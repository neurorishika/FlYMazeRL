
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GRNNLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_reward_set.csv
Model: GRNN_1x100_RNN_acceptreject_asymmetric_qp_no-punishment_2022_10_04_02_17_35_326985
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6756	Validation Loss: 0.6527
Epoch 500: 	Training Loss: 0.6701	Validation Loss: 0.6695
Epoch 1000: 	Training Loss: 0.6517	Validation Loss: 0.6629
Epoch 1500: 	Training Loss: 0.6537	Validation Loss: 0.6600
Epoch 2000: 	Training Loss: 0.6473	Validation Loss: 0.6373
Epoch 2500: 	Training Loss: 0.6564	Validation Loss: 0.6613
Early stopping at epoch 2906
Best validation loss: 0.6202
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6663	Validation Loss: 0.6546
Epoch 500: 	Training Loss: 0.6307	Validation Loss: 0.6441
Epoch 1000: 	Training Loss: 0.6335	Validation Loss: 0.6461
Epoch 1500: 	Training Loss: 0.6307	Validation Loss: 0.6498
Epoch 2000: 	Training Loss: 0.6600	Validation Loss: 0.6634
Epoch 2500: 	Training Loss: 0.6414	Validation Loss: 0.6675
Early stopping at epoch 2767
Best validation loss: 0.6345
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6855	Validation Loss: 0.7563
Epoch 500: 	Training Loss: 0.6111	Validation Loss: 0.6921
Epoch 1000: 	Training Loss: 0.6673	Validation Loss: 0.6923
Epoch 1500: 	Training Loss: 0.6908	Validation Loss: 0.6919
Epoch 2000: 	Training Loss: 0.6217	Validation Loss: 0.6721
Epoch 2500: 	Training Loss: 0.6450	Validation Loss: 0.6996
Early stopping at epoch 2651
Best validation loss: 0.6590
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6736	Validation Loss: 0.6927
Epoch 500: 	Training Loss: 0.6253	Validation Loss: 0.6669
Epoch 1000: 	Training Loss: 0.6268	Validation Loss: 0.6752
Epoch 1500: 	Training Loss: 0.6431	Validation Loss: 0.6652
Epoch 2000: 	Training Loss: 0.6189	Validation Loss: 0.6607
Epoch 2500: 	Training Loss: 0.6360	Validation Loss: 0.6720
Epoch 3000: 	Training Loss: 0.6244	Validation Loss: 0.6773
Epoch 3500: 	Training Loss: 0.7147	Validation Loss: 0.6937
Epoch 4000: 	Training Loss: 0.6187	Validation Loss: 0.6938
Epoch 4500: 	Training Loss: 0.6336	Validation Loss: 0.6647
Epoch 5000: 	Training Loss: 0.6665	Validation Loss: 0.6968
Epoch 5500: 	Training Loss: 0.6442	Validation Loss: 0.6789
Early stopping at epoch 5645
Best validation loss: 0.6430
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6811	Validation Loss: 0.6843
Epoch 500: 	Training Loss: 0.6797	Validation Loss: 0.7155
Epoch 1000: 	Training Loss: 0.7008	Validation Loss: 0.7525
Epoch 1500: 	Training Loss: 0.6408	Validation Loss: 0.6437
Epoch 2000: 	Training Loss: 0.6412	Validation Loss: 0.6361
Epoch 2500: 	Training Loss: 0.6739	Validation Loss: 0.6786
Early stopping at epoch 2587
Best validation loss: 0.6136
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/GRNN_1x100_RNN_acceptreject_asymmetric_qp_no-punishment_2022_10_04_02_17_35_326985/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u30>
Subject: Job 126232928: <GRNNx100-1-0> in cluster <Janelia> Done

Job <GRNNx100-1-0> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Tue Oct  4 02:17:11 2022
Job was executed on host(s) <e10u30>, in queue <local>, as user <mohantas> in cluster <Janelia> at Tue Oct  4 02:17:12 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Tue Oct  4 02:17:12 2022
Terminated at Tue Oct  4 04:03:46 2022
Results reported at Tue Oct  4 04:03:46 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_rajagopalan.py --agent GRNN --num_reservoir 1 --reservoir_size 100 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric no --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   12672.32 sec.
    Max Memory :                                 254 MB
    Average Memory :                             235.10 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15106.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   6397 sec.
    Turnaround time :                            6395 sec.

The output (if any) is above this job summary.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GRNNLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_reward_set.csv
Model: GRNN_1x100_RNN_acceptreject_asymmetric_qp_no-punishment_2022_10_08_20_14_45_134387
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6393	Validation Loss: 0.6031
Epoch 500: 	Training Loss: 0.6924	Validation Loss: 0.6938
Epoch 1000: 	Training Loss: 0.6150	Validation Loss: 0.5985
Epoch 1500: 	Training Loss: 0.6227	Validation Loss: 0.6040
Epoch 2000: 	Training Loss: 0.6460	Validation Loss: 0.6106
Epoch 2500: 	Training Loss: 0.6544	Validation Loss: 0.6365
Epoch 3000: 	Training Loss: 0.6255	Validation Loss: 0.6056
Epoch 3500: 	Training Loss: 0.6550	Validation Loss: 0.6359
Epoch 4000: 	Training Loss: 0.6923	Validation Loss: 0.6945
Epoch 4500: 	Training Loss: 0.6245	Validation Loss: 0.6160
Epoch 5000: 	Training Loss: 0.6177	Validation Loss: 0.6036
Epoch 5500: 	Training Loss: 0.6216	Validation Loss: 0.5984
Epoch 6000: 	Training Loss: 0.6931	Validation Loss: 0.6937
Epoch 6500: 	Training Loss: 0.6259	Validation Loss: 0.6009
Early stopping at epoch 6947
Best validation loss: 0.5864
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6636	Validation Loss: 0.6836
Epoch 500: 	Training Loss: 0.6051	Validation Loss: 0.6245
Epoch 1000: 	Training Loss: 0.6138	Validation Loss: 0.6271
Epoch 1500: 	Training Loss: 0.6531	Validation Loss: 0.6743
Epoch 2000: 	Training Loss: 0.6930	Validation Loss: 0.6939
Epoch 2500: 	Training Loss: 0.7194	Validation Loss: 0.7612
Early stopping at epoch 2543
Best validation loss: 0.6113
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6956	Validation Loss: 0.6936
Epoch 500: 	Training Loss: 0.6048	Validation Loss: 0.5911
Epoch 1000: 	Training Loss: 0.6432	Validation Loss: 0.6252
Epoch 1500: 	Training Loss: 0.7537	Validation Loss: 0.7485
Epoch 2000: 	Training Loss: 0.6123	Validation Loss: 0.5924
Epoch 2500: 	Training Loss: 0.6302	Validation Loss: 0.6214
Epoch 3000: 	Training Loss: 0.7068	Validation Loss: 0.6933
Early stopping at epoch 3211
Best validation loss: 0.5788
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6394	Validation Loss: 0.6378
Epoch 500: 	Training Loss: 0.6495	Validation Loss: 0.6678
Epoch 1000: 	Training Loss: 0.6247	Validation Loss: 0.6458
Epoch 1500: 	Training Loss: 0.6590	Validation Loss: 0.6727
Epoch 2000: 	Training Loss: 0.6187	Validation Loss: 0.6344
Epoch 2500: 	Training Loss: 0.6078	Validation Loss: 0.6309
Epoch 3000: 	Training Loss: 0.8308	Validation Loss: 0.8432
Epoch 3500: 	Training Loss: 0.7474	Validation Loss: 0.7619
Epoch 4000: 	Training Loss: 0.6114	Validation Loss: 0.6397
Early stopping at epoch 4100
Best validation loss: 0.6203
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6387	Validation Loss: 0.6275
Epoch 500: 	Training Loss: 0.6930	Validation Loss: 0.6936
Epoch 1000: 	Training Loss: 0.6351	Validation Loss: 0.6529
Epoch 1500: 	Training Loss: 0.6930	Validation Loss: 0.6939
Epoch 2000: 	Training Loss: 0.6014	Validation Loss: 0.6266
Epoch 2500: 	Training Loss: 0.8540	Validation Loss: 0.8769
Early stopping at epoch 2602
Best validation loss: 0.6165
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/GRNN_1x100_RNN_acceptreject_asymmetric_qp_no-punishment_2022_10_08_20_14_45_134387/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u10>
Subject: Job 126381335: <GRNNx100-1-0> in cluster <Janelia> Done

Job <GRNNx100-1-0> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Sat Oct  8 20:14:38 2022
Job was executed on host(s) <e10u10>, in queue <local>, as user <mohantas> in cluster <Janelia> at Sat Oct  8 20:14:38 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Sat Oct  8 20:14:38 2022
Terminated at Sun Oct  9 01:23:02 2022
Results reported at Sun Oct  9 01:23:02 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_mohanta.py --agent GRNN --num_reservoir 1 --reservoir_size 100 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric no --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   36297.45 sec.
    Max Memory :                                 370 MB
    Average Memory :                             272.53 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               14990.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   18504 sec.
    Turnaround time :                            18504 sec.

The output (if any) is above this job summary.

