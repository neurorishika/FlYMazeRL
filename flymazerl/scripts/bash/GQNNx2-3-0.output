
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_reward_set.csv
Model: GQNN_2_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_04_02_25_30_645051
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6796	Validation Loss: 0.6814
Epoch 500: 	Training Loss: 0.6272	Validation Loss: 0.6305
Epoch 1000: 	Training Loss: 0.6233	Validation Loss: 0.6305
Epoch 1500: 	Training Loss: 0.6240	Validation Loss: 0.6304
Epoch 2000: 	Training Loss: 0.6239	Validation Loss: 0.6311
Epoch 2500: 	Training Loss: 0.6246	Validation Loss: 0.6319
Epoch 3000: 	Training Loss: 0.6232	Validation Loss: 0.6334
Early stopping at epoch 3068
Best validation loss: 0.6291
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6272	Validation Loss: 0.6398
Epoch 500: 	Training Loss: 0.6233	Validation Loss: 0.6398
Epoch 1000: 	Training Loss: 0.6212	Validation Loss: 0.6394
Epoch 1500: 	Training Loss: 0.6207	Validation Loss: 0.6395
Epoch 2000: 	Training Loss: 0.6218	Validation Loss: 0.6405
Epoch 2500: 	Training Loss: 0.6212	Validation Loss: 0.6403
Early stopping at epoch 2875
Best validation loss: 0.6370
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6344	Validation Loss: 0.6140
Epoch 500: 	Training Loss: 0.6311	Validation Loss: 0.6088
Epoch 1000: 	Training Loss: 0.6301	Validation Loss: 0.6138
Epoch 1500: 	Training Loss: 0.6303	Validation Loss: 0.6064
Epoch 2000: 	Training Loss: 0.6309	Validation Loss: 0.6115
Epoch 2500: 	Training Loss: 0.6303	Validation Loss: 0.6066
Early stopping at epoch 2511
Best validation loss: 0.6029
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6308	Validation Loss: 0.6166
Epoch 500: 	Training Loss: 0.6300	Validation Loss: 0.6144
Epoch 1000: 	Training Loss: 0.6284	Validation Loss: 0.6151
Epoch 1500: 	Training Loss: 0.6291	Validation Loss: 0.6141
Epoch 2000: 	Training Loss: 0.6281	Validation Loss: 0.6140
Epoch 2500: 	Training Loss: 0.6281	Validation Loss: 0.6146
Early stopping at epoch 2502
Best validation loss: 0.6127
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6232	Validation Loss: 0.6384
Epoch 500: 	Training Loss: 0.6216	Validation Loss: 0.6479
Epoch 1000: 	Training Loss: 0.6203	Validation Loss: 0.6392
Epoch 1500: 	Training Loss: 0.6211	Validation Loss: 0.6427
Epoch 2000: 	Training Loss: 0.6207	Validation Loss: 0.6378
Epoch 2500: 	Training Loss: 0.6206	Validation Loss: 0.6383
Epoch 3000: 	Training Loss: 0.6208	Validation Loss: 0.6430
Epoch 3500: 	Training Loss: 0.6203	Validation Loss: 0.6440
Epoch 4000: 	Training Loss: 0.6212	Validation Loss: 0.6375
Epoch 4500: 	Training Loss: 0.6199	Validation Loss: 0.6407
Epoch 5000: 	Training Loss: 0.6207	Validation Loss: 0.6400
Early stopping at epoch 5006
Best validation loss: 0.6372
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/GQNN_2_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_04_02_25_30_645051/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u11>
Subject: Job 126235929: <GQNNx2-3-0> in cluster <Janelia> Done

Job <GQNNx2-3-0> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Tue Oct  4 02:25:16 2022
Job was executed on host(s) <e10u11>, in queue <local>, as user <mohantas> in cluster <Janelia> at Tue Oct  4 02:25:17 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Tue Oct  4 02:25:17 2022
Terminated at Tue Oct  4 06:01:37 2022
Results reported at Tue Oct  4 06:01:37 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_rajagopalan.py --agent GQNN --hidden_state_sizes 2 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric no --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   25833.48 sec.
    Max Memory :                                 255 MB
    Average Memory :                             237.30 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15105.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   12980 sec.
    Turnaround time :                            12981 sec.

The output (if any) is above this job summary.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_reward_set.csv
Model: GQNN_2_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_08_20_15_23_670742
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6648	Validation Loss: 0.7231
Epoch 500: 	Training Loss: 0.6076	Validation Loss: 0.5761
Epoch 1000: 	Training Loss: 0.6074	Validation Loss: 0.5742
Epoch 1500: 	Training Loss: 0.6076	Validation Loss: 0.5738
Epoch 2000: 	Training Loss: 0.6074	Validation Loss: 0.5759
Epoch 2500: 	Training Loss: 0.6068	Validation Loss: 0.5739
Epoch 3000: 	Training Loss: 0.6072	Validation Loss: 0.5736
Epoch 3500: 	Training Loss: 0.6067	Validation Loss: 0.5762
Epoch 4000: 	Training Loss: 0.6067	Validation Loss: 0.5800
Epoch 4500: 	Training Loss: 0.6086	Validation Loss: 0.5745
Early stopping at epoch 4509
Best validation loss: 0.5714
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5926	Validation Loss: 0.6314
Epoch 500: 	Training Loss: 0.5911	Validation Loss: 0.6311
Epoch 1000: 	Training Loss: 0.5911	Validation Loss: 0.6311
Epoch 1500: 	Training Loss: 0.5920	Validation Loss: 0.6320
Epoch 2000: 	Training Loss: 0.5925	Validation Loss: 0.6341
Epoch 2500: 	Training Loss: 0.5920	Validation Loss: 0.6313
Early stopping at epoch 2646
Best validation loss: 0.6307
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5937	Validation Loss: 0.6247
Epoch 500: 	Training Loss: 0.5928	Validation Loss: 0.6239
Epoch 1000: 	Training Loss: 0.5929	Validation Loss: 0.6241
Epoch 1500: 	Training Loss: 0.5928	Validation Loss: 0.6271
Epoch 2000: 	Training Loss: 0.5931	Validation Loss: 0.6244
Epoch 2500: 	Training Loss: 0.5940	Validation Loss: 0.6243
Early stopping at epoch 2809
Best validation loss: 0.6231
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6022	Validation Loss: 0.5974
Epoch 500: 	Training Loss: 0.6033	Validation Loss: 0.5937
Epoch 1000: 	Training Loss: 0.6010	Validation Loss: 0.5966
Epoch 1500: 	Training Loss: 0.6003	Validation Loss: 0.5963
Epoch 2000: 	Training Loss: 0.6018	Validation Loss: 0.5937
Epoch 2500: 	Training Loss: 0.6008	Validation Loss: 0.5935
Early stopping at epoch 2759
Best validation loss: 0.5921
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6013	Validation Loss: 0.5965
Epoch 500: 	Training Loss: 0.6002	Validation Loss: 0.6005
Epoch 1000: 	Training Loss: 0.6000	Validation Loss: 0.5961
Epoch 1500: 	Training Loss: 0.6018	Validation Loss: 0.5966
Epoch 2000: 	Training Loss: 0.5997	Validation Loss: 0.5971
Epoch 2500: 	Training Loss: 0.6004	Validation Loss: 0.5977
Early stopping at epoch 2504
Best validation loss: 0.5954
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/GQNN_2_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_08_20_15_23_670742/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u22>
Subject: Job 126381381: <GQNNx2-3-0> in cluster <Janelia> Done

Job <GQNNx2-3-0> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Sat Oct  8 20:15:16 2022
Job was executed on host(s) <e10u22>, in queue <local>, as user <mohantas> in cluster <Janelia> at Sat Oct  8 20:15:17 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Sat Oct  8 20:15:17 2022
Terminated at Sun Oct  9 20:50:38 2022
Results reported at Sun Oct  9 20:50:38 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_mohanta.py --agent GQNN --hidden_state_sizes 2 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric no --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   175833.73 sec.
    Max Memory :                                 326 MB
    Average Memory :                             258.22 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15034.00 MB
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                14
    Run time :                                   88521 sec.
    Turnaround time :                            88522 sec.

The output (if any) is above this job summary.

