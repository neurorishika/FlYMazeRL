
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_reward_set.csv
Model: GQNN_5-5_relu_acceptreject_symmetric_qp_no-punishment_2022_10_04_02_25_23_590095
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6914	Validation Loss: 0.6899
Epoch 500: 	Training Loss: 0.6257	Validation Loss: 0.6321
Epoch 1000: 	Training Loss: 0.6230	Validation Loss: 0.6302
Epoch 1500: 	Training Loss: 0.6242	Validation Loss: 0.6301
Epoch 2000: 	Training Loss: 0.6242	Validation Loss: 0.6297
Epoch 2500: 	Training Loss: 0.6274	Validation Loss: 0.6310
Epoch 3000: 	Training Loss: 0.6551	Validation Loss: 0.6546
Epoch 3500: 	Training Loss: 0.6239	Validation Loss: 0.6377
Early stopping at epoch 3923
Best validation loss: 0.6269
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6253	Validation Loss: 0.6307
Epoch 500: 	Training Loss: 0.6231	Validation Loss: 0.6344
Epoch 1000: 	Training Loss: 0.6221	Validation Loss: 0.6327
Epoch 1500: 	Training Loss: 0.6216	Validation Loss: 0.6322
Epoch 2000: 	Training Loss: 0.6275	Validation Loss: 0.6409
Epoch 2500: 	Training Loss: 0.6251	Validation Loss: 0.6368
Epoch 3000: 	Training Loss: 0.6234	Validation Loss: 0.6379
Early stopping at epoch 3324
Best validation loss: 0.6275
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6283	Validation Loss: 0.6222
Epoch 500: 	Training Loss: 0.6340	Validation Loss: 0.6334
Epoch 1000: 	Training Loss: 0.6250	Validation Loss: 0.6244
Epoch 1500: 	Training Loss: 0.6255	Validation Loss: 0.6262
Epoch 2000: 	Training Loss: 0.6930	Validation Loss: 0.6931
Epoch 2500: 	Training Loss: 0.6320	Validation Loss: 0.6343
Early stopping at epoch 2723
Best validation loss: 0.6183
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6322	Validation Loss: 0.6100
Epoch 500: 	Training Loss: 0.6273	Validation Loss: 0.6154
Epoch 1000: 	Training Loss: 0.6345	Validation Loss: 0.6143
Epoch 1500: 	Training Loss: 0.6265	Validation Loss: 0.6156
Epoch 2000: 	Training Loss: 0.6342	Validation Loss: 0.6150
Epoch 2500: 	Training Loss: 0.6285	Validation Loss: 0.6211
Epoch 3000: 	Training Loss: 0.6329	Validation Loss: 0.6110
Epoch 3500: 	Training Loss: 0.6315	Validation Loss: 0.6184
Epoch 4000: 	Training Loss: 0.6443	Validation Loss: 0.6258
Epoch 4500: 	Training Loss: 0.6353	Validation Loss: 0.6288
Epoch 5000: 	Training Loss: 0.6929	Validation Loss: 0.6933
Epoch 5500: 	Training Loss: 0.6557	Validation Loss: 0.6382
Early stopping at epoch 5551
Best validation loss: 0.6069
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6286	Validation Loss: 0.6240
Epoch 500: 	Training Loss: 0.7705	Validation Loss: 0.7837
Epoch 1000: 	Training Loss: 0.6393	Validation Loss: 0.6377
Epoch 1500: 	Training Loss: 0.6381	Validation Loss: 0.6355
Epoch 2000: 	Training Loss: 0.6268	Validation Loss: 0.6302
Epoch 2500: 	Training Loss: 0.6496	Validation Loss: 0.6656
Early stopping at epoch 2880
Best validation loss: 0.6188
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/GQNN_5-5_relu_acceptreject_symmetric_qp_no-punishment_2022_10_04_02_25_23_590095/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u27>
Subject: Job 126235734: <GQNNx5x5-2-1> in cluster <Janelia> Done

Job <GQNNx5x5-2-1> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Tue Oct  4 02:24:57 2022
Job was executed on host(s) <e10u27>, in queue <local>, as user <mohantas> in cluster <Janelia> at Tue Oct  4 02:24:59 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Tue Oct  4 02:24:59 2022
Terminated at Tue Oct  4 10:24:54 2022
Results reported at Tue Oct  4 10:24:54 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_rajagopalan.py --agent GQNN --hidden_state_sizes 5 5 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric yes --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   57287.34 sec.
    Max Memory :                                 266 MB
    Average Memory :                             247.77 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15094.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   28795 sec.
    Turnaround time :                            28797 sec.

The output (if any) is above this job summary.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_reward_set.csv
Model: GQNN_5-5_relu_acceptreject_symmetric_qp_no-punishment_2022_10_08_20_15_19_609459
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6906	Validation Loss: 0.6733
Epoch 500: 	Training Loss: 0.6134	Validation Loss: 0.5736
Epoch 1000: 	Training Loss: 0.6072	Validation Loss: 0.5680
Epoch 1500: 	Training Loss: 0.6070	Validation Loss: 0.5681
Epoch 2000: 	Training Loss: 0.6076	Validation Loss: 0.5713
Epoch 2500: 	Training Loss: 0.6068	Validation Loss: 0.5690
Epoch 3000: 	Training Loss: 0.6075	Validation Loss: 0.5685
Early stopping at epoch 3114
Best validation loss: 0.5674
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6053	Validation Loss: 0.5853
Epoch 500: 	Training Loss: 0.6034	Validation Loss: 0.5846
Epoch 1000: 	Training Loss: 0.6031	Validation Loss: 0.5844
Epoch 1500: 	Training Loss: 0.6052	Validation Loss: 0.5862
Epoch 2000: 	Training Loss: 0.6024	Validation Loss: 0.5845
Epoch 2500: 	Training Loss: 0.6032	Validation Loss: 0.5849
Epoch 3000: 	Training Loss: 0.6039	Validation Loss: 0.5861
Epoch 3500: 	Training Loss: 0.6017	Validation Loss: 0.5840
Epoch 4000: 	Training Loss: 0.6016	Validation Loss: 0.5846
Epoch 4500: 	Training Loss: 0.6052	Validation Loss: 0.5914
Epoch 5000: 	Training Loss: 0.6040	Validation Loss: 0.5868
Epoch 5500: 	Training Loss: 0.6013	Validation Loss: 0.5857
Early stopping at epoch 5541
Best validation loss: 0.5833
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5960	Validation Loss: 0.6099
Epoch 500: 	Training Loss: 0.5953	Validation Loss: 0.6105
Epoch 1000: 	Training Loss: 0.5947	Validation Loss: 0.6111
Epoch 1500: 	Training Loss: 0.5948	Validation Loss: 0.6110
Epoch 2000: 	Training Loss: 0.5971	Validation Loss: 0.6148
Epoch 2500: 	Training Loss: 0.5947	Validation Loss: 0.6106
Early stopping at epoch 2867
Best validation loss: 0.6092
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6037	Validation Loss: 0.5799
Epoch 500: 	Training Loss: 0.6034	Validation Loss: 0.5807
Epoch 1000: 	Training Loss: 0.6049	Validation Loss: 0.5814
Epoch 1500: 	Training Loss: 0.6053	Validation Loss: 0.5817
Epoch 2000: 	Training Loss: 0.6031	Validation Loss: 0.5814
Epoch 2500: 	Training Loss: 0.6035	Validation Loss: 0.5809
Early stopping at epoch 2511
Best validation loss: 0.5785
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5898	Validation Loss: 0.6326
Epoch 500: 	Training Loss: 0.5907	Validation Loss: 0.6338
Epoch 1000: 	Training Loss: 0.5901	Validation Loss: 0.6341
Epoch 1500: 	Training Loss: 0.5900	Validation Loss: 0.6326
Epoch 2000: 	Training Loss: 0.5895	Validation Loss: 0.6335
Epoch 2500: 	Training Loss: 0.5899	Validation Loss: 0.6330
Epoch 3000: 	Training Loss: 0.5892	Validation Loss: 0.6334
Early stopping at epoch 3025
Best validation loss: 0.6316
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/GQNN_5-5_relu_acceptreject_symmetric_qp_no-punishment_2022_10_08_20_15_19_609459/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u18>
Subject: Job 126381360: <GQNNx5x5-2-1> in cluster <Janelia> Done

Job <GQNNx5x5-2-1> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Sat Oct  8 20:14:58 2022
Job was executed on host(s) <e10u18>, in queue <local>, as user <mohantas> in cluster <Janelia> at Sat Oct  8 20:15:00 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Sat Oct  8 20:15:00 2022
Terminated at Mon Oct 10 03:21:45 2022
Results reported at Mon Oct 10 03:21:45 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_mohanta.py --agent GQNN --hidden_state_sizes 5 5 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric yes --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   222479.39 sec.
    Max Memory :                                 337 MB
    Average Memory :                             257.40 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15023.00 MB
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                14
    Run time :                                   112007 sec.
    Turnaround time :                            112007 sec.

The output (if any) is above this job summary.

