
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_reward_set.csv
Model: GQNN_100-100-100_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_04_02_25_48_828373
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6697	Validation Loss: 0.6729
Epoch 500: 	Training Loss: 0.6594	Validation Loss: 0.6744
Epoch 1000: 	Training Loss: nan	Validation Loss: nan
Epoch 1500: 	Training Loss: nan	Validation Loss: nan
Epoch 2000: 	Training Loss: nan	Validation Loss: nan
Epoch 2500: 	Training Loss: nan	Validation Loss: nan
Early stopping at epoch 2818
Best validation loss: 0.6301
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6380	Validation Loss: 0.6371
Epoch 500: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 1000: 	Training Loss: 0.6322	Validation Loss: 0.6444
Epoch 1500: 	Training Loss: 0.6595	Validation Loss: 0.6774
Epoch 2000: 	Training Loss: 0.6251	Validation Loss: 0.6429
Epoch 2500: 	Training Loss: 0.6585	Validation Loss: 0.6725
Epoch 3000: 	Training Loss: nan	Validation Loss: nan
Epoch 3500: 	Training Loss: nan	Validation Loss: nan
Epoch 4000: 	Training Loss: nan	Validation Loss: nan
Early stopping at epoch 4047
Best validation loss: 0.6327
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6747	Validation Loss: 0.6621
Epoch 500: 	Training Loss: 0.6608	Validation Loss: 0.6704
Epoch 1000: 	Training Loss: 0.6384	Validation Loss: 0.6400
Epoch 1500: 	Training Loss: 0.6586	Validation Loss: 0.6701
Epoch 2000: 	Training Loss: 0.6345	Validation Loss: 0.6378
Epoch 2500: 	Training Loss: 0.6931	Validation Loss: 0.6931
Early stopping at epoch 2659
Best validation loss: 0.6258
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6397	Validation Loss: 0.6285
Epoch 500: 	Training Loss: 0.6420	Validation Loss: 0.6341
Epoch 1000: 	Training Loss: 0.6658	Validation Loss: 0.6446
Epoch 1500: 	Training Loss: 0.6659	Validation Loss: 0.6459
Epoch 2000: 	Training Loss: 0.6658	Validation Loss: 0.6459
Epoch 2500: 	Training Loss: 0.6401	Validation Loss: 0.6373
Epoch 3000: 	Training Loss: 0.6415	Validation Loss: 0.6334
Epoch 3500: 	Training Loss: 0.6439	Validation Loss: 0.6336
Epoch 4000: 	Training Loss: 0.6375	Validation Loss: 0.6344
Epoch 4500: 	Training Loss: 0.6471	Validation Loss: 0.6332
Epoch 5000: 	Training Loss: nan	Validation Loss: nan
Epoch 5500: 	Training Loss: nan	Validation Loss: nan
Epoch 6000: 	Training Loss: nan	Validation Loss: nan
Early stopping at epoch 6154
Best validation loss: 0.6183
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6279	Validation Loss: 0.6366
Epoch 500: 	Training Loss: 0.6762	Validation Loss: 0.6688
Epoch 1000: 	Training Loss: 0.6607	Validation Loss: 0.6719
Epoch 1500: 	Training Loss: 0.6371	Validation Loss: 0.6392
Epoch 2000: 	Training Loss: 0.6407	Validation Loss: 0.6455
Epoch 2500: 	Training Loss: 0.6607	Validation Loss: 0.6729
Early stopping at epoch 2525
Best validation loss: 0.6294
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/GQNN_100-100-100_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_04_02_25_48_828373/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u02>
Subject: Job 126236049: <GQNNx100x100x100-2-0> in cluster <Janelia> Done

Job <GQNNx100x100x100-2-0> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Tue Oct  4 02:25:33 2022
Job was executed on host(s) <e10u02>, in queue <local>, as user <mohantas> in cluster <Janelia> at Tue Oct  4 02:25:33 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Tue Oct  4 02:25:33 2022
Terminated at Tue Oct  4 09:16:19 2022
Results reported at Tue Oct  4 09:16:19 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_rajagopalan.py --agent GQNN --hidden_state_sizes 100 100 100 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric no --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   49095.43 sec.
    Max Memory :                                 266 MB
    Average Memory :                             249.12 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15094.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   24645 sec.
    Turnaround time :                            24646 sec.

The output (if any) is above this job summary.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_reward_set.csv
Model: GQNN_100-100-100_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_08_20_15_43_740220
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6561	Validation Loss: 0.6565
Epoch 500: 	Training Loss: nan	Validation Loss: nan
Epoch 1000: 	Training Loss: nan	Validation Loss: nan
Epoch 1500: 	Training Loss: nan	Validation Loss: nan
Epoch 2000: 	Training Loss: nan	Validation Loss: nan
Epoch 2500: 	Training Loss: nan	Validation Loss: nan
Early stopping at epoch 2618
Best validation loss: 0.6090
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5917	Validation Loss: 0.6529
Epoch 500: 	Training Loss: 0.5894	Validation Loss: 0.6509
Epoch 1000: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 1500: 	Training Loss: nan	Validation Loss: nan
Epoch 2000: 	Training Loss: nan	Validation Loss: nan
Epoch 2500: 	Training Loss: nan	Validation Loss: nan
Epoch 3000: 	Training Loss: nan	Validation Loss: nan
Epoch 3500: 	Training Loss: nan	Validation Loss: nan
Early stopping at epoch 3562
Best validation loss: 0.6478
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5997	Validation Loss: 0.6172
Epoch 500: 	Training Loss: 0.6621	Validation Loss: 0.6712
Epoch 1000: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 1500: 	Training Loss: nan	Validation Loss: nan
Epoch 2000: 	Training Loss: nan	Validation Loss: nan
Epoch 2500: 	Training Loss: nan	Validation Loss: nan
Early stopping at epoch 2509
Best validation loss: 0.6116
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5967	Validation Loss: 0.6349
Epoch 500: 	Training Loss: 0.6409	Validation Loss: 0.6840
Epoch 1000: 	Training Loss: nan	Validation Loss: nan
Epoch 1500: 	Training Loss: nan	Validation Loss: nan
Epoch 2000: 	Training Loss: nan	Validation Loss: nan
Epoch 2500: 	Training Loss: nan	Validation Loss: nan
Early stopping at epoch 2523
Best validation loss: 0.6303
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5998	Validation Loss: 0.6097
Epoch 500: 	Training Loss: 0.6264	Validation Loss: 0.6295
Epoch 1000: 	Training Loss: 0.6128	Validation Loss: 0.6238
Epoch 1500: 	Training Loss: nan	Validation Loss: nan
Epoch 2000: 	Training Loss: nan	Validation Loss: nan
Epoch 2500: 	Training Loss: nan	Validation Loss: nan
Early stopping at epoch 2507
Best validation loss: 0.6077
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/GQNN_100-100-100_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_08_20_15_43_740220/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u19>
Subject: Job 126381412: <GQNNx100x100x100-2-0> in cluster <Janelia> Done

Job <GQNNx100x100x100-2-0> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Sat Oct  8 20:15:33 2022
Job was executed on host(s) <e10u19>, in queue <local>, as user <mohantas> in cluster <Janelia> at Sat Oct  8 20:15:33 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Sat Oct  8 20:15:33 2022
Terminated at Mon Oct 10 05:10:36 2022
Results reported at Mon Oct 10 05:10:36 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_mohanta.py --agent GQNN --hidden_state_sizes 100 100 100 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric no --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   235678.36 sec.
    Max Memory :                                 352 MB
    Average Memory :                             311.44 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15008.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   118506 sec.
    Turnaround time :                            118503 sec.

The output (if any) is above this job summary.

