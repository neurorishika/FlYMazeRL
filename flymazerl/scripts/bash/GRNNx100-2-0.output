
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GRNNLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_reward_set.csv
Model: GRNN_1x100_RNN_acceptreject_asymmetric_qp_no-punishment_2022_10_04_02_17_35_326988
Traceback (most recent call last):
  File "/groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash/../nn_fitting_rajagopalan.py", line 172, in <module>
    os.makedirs(save_path)
  File "/groups/turner/home/mohantas/anaconda3/envs/flymazerl/lib/python3.9/os.py", line 225, in makedirs
    mkdir(name, mode)
FileExistsError: [Errno 17] File exists: '/groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/GRNN_1x100_RNN_acceptreject_asymmetric_qp_no-punishment_2022_10_04_02_17_35_326988/'

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u30>
Subject: Job 126232934: <GRNNx100-2-0> in cluster <Janelia> Exited

Job <GRNNx100-2-0> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Tue Oct  4 02:17:11 2022
Job was executed on host(s) <e10u30>, in queue <local>, as user <mohantas> in cluster <Janelia> at Tue Oct  4 02:17:12 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Tue Oct  4 02:17:12 2022
Terminated at Tue Oct  4 02:17:50 2022
Results reported at Tue Oct  4 02:17:50 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_rajagopalan.py --agent GRNN --num_reservoir 1 --reservoir_size 100 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric no --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/ 
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   3.92 sec.
    Max Memory :                                 222 MB
    Average Memory :                             177.43 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15138.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                12
    Run time :                                   41 sec.
    Turnaround time :                            39 sec.

The output (if any) is above this job summary.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GRNNLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_reward_set.csv
Model: GRNN_1x100_RNN_acceptreject_asymmetric_qp_no-punishment_2022_10_04_02_23_19_155316
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6762	Validation Loss: 0.6714
Epoch 500: 	Training Loss: 0.6336	Validation Loss: 0.6576
Epoch 1000: 	Training Loss: 0.7673	Validation Loss: 0.8146
Epoch 1500: 	Training Loss: 0.6448	Validation Loss: 0.6659
Epoch 2000: 	Training Loss: 0.6246	Validation Loss: 0.6455
Epoch 2500: 	Training Loss: 0.6595	Validation Loss: 0.6839
Early stopping at epoch 2769
Best validation loss: 0.6350
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6684	Validation Loss: 0.6675
Epoch 500: 	Training Loss: 0.6349	Validation Loss: 0.6734
Epoch 1000: 	Training Loss: 0.6300	Validation Loss: 0.6683
Epoch 1500: 	Training Loss: 0.6296	Validation Loss: 0.6651
Epoch 2000: 	Training Loss: 0.6442	Validation Loss: 0.6656
Epoch 2500: 	Training Loss: 0.6409	Validation Loss: 0.6715
Epoch 3000: 	Training Loss: 0.6599	Validation Loss: 0.6837
Early stopping at epoch 3373
Best validation loss: 0.6499
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6863	Validation Loss: 0.6781
Epoch 500: 	Training Loss: 0.6119	Validation Loss: 0.6627
Epoch 1000: 	Training Loss: 0.6294	Validation Loss: 0.6783
Epoch 1500: 	Training Loss: 0.6368	Validation Loss: 0.6673
Epoch 2000: 	Training Loss: 0.7780	Validation Loss: 0.7758
Epoch 2500: 	Training Loss: 0.7798	Validation Loss: 0.7758
Early stopping at epoch 2574
Best validation loss: 0.6584
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6716	Validation Loss: 0.7097
Epoch 500: 	Training Loss: 0.6126	Validation Loss: 0.6554
Epoch 1000: 	Training Loss: 0.6111	Validation Loss: 0.6477
Epoch 1500: 	Training Loss: 0.6240	Validation Loss: 0.6430
Epoch 2000: 	Training Loss: 0.6419	Validation Loss: 0.6505
Epoch 2500: 	Training Loss: 0.6305	Validation Loss: 0.6533
Epoch 3000: 	Training Loss: 0.6222	Validation Loss: 0.6528
Epoch 3500: 	Training Loss: 0.6638	Validation Loss: 0.6801
Epoch 4000: 	Training Loss: 0.6419	Validation Loss: 0.6480
Epoch 4500: 	Training Loss: 0.6058	Validation Loss: 0.6656
Epoch 5000: 	Training Loss: 0.6429	Validation Loss: 0.6520
Epoch 5500: 	Training Loss: 0.6307	Validation Loss: 0.6477
Epoch 6000: 	Training Loss: 0.6627	Validation Loss: 0.6650
Epoch 6500: 	Training Loss: 0.6189	Validation Loss: 0.6642
Early stopping at epoch 6854
Best validation loss: 0.6304
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6799	Validation Loss: 0.6276
Epoch 500: 	Training Loss: 0.6411	Validation Loss: 0.6370
Epoch 1000: 	Training Loss: 0.6324	Validation Loss: 0.6291
Epoch 1500: 	Training Loss: 0.6471	Validation Loss: 0.6350
Epoch 2000: 	Training Loss: 0.6217	Validation Loss: 0.6304
Epoch 2500: 	Training Loss: 0.6159	Validation Loss: 0.6515
Early stopping at epoch 2630
Best validation loss: 0.5934
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/GRNN_1x100_RNN_acceptreject_asymmetric_qp_no-punishment_2022_10_04_02_23_19_155316/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u18>
Subject: Job 126235060: <GRNNx100-2-0> in cluster <Janelia> Done

Job <GRNNx100-2-0> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Tue Oct  4 02:23:07 2022
Job was executed on host(s) <e10u18>, in queue <local>, as user <mohantas> in cluster <Janelia> at Tue Oct  4 02:23:07 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Tue Oct  4 02:23:07 2022
Terminated at Tue Oct  4 03:27:29 2022
Results reported at Tue Oct  4 03:27:29 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_rajagopalan.py --agent GRNN --num_reservoir 1 --reservoir_size 100 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric no --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   7657.71 sec.
    Max Memory :                                 265 MB
    Average Memory :                             243.79 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15095.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   3865 sec.
    Turnaround time :                            3862 sec.

The output (if any) is above this job summary.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GRNNLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_reward_set.csv
Model: GRNN_1x100_RNN_acceptreject_asymmetric_qp_no-punishment_2022_10_08_20_14_45_134388
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.7491	Validation Loss: 0.7577
Epoch 500: 	Training Loss: 0.6929	Validation Loss: 0.6934
Epoch 1000: 	Training Loss: 0.6161	Validation Loss: 0.6064
Epoch 1500: 	Training Loss: 0.6268	Validation Loss: 0.6149
Epoch 2000: 	Training Loss: 0.6269	Validation Loss: 0.6188
Epoch 2500: 	Training Loss: 0.6928	Validation Loss: 0.6934
Epoch 3000: 	Training Loss: 0.6205	Validation Loss: 0.6187
Early stopping at epoch 3498
Best validation loss: 0.5965
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6487	Validation Loss: 0.6177
Epoch 500: 	Training Loss: 0.6334	Validation Loss: 0.6382
Epoch 1000: 	Training Loss: 0.6631	Validation Loss: 0.6662
Epoch 1500: 	Training Loss: 0.7948	Validation Loss: 0.7761
Epoch 2000: 	Training Loss: 0.6183	Validation Loss: 0.6185
Epoch 2500: 	Training Loss: 0.6371	Validation Loss: 0.6397
Early stopping at epoch 2646
Best validation loss: 0.6002
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6317	Validation Loss: 0.6455
Epoch 500: 	Training Loss: 0.6160	Validation Loss: 0.6497
Epoch 1000: 	Training Loss: 0.6120	Validation Loss: 0.6465
Epoch 1500: 	Training Loss: 0.7146	Validation Loss: 0.6935
Epoch 2000: 	Training Loss: 0.6051	Validation Loss: 0.6491
Epoch 2500: 	Training Loss: 0.6751	Validation Loss: 0.6852
Epoch 3000: 	Training Loss: 0.6022	Validation Loss: 0.6327
Epoch 3500: 	Training Loss: 0.6057	Validation Loss: 0.6455
Epoch 4000: 	Training Loss: 0.6104	Validation Loss: 0.6453
Epoch 4500: 	Training Loss: 0.6285	Validation Loss: 0.6525
Early stopping at epoch 4874
Best validation loss: 0.6288
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6598	Validation Loss: 0.6177
Epoch 500: 	Training Loss: 0.6302	Validation Loss: 0.6246
Epoch 1000: 	Training Loss: 0.6172	Validation Loss: 0.6245
Epoch 1500: 	Training Loss: 0.7827	Validation Loss: 0.7693
Epoch 2000: 	Training Loss: 0.6114	Validation Loss: 0.6201
Epoch 2500: 	Training Loss: 0.6175	Validation Loss: 0.6162
Epoch 3000: 	Training Loss: 0.6278	Validation Loss: 0.6268
Epoch 3500: 	Training Loss: 0.6282	Validation Loss: 0.6377
Epoch 4000: 	Training Loss: 0.6116	Validation Loss: 0.6117
Epoch 4500: 	Training Loss: 0.6113	Validation Loss: 0.6166
Epoch 5000: 	Training Loss: 0.6601	Validation Loss: 0.6567
Epoch 5500: 	Training Loss: 0.7236	Validation Loss: 0.7456
Epoch 6000: 	Training Loss: 0.6202	Validation Loss: 0.6159
Epoch 6500: 	Training Loss: 0.6536	Validation Loss: 0.6389
Early stopping at epoch 6522
Best validation loss: 0.6035
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6494	Validation Loss: 0.6275
Epoch 500: 	Training Loss: 0.6172	Validation Loss: 0.6190
Epoch 1000: 	Training Loss: 0.7928	Validation Loss: 0.7829
Epoch 1500: 	Training Loss: 0.6204	Validation Loss: 0.6185
Epoch 2000: 	Training Loss: 0.6249	Validation Loss: 0.6294
Epoch 2500: 	Training Loss: 0.6714	Validation Loss: 0.6651
Epoch 3000: 	Training Loss: 0.7058	Validation Loss: 0.7049
Epoch 3500: 	Training Loss: 0.6932	Validation Loss: 0.6926
Epoch 4000: 	Training Loss: 0.6357	Validation Loss: 0.6402
Early stopping at epoch 4398
Best validation loss: 0.5997
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/GRNN_1x100_RNN_acceptreject_asymmetric_qp_no-punishment_2022_10_08_20_14_45_134388/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u10>
Subject: Job 126381336: <GRNNx100-2-0> in cluster <Janelia> Done

Job <GRNNx100-2-0> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Sat Oct  8 20:14:39 2022
Job was executed on host(s) <e10u10>, in queue <local>, as user <mohantas> in cluster <Janelia> at Sat Oct  8 20:14:39 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Sat Oct  8 20:14:39 2022
Terminated at Sun Oct  9 01:57:17 2022
Results reported at Sun Oct  9 01:57:17 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_mohanta.py --agent GRNN --num_reservoir 1 --reservoir_size 100 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric no --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   40328.95 sec.
    Max Memory :                                 364 MB
    Average Memory :                             281.49 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               14996.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   20556 sec.
    Turnaround time :                            20558 sec.

The output (if any) is above this job summary.

