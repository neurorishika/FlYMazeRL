
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_reward_set.csv
Model: GQNN_10-10-10_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_04_02_25_48_828377
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6963	Validation Loss: 0.6903
Epoch 500: 	Training Loss: 0.6545	Validation Loss: 0.6871
Epoch 1000: 	Training Loss: 0.6552	Validation Loss: 0.6879
Epoch 1500: 	Training Loss: 0.6519	Validation Loss: 0.6819
Epoch 2000: 	Training Loss: 0.6295	Validation Loss: 0.6657
Epoch 2500: 	Training Loss: 0.6449	Validation Loss: 0.6815
Early stopping at epoch 2624
Best validation loss: 0.6540
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6256	Validation Loss: 0.6508
Epoch 500: 	Training Loss: 0.6298	Validation Loss: 0.6475
Epoch 1000: 	Training Loss: 0.6257	Validation Loss: 0.6494
Epoch 1500: 	Training Loss: 0.6530	Validation Loss: 0.6743
Epoch 2000: 	Training Loss: 0.6266	Validation Loss: 0.6477
Epoch 2500: 	Training Loss: 0.6304	Validation Loss: 0.6516
Epoch 3000: 	Training Loss: 0.6301	Validation Loss: 0.6514
Epoch 3500: 	Training Loss: 0.6381	Validation Loss: 0.6568
Epoch 4000: 	Training Loss: 0.6283	Validation Loss: 0.6461
Epoch 4500: 	Training Loss: 0.6246	Validation Loss: 0.6453
Epoch 5000: 	Training Loss: 0.6302	Validation Loss: 0.6521
Epoch 5500: 	Training Loss: 0.6271	Validation Loss: 0.6440
Epoch 6000: 	Training Loss: 0.6331	Validation Loss: 0.6480
Epoch 6500: 	Training Loss: 0.6316	Validation Loss: 0.6481
Epoch 7000: 	Training Loss: 0.6744	Validation Loss: 0.6767
Epoch 7500: 	Training Loss: 0.6835	Validation Loss: 0.6828
Epoch 8000: 	Training Loss: 0.7200	Validation Loss: 0.7083
Early stopping at epoch 8202
Best validation loss: 0.6396
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6287	Validation Loss: 0.6291
Epoch 500: 	Training Loss: 0.6815	Validation Loss: 0.6556
Epoch 1000: 	Training Loss: 0.6810	Validation Loss: 0.6570
Epoch 1500: 	Training Loss: 0.6809	Validation Loss: 0.6557
Epoch 2000: 	Training Loss: 0.6340	Validation Loss: 0.6374
Epoch 2500: 	Training Loss: 0.6931	Validation Loss: 0.6931
Early stopping at epoch 2501
Best validation loss: 0.6280
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6262	Validation Loss: 0.6401
Epoch 500: 	Training Loss: 0.6277	Validation Loss: 0.6433
Epoch 1000: 	Training Loss: 0.6279	Validation Loss: 0.6488
Epoch 1500: 	Training Loss: 0.6389	Validation Loss: 0.6490
Epoch 2000: 	Training Loss: 0.6367	Validation Loss: 0.6576
Epoch 2500: 	Training Loss: 0.6802	Validation Loss: 0.6735
Epoch 3000: 	Training Loss: 0.6240	Validation Loss: 0.6444
Early stopping at epoch 3167
Best validation loss: 0.6374
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6219	Validation Loss: 0.6559
Epoch 500: 	Training Loss: 0.6259	Validation Loss: 0.6546
Epoch 1000: 	Training Loss: 0.6256	Validation Loss: 0.6581
Epoch 1500: 	Training Loss: 0.6257	Validation Loss: 0.6661
Epoch 2000: 	Training Loss: 0.6233	Validation Loss: 0.6568
Epoch 2500: 	Training Loss: 0.6268	Validation Loss: 0.6611
Early stopping at epoch 2746
Best validation loss: 0.6466
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/GQNN_10-10-10_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_04_02_25_48_828377/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u02>
Subject: Job 126236036: <GQNNx10x10x10-3-0> in cluster <Janelia> Done

Job <GQNNx10x10x10-3-0> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Tue Oct  4 02:25:32 2022
Job was executed on host(s) <e10u02>, in queue <local>, as user <mohantas> in cluster <Janelia> at Tue Oct  4 02:25:32 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Tue Oct  4 02:25:32 2022
Terminated at Tue Oct  4 08:35:08 2022
Results reported at Tue Oct  4 08:35:08 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_rajagopalan.py --agent GQNN --hidden_state_sizes 10 10 10 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric no --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   44157.40 sec.
    Max Memory :                                 267 MB
    Average Memory :                             242.08 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15093.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   22175 sec.
    Turnaround time :                            22176 sec.

The output (if any) is above this job summary.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_reward_set.csv
Model: GQNN_10-10-10_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_08_20_15_39_951513
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6804	Validation Loss: 0.6718
Epoch 500: 	Training Loss: 0.6270	Validation Loss: 0.6675
Epoch 1000: 	Training Loss: 0.5931	Validation Loss: 0.6450
Epoch 1500: 	Training Loss: 0.6372	Validation Loss: 0.6576
Epoch 2000: 	Training Loss: 0.6050	Validation Loss: 0.6580
Epoch 2500: 	Training Loss: 0.5923	Validation Loss: 0.6412
Early stopping at epoch 2583
Best validation loss: 0.6346
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6238	Validation Loss: 0.6075
Epoch 500: 	Training Loss: 0.6019	Validation Loss: 0.6073
Epoch 1000: 	Training Loss: 0.5970	Validation Loss: 0.6047
Epoch 1500: 	Training Loss: 0.5986	Validation Loss: 0.6057
Epoch 2000: 	Training Loss: 0.5984	Validation Loss: 0.6054
Epoch 2500: 	Training Loss: 0.5988	Validation Loss: 0.6058
Epoch 3000: 	Training Loss: 0.6031	Validation Loss: 0.6123
Early stopping at epoch 3498
Best validation loss: 0.6033
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6046	Validation Loss: 0.5768
Epoch 500: 	Training Loss: 0.6046	Validation Loss: 0.5824
Epoch 1000: 	Training Loss: 0.6053	Validation Loss: 0.5793
Epoch 1500: 	Training Loss: 0.6044	Validation Loss: 0.5765
Epoch 2000: 	Training Loss: 0.6595	Validation Loss: 0.6443
Epoch 2500: 	Training Loss: 0.6069	Validation Loss: 0.5807
Early stopping at epoch 2505
Best validation loss: 0.5748
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5942	Validation Loss: 0.6220
Epoch 500: 	Training Loss: 0.5937	Validation Loss: 0.6217
Epoch 1000: 	Training Loss: 0.6230	Validation Loss: 0.6343
Epoch 1500: 	Training Loss: 0.5926	Validation Loss: 0.6217
Epoch 2000: 	Training Loss: 0.5964	Validation Loss: 0.6253
Epoch 2500: 	Training Loss: 0.5949	Validation Loss: 0.6256
Epoch 3000: 	Training Loss: 0.6321	Validation Loss: 0.6562
Early stopping at epoch 3170
Best validation loss: 0.6204
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5969	Validation Loss: 0.6105
Epoch 500: 	Training Loss: 0.5968	Validation Loss: 0.6114
Epoch 1000: 	Training Loss: 0.6353	Validation Loss: 0.6503
Epoch 1500: 	Training Loss: 0.5976	Validation Loss: 0.6121
Epoch 2000: 	Training Loss: 0.5996	Validation Loss: 0.6144
Epoch 2500: 	Training Loss: 0.6118	Validation Loss: 0.6682
Epoch 3000: 	Training Loss: 0.5988	Validation Loss: 0.6131
Epoch 3500: 	Training Loss: 0.5975	Validation Loss: 0.6137
Epoch 4000: 	Training Loss: 0.5976	Validation Loss: 0.6112
Epoch 4500: 	Training Loss: 0.5973	Validation Loss: 0.6109
Early stopping at epoch 4764
Best validation loss: 0.6068
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/GQNN_10-10-10_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_08_20_15_39_951513/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u14>
Subject: Job 126381409: <GQNNx10x10x10-3-0> in cluster <Janelia> Done

Job <GQNNx10x10x10-3-0> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Sat Oct  8 20:15:31 2022
Job was executed on host(s) <e10u14>, in queue <local>, as user <mohantas> in cluster <Janelia> at Sat Oct  8 20:15:34 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Sat Oct  8 20:15:34 2022
Terminated at Sun Oct  9 20:00:30 2022
Results reported at Sun Oct  9 20:00:30 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_mohanta.py --agent GQNN --hidden_state_sizes 10 10 10 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric no --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   169791.64 sec.
    Max Memory :                                 331 MB
    Average Memory :                             260.11 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15029.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   85503 sec.
    Turnaround time :                            85499 sec.

The output (if any) is above this job summary.

