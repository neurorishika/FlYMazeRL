
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_reward_set.csv
Model: GQNN_5-5_relu_acceptreject_symmetric_qp_no-punishment_2022_10_04_02_25_23_590103
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6981	Validation Loss: 0.6947
Epoch 500: 	Training Loss: 0.6270	Validation Loss: 0.6315
Epoch 1000: 	Training Loss: 0.6297	Validation Loss: 0.6356
Epoch 1500: 	Training Loss: 0.6281	Validation Loss: 0.6361
Epoch 2000: 	Training Loss: 0.6930	Validation Loss: 0.6930
Epoch 2500: 	Training Loss: 0.6929	Validation Loss: 0.6929
Epoch 3000: 	Training Loss: 0.6272	Validation Loss: 0.6298
Epoch 3500: 	Training Loss: 0.6270	Validation Loss: 0.6315
Epoch 4000: 	Training Loss: 0.6276	Validation Loss: 0.6327
Epoch 4500: 	Training Loss: 0.6285	Validation Loss: 0.6486
Epoch 5000: 	Training Loss: 0.6249	Validation Loss: 0.6329
Early stopping at epoch 5134
Best validation loss: 0.6278
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6358	Validation Loss: 0.5991
Epoch 500: 	Training Loss: 0.6395	Validation Loss: 0.6146
Epoch 1000: 	Training Loss: 0.6363	Validation Loss: 0.6101
Epoch 1500: 	Training Loss: 0.6932	Validation Loss: 0.6932
Epoch 2000: 	Training Loss: 0.6368	Validation Loss: 0.6180
Epoch 2500: 	Training Loss: 0.6337	Validation Loss: 0.6046
Early stopping at epoch 2555
Best validation loss: 0.5967
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6359	Validation Loss: 0.6076
Epoch 500: 	Training Loss: 0.6328	Validation Loss: 0.6080
Epoch 1000: 	Training Loss: 0.6357	Validation Loss: 0.6107
Epoch 1500: 	Training Loss: 0.6311	Validation Loss: 0.6099
Epoch 2000: 	Training Loss: 0.6374	Validation Loss: 0.6104
Epoch 2500: 	Training Loss: 0.6342	Validation Loss: 0.6291
Epoch 3000: 	Training Loss: 0.6328	Validation Loss: 0.6147
Early stopping at epoch 3285
Best validation loss: 0.6053
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6177	Validation Loss: 0.6835
Epoch 500: 	Training Loss: 0.6153	Validation Loss: 0.6781
Epoch 1000: 	Training Loss: 0.6119	Validation Loss: 0.6751
Epoch 1500: 	Training Loss: 0.6139	Validation Loss: 0.6738
Epoch 2000: 	Training Loss: 0.6216	Validation Loss: 0.6767
Epoch 2500: 	Training Loss: 0.6188	Validation Loss: 0.6766
Epoch 3000: 	Training Loss: 0.6169	Validation Loss: 0.6754
Early stopping at epoch 3236
Best validation loss: 0.6696
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6279	Validation Loss: 0.6225
Epoch 500: 	Training Loss: 0.6259	Validation Loss: 0.6246
Epoch 1000: 	Training Loss: 0.6314	Validation Loss: 0.6300
Epoch 1500: 	Training Loss: 0.6314	Validation Loss: 0.6286
Epoch 2000: 	Training Loss: 0.6248	Validation Loss: 0.6217
Epoch 2500: 	Training Loss: 0.6249	Validation Loss: 0.6219
Epoch 3000: 	Training Loss: 0.6272	Validation Loss: 0.6256
Epoch 3500: 	Training Loss: 0.6286	Validation Loss: 0.6329
Epoch 4000: 	Training Loss: 0.6271	Validation Loss: 0.6232
Early stopping at epoch 4233
Best validation loss: 0.6193
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/GQNN_5-5_relu_acceptreject_symmetric_qp_no-punishment_2022_10_04_02_25_23_590103/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u27>
Subject: Job 126235728: <GQNNx5x5-1-1> in cluster <Janelia> Done

Job <GQNNx5x5-1-1> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Tue Oct  4 02:24:56 2022
Job was executed on host(s) <e10u27>, in queue <local>, as user <mohantas> in cluster <Janelia> at Tue Oct  4 02:24:59 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Tue Oct  4 02:24:59 2022
Terminated at Tue Oct  4 09:56:30 2022
Results reported at Tue Oct  4 09:56:30 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_rajagopalan.py --agent GQNN --hidden_state_sizes 5 5 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric yes --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   53900.39 sec.
    Max Memory :                                 260 MB
    Average Memory :                             244.00 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15100.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   27092 sec.
    Turnaround time :                            27094 sec.

The output (if any) is above this job summary.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_reward_set.csv
Model: GQNN_5-5_relu_acceptreject_symmetric_qp_no-punishment_2022_10_08_20_15_19_609461
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6819	Validation Loss: 0.6398
Epoch 500: 	Training Loss: 0.6067	Validation Loss: 0.5739
Epoch 1000: 	Training Loss: 0.6057	Validation Loss: 0.5736
Epoch 1500: 	Training Loss: 0.6066	Validation Loss: 0.5731
Epoch 2000: 	Training Loss: 0.6061	Validation Loss: 0.5736
Epoch 2500: 	Training Loss: 0.6062	Validation Loss: 0.5733
Epoch 3000: 	Training Loss: 0.6060	Validation Loss: 0.5726
Epoch 3500: 	Training Loss: 0.6060	Validation Loss: 0.5729
Epoch 4000: 	Training Loss: 0.6060	Validation Loss: 0.5731
Early stopping at epoch 4073
Best validation loss: 0.5721
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6038	Validation Loss: 0.5883
Epoch 500: 	Training Loss: 0.6029	Validation Loss: 0.5851
Epoch 1000: 	Training Loss: 0.6048	Validation Loss: 0.5940
Epoch 1500: 	Training Loss: 0.6028	Validation Loss: 0.5849
Epoch 2000: 	Training Loss: 0.6024	Validation Loss: 0.5858
Epoch 2500: 	Training Loss: 0.6021	Validation Loss: 0.5862
Epoch 3000: 	Training Loss: 0.6025	Validation Loss: 0.5870
Epoch 3500: 	Training Loss: 0.6023	Validation Loss: 0.5860
Early stopping at epoch 3942
Best validation loss: 0.5829
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6029	Validation Loss: 0.5862
Epoch 500: 	Training Loss: 0.6021	Validation Loss: 0.5860
Epoch 1000: 	Training Loss: 0.6025	Validation Loss: 0.5862
Epoch 1500: 	Training Loss: 0.6014	Validation Loss: 0.5863
Epoch 2000: 	Training Loss: 0.6028	Validation Loss: 0.5864
Epoch 2500: 	Training Loss: 0.6020	Validation Loss: 0.5873
Early stopping at epoch 2516
Best validation loss: 0.5850
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6022	Validation Loss: 0.5856
Epoch 500: 	Training Loss: 0.6024	Validation Loss: 0.5866
Epoch 1000: 	Training Loss: 0.6027	Validation Loss: 0.5861
Epoch 1500: 	Training Loss: 0.6020	Validation Loss: 0.5862
Epoch 2000: 	Training Loss: 0.6104	Validation Loss: 0.5914
Epoch 2500: 	Training Loss: 0.6032	Validation Loss: 0.5889
Early stopping at epoch 2501
Best validation loss: 0.5854
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6037	Validation Loss: 0.5823
Epoch 500: 	Training Loss: 0.6033	Validation Loss: 0.5854
Epoch 1000: 	Training Loss: 0.6041	Validation Loss: 0.5804
Epoch 1500: 	Training Loss: 0.6045	Validation Loss: 0.5805
Epoch 2000: 	Training Loss: 0.6056	Validation Loss: 0.5827
Epoch 2500: 	Training Loss: 0.6032	Validation Loss: 0.5807
Early stopping at epoch 2702
Best validation loss: 0.5782
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/GQNN_5-5_relu_acceptreject_symmetric_qp_no-punishment_2022_10_08_20_15_19_609461/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u18>
Subject: Job 126381359: <GQNNx5x5-1-1> in cluster <Janelia> Done

Job <GQNNx5x5-1-1> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Sat Oct  8 20:14:57 2022
Job was executed on host(s) <e10u18>, in queue <local>, as user <mohantas> in cluster <Janelia> at Sat Oct  8 20:15:00 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Sat Oct  8 20:15:00 2022
Terminated at Mon Oct 10 00:15:45 2022
Results reported at Mon Oct 10 00:15:45 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_mohanta.py --agent GQNN --hidden_state_sizes 5 5 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric yes --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   200304.08 sec.
    Max Memory :                                 323 MB
    Average Memory :                             259.66 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15037.00 MB
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                14
    Run time :                                   100848 sec.
    Turnaround time :                            100848 sec.

The output (if any) is above this job summary.

