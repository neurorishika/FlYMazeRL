
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_reward_set.csv
Model: GQNN_10-10-10_relu_acceptreject_symmetric_qp_no-punishment_2022_10_04_02_25_11_418153
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6887	Validation Loss: 0.6795
Epoch 500: 	Training Loss: 0.6405	Validation Loss: 0.5951
Epoch 1000: 	Training Loss: 0.6397	Validation Loss: 0.5988
Epoch 1500: 	Training Loss: 0.6415	Validation Loss: 0.5982
Epoch 2000: 	Training Loss: 0.6387	Validation Loss: 0.5991
Epoch 2500: 	Training Loss: 0.6508	Validation Loss: 0.6072
Early stopping at epoch 2985
Best validation loss: 0.5903
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6356	Validation Loss: 0.6345
Epoch 500: 	Training Loss: 0.6805	Validation Loss: 0.6243
Epoch 1000: 	Training Loss: 0.6351	Validation Loss: 0.6253
Epoch 1500: 	Training Loss: 0.6311	Validation Loss: 0.6232
Epoch 2000: 	Training Loss: 0.6296	Validation Loss: 0.6241
Epoch 2500: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 3000: 	Training Loss: 0.6428	Validation Loss: 0.6300
Epoch 3500: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 4000: 	Training Loss: 0.6306	Validation Loss: 0.6216
Epoch 4500: 	Training Loss: 0.6573	Validation Loss: 0.6489
Early stopping at epoch 4623
Best validation loss: 0.6152
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6240	Validation Loss: 0.6447
Epoch 500: 	Training Loss: 0.6931	Validation Loss: 0.6928
Epoch 1000: 	Training Loss: 0.6931	Validation Loss: 0.6927
Epoch 1500: 	Training Loss: 0.6931	Validation Loss: 0.6926
Epoch 2000: 	Training Loss: 0.6931	Validation Loss: 0.6926
Epoch 2500: 	Training Loss: 0.6931	Validation Loss: 0.6927
Early stopping at epoch 2500
Best validation loss: 0.6447
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6275	Validation Loss: 0.6362
Epoch 500: 	Training Loss: 0.6533	Validation Loss: 0.6616
Epoch 1000: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 1500: 	Training Loss: 0.6924	Validation Loss: 0.6942
Epoch 2000: 	Training Loss: 0.6924	Validation Loss: 0.6942
Epoch 2500: 	Training Loss: 0.6924	Validation Loss: 0.6942
Early stopping at epoch 2500
Best validation loss: 0.6362
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6280	Validation Loss: 0.6341
Epoch 500: 	Training Loss: 0.6312	Validation Loss: 0.6475
Epoch 1000: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 1500: 	Training Loss: 0.6933	Validation Loss: 0.6932
Epoch 2000: 	Training Loss: 0.6301	Validation Loss: 0.6418
Epoch 2500: 	Training Loss: 0.6263	Validation Loss: 0.6405
Epoch 3000: 	Training Loss: 0.6263	Validation Loss: 0.6399
Epoch 3500: 	Training Loss: 0.6272	Validation Loss: 0.6417
Early stopping at epoch 3940
Best validation loss: 0.6307
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/GQNN_10-10-10_relu_acceptreject_symmetric_qp_no-punishment_2022_10_04_02_25_11_418153/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u21>
Subject: Job 126235784: <GQNNx10x10x10-3-1> in cluster <Janelia> Done

Job <GQNNx10x10x10-3-1> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Tue Oct  4 02:25:04 2022
Job was executed on host(s) <e10u21>, in queue <local>, as user <mohantas> in cluster <Janelia> at Tue Oct  4 02:25:04 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Tue Oct  4 02:25:04 2022
Terminated at Tue Oct  4 10:43:11 2022
Results reported at Tue Oct  4 10:43:11 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_rajagopalan.py --agent GQNN --hidden_state_sizes 10 10 10 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric yes --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   59537.14 sec.
    Max Memory :                                 266 MB
    Average Memory :                             250.83 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15094.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   29887 sec.
    Turnaround time :                            29887 sec.

The output (if any) is above this job summary.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_reward_set.csv
Model: GQNN_10-10-10_relu_acceptreject_symmetric_qp_no-punishment_2022_10_08_20_15_19_609469
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6680	Validation Loss: 0.6427
Epoch 500: 	Training Loss: 0.6103	Validation Loss: 0.6118
Epoch 1000: 	Training Loss: 0.5991	Validation Loss: 0.6021
Epoch 1500: 	Training Loss: 0.6000	Validation Loss: 0.6039
Epoch 2000: 	Training Loss: 0.5989	Validation Loss: 0.6017
Epoch 2500: 	Training Loss: 0.6001	Validation Loss: 0.6054
Epoch 3000: 	Training Loss: 0.5982	Validation Loss: 0.6018
Early stopping at epoch 3310
Best validation loss: 0.6003
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5933	Validation Loss: 0.6303
Epoch 500: 	Training Loss: 0.5919	Validation Loss: 0.6287
Epoch 1000: 	Training Loss: 0.5924	Validation Loss: 0.6293
Epoch 1500: 	Training Loss: 0.5929	Validation Loss: 0.6299
Epoch 2000: 	Training Loss: 0.5921	Validation Loss: 0.6295
Epoch 2500: 	Training Loss: 0.5924	Validation Loss: 0.6292
Early stopping at epoch 2683
Best validation loss: 0.6271
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6068	Validation Loss: 0.5761
Epoch 500: 	Training Loss: 0.6204	Validation Loss: 0.5866
Epoch 1000: 	Training Loss: 0.6333	Validation Loss: 0.6003
Epoch 1500: 	Training Loss: 0.6064	Validation Loss: 0.5778
Epoch 2000: 	Training Loss: 0.6057	Validation Loss: 0.5771
Epoch 2500: 	Training Loss: 0.6068	Validation Loss: 0.5800
Epoch 3000: 	Training Loss: 0.6062	Validation Loss: 0.5779
Epoch 3500: 	Training Loss: 0.6073	Validation Loss: 0.5779
Epoch 4000: 	Training Loss: 0.6062	Validation Loss: 0.5770
Epoch 4500: 	Training Loss: 0.6064	Validation Loss: 0.5802
Epoch 5000: 	Training Loss: 0.6050	Validation Loss: 0.5763
Epoch 5500: 	Training Loss: 0.6073	Validation Loss: 0.5765
Epoch 6000: 	Training Loss: 0.6059	Validation Loss: 0.5767
Early stopping at epoch 6457
Best validation loss: 0.5751
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5947	Validation Loss: 0.6225
Epoch 500: 	Training Loss: 0.5944	Validation Loss: 0.6223
Epoch 1000: 	Training Loss: 0.6001	Validation Loss: 0.6289
Epoch 1500: 	Training Loss: 0.5945	Validation Loss: 0.6225
Epoch 2000: 	Training Loss: 0.5956	Validation Loss: 0.6223
Epoch 2500: 	Training Loss: 0.5937	Validation Loss: 0.6221
Epoch 3000: 	Training Loss: 0.5932	Validation Loss: 0.6213
Epoch 3500: 	Training Loss: 0.5939	Validation Loss: 0.6231
Epoch 4000: 	Training Loss: 0.6041	Validation Loss: 0.6359
Epoch 4500: 	Training Loss: 0.5960	Validation Loss: 0.6225
Early stopping at epoch 4576
Best validation loss: 0.6201
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6033	Validation Loss: 0.5858
Epoch 500: 	Training Loss: 0.6040	Validation Loss: 0.5873
Epoch 1000: 	Training Loss: 0.6052	Validation Loss: 0.5876
Epoch 1500: 	Training Loss: 0.6039	Validation Loss: 0.5865
Epoch 2000: 	Training Loss: 0.6033	Validation Loss: 0.5868
Epoch 2500: 	Training Loss: 0.6029	Validation Loss: 0.5869
Early stopping at epoch 2740
Best validation loss: 0.5844
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/GQNN_10-10-10_relu_acceptreject_symmetric_qp_no-punishment_2022_10_08_20_15_19_609469/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u18>
Subject: Job 126381373: <GQNNx10x10x10-3-1> in cluster <Janelia> Done

Job <GQNNx10x10x10-3-1> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Sat Oct  8 20:15:05 2022
Job was executed on host(s) <e10u18>, in queue <local>, as user <mohantas> in cluster <Janelia> at Sat Oct  8 20:15:10 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Sat Oct  8 20:15:10 2022
Terminated at Mon Oct 10 12:46:43 2022
Results reported at Mon Oct 10 12:46:43 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_mohanta.py --agent GQNN --hidden_state_sizes 10 10 10 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric yes --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   289704.25 sec.
    Max Memory :                                 360 MB
    Average Memory :                             268.77 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15000.00 MB
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                14
    Run time :                                   145904 sec.
    Turnaround time :                            145898 sec.

The output (if any) is above this job summary.

