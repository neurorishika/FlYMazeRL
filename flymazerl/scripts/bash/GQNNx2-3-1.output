
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_reward_set.csv
Model: GQNN_2_relu_acceptreject_symmetric_qp_no-punishment_2022_10_04_02_24_58_130444
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6934	Validation Loss: 0.6928
Epoch 500: 	Training Loss: 0.6392	Validation Loss: 0.6019
Epoch 1000: 	Training Loss: 0.6388	Validation Loss: 0.6017
Epoch 1500: 	Training Loss: 0.6387	Validation Loss: 0.6021
Epoch 2000: 	Training Loss: 0.6390	Validation Loss: 0.6020
Epoch 2500: 	Training Loss: 0.6387	Validation Loss: 0.6022
Early stopping at epoch 2722
Best validation loss: 0.6005
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6256	Validation Loss: 0.6514
Epoch 500: 	Training Loss: 0.6255	Validation Loss: 0.6506
Epoch 1000: 	Training Loss: 0.6249	Validation Loss: 0.6503
Epoch 1500: 	Training Loss: 0.6247	Validation Loss: 0.6505
Epoch 2000: 	Training Loss: 0.6248	Validation Loss: 0.6508
Epoch 2500: 	Training Loss: 0.6243	Validation Loss: 0.6506
Epoch 3000: 	Training Loss: 0.6242	Validation Loss: 0.6521
Epoch 3500: 	Training Loss: 0.6233	Validation Loss: 0.6548
Epoch 4000: 	Training Loss: 0.6230	Validation Loss: 0.6543
Early stopping at epoch 4278
Best validation loss: 0.6496
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6299	Validation Loss: 0.6392
Epoch 500: 	Training Loss: 0.6261	Validation Loss: 0.6390
Epoch 1000: 	Training Loss: 0.6255	Validation Loss: 0.6389
Epoch 1500: 	Training Loss: 0.6255	Validation Loss: 0.6389
Epoch 2000: 	Training Loss: 0.6266	Validation Loss: 0.6411
Epoch 2500: 	Training Loss: 0.6252	Validation Loss: 0.6387
Early stopping at epoch 2924
Best validation loss: 0.6375
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6291	Validation Loss: 0.6329
Epoch 500: 	Training Loss: 0.6269	Validation Loss: 0.6367
Epoch 1000: 	Training Loss: 0.6265	Validation Loss: 0.6372
Epoch 1500: 	Training Loss: 0.6265	Validation Loss: 0.6372
Epoch 2000: 	Training Loss: 0.6263	Validation Loss: 0.6384
Epoch 2500: 	Training Loss: 0.6270	Validation Loss: 0.6374
Early stopping at epoch 2500
Best validation loss: 0.6329
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6203	Validation Loss: 0.6621
Epoch 500: 	Training Loss: 0.6191	Validation Loss: 0.6636
Epoch 1000: 	Training Loss: 0.6186	Validation Loss: 0.6637
Epoch 1500: 	Training Loss: 0.6187	Validation Loss: 0.6649
Epoch 2000: 	Training Loss: 0.6190	Validation Loss: 0.6637
Epoch 2500: 	Training Loss: 0.6187	Validation Loss: 0.6650
Epoch 3000: 	Training Loss: 0.6181	Validation Loss: 0.6643
Early stopping at epoch 3390
Best validation loss: 0.6603
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/GQNN_2_relu_acceptreject_symmetric_qp_no-punishment_2022_10_04_02_24_58_130444/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u04>
Subject: Job 126235668: <GQNNx2-3-1> in cluster <Janelia> Done

Job <GQNNx2-3-1> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Tue Oct  4 02:24:49 2022
Job was executed on host(s) <e10u04>, in queue <local>, as user <mohantas> in cluster <Janelia> at Tue Oct  4 02:24:49 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Tue Oct  4 02:24:49 2022
Terminated at Tue Oct  4 07:43:18 2022
Results reported at Tue Oct  4 07:43:18 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_rajagopalan.py --agent GQNN --hidden_state_sizes 2 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric yes --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   38070.38 sec.
    Max Memory :                                 260 MB
    Average Memory :                             242.76 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15100.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   19109 sec.
    Turnaround time :                            19109 sec.

The output (if any) is above this job summary.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_reward_set.csv
Model: GQNN_2_relu_acceptreject_symmetric_qp_no-punishment_2022_10_08_20_14_53_949654
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6688	Validation Loss: 0.6600
Epoch 500: 	Training Loss: 0.5986	Validation Loss: 0.6069
Epoch 1000: 	Training Loss: 0.5989	Validation Loss: 0.6078
Epoch 1500: 	Training Loss: 0.5985	Validation Loss: 0.6070
Epoch 2000: 	Training Loss: 0.5994	Validation Loss: 0.6072
Epoch 2500: 	Training Loss: 0.5985	Validation Loss: 0.6068
Epoch 3000: 	Training Loss: 0.5988	Validation Loss: 0.6071
Epoch 3500: 	Training Loss: 0.5988	Validation Loss: 0.6064
Epoch 4000: 	Training Loss: 0.5987	Validation Loss: 0.6064
Epoch 4500: 	Training Loss: 0.5983	Validation Loss: 0.6062
Epoch 5000: 	Training Loss: 0.5983	Validation Loss: 0.6063
Epoch 5500: 	Training Loss: 0.5983	Validation Loss: 0.6064
Epoch 6000: 	Training Loss: 0.5991	Validation Loss: 0.6064
Epoch 6500: 	Training Loss: 0.5981	Validation Loss: 0.6062
Epoch 7000: 	Training Loss: 0.5983	Validation Loss: 0.6064
Early stopping at epoch 7120
Best validation loss: 0.6056
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6115	Validation Loss: 0.5570
Epoch 500: 	Training Loss: 0.6111	Validation Loss: 0.5577
Epoch 1000: 	Training Loss: 0.6106	Validation Loss: 0.5577
Epoch 1500: 	Training Loss: 0.6108	Validation Loss: 0.5574
Epoch 2000: 	Training Loss: 0.6109	Validation Loss: 0.5591
Epoch 2500: 	Training Loss: 0.6107	Validation Loss: 0.5572
Early stopping at epoch 2500
Best validation loss: 0.5570
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6031	Validation Loss: 0.5873
Epoch 500: 	Training Loss: 0.6027	Validation Loss: 0.5890
Epoch 1000: 	Training Loss: 0.6029	Validation Loss: 0.5887
Epoch 1500: 	Training Loss: 0.6031	Validation Loss: 0.5940
Epoch 2000: 	Training Loss: 0.6028	Validation Loss: 0.5878
Epoch 2500: 	Training Loss: 0.6033	Validation Loss: 0.5888
Early stopping at epoch 2514
Best validation loss: 0.5869
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6093	Validation Loss: 0.5675
Epoch 500: 	Training Loss: 0.6090	Validation Loss: 0.5651
Epoch 1000: 	Training Loss: 0.6092	Validation Loss: 0.5647
Epoch 1500: 	Training Loss: 0.6090	Validation Loss: 0.5658
Epoch 2000: 	Training Loss: 0.6086	Validation Loss: 0.5690
Epoch 2500: 	Training Loss: 0.6090	Validation Loss: 0.5642
Epoch 3000: 	Training Loss: 0.6090	Validation Loss: 0.5661
Early stopping at epoch 3027
Best validation loss: 0.5630
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6094	Validation Loss: 0.5652
Epoch 500: 	Training Loss: 0.6097	Validation Loss: 0.5633
Epoch 1000: 	Training Loss: 0.6104	Validation Loss: 0.5633
Epoch 1500: 	Training Loss: 0.6101	Validation Loss: 0.5641
Epoch 2000: 	Training Loss: 0.6101	Validation Loss: 0.5627
Epoch 2500: 	Training Loss: 0.6102	Validation Loss: 0.5624
Early stopping at epoch 2536
Best validation loss: 0.5620
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/GQNN_2_relu_acceptreject_symmetric_qp_no-punishment_2022_10_08_20_14_53_949654/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u13>
Subject: Job 126381345: <GQNNx2-3-1> in cluster <Janelia> Done

Job <GQNNx2-3-1> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Sat Oct  8 20:14:50 2022
Job was executed on host(s) <e10u13>, in queue <local>, as user <mohantas> in cluster <Janelia> at Sat Oct  8 20:14:50 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Sat Oct  8 20:14:50 2022
Terminated at Sun Oct  9 19:07:59 2022
Results reported at Sun Oct  9 19:07:59 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_mohanta.py --agent GQNN --hidden_state_sizes 2 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric yes --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   163562.05 sec.
    Max Memory :                                 342 MB
    Average Memory :                             254.95 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15018.00 MB
    Max Swap :                                   6 MB
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   82388 sec.
    Turnaround time :                            82389 sec.

The output (if any) is above this job summary.

