
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_reward_set.csv
Model: GQNN_10-10-10_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_04_02_25_35_457312
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6876	Validation Loss: 0.6729
Epoch 500: 	Training Loss: 0.6698	Validation Loss: 0.6868
Epoch 1000: 	Training Loss: 0.6414	Validation Loss: 0.6154
Epoch 1500: 	Training Loss: 0.6363	Validation Loss: 0.6186
Epoch 2000: 	Training Loss: 0.6420	Validation Loss: 0.6248
Epoch 2500: 	Training Loss: 0.6401	Validation Loss: 0.6172
Early stopping at epoch 2734
Best validation loss: 0.6080
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6206	Validation Loss: 0.6547
Epoch 500: 	Training Loss: 0.6751	Validation Loss: 0.6810
Epoch 1000: 	Training Loss: 0.6751	Validation Loss: 0.6788
Epoch 1500: 	Training Loss: 0.6742	Validation Loss: 0.6797
Epoch 2000: 	Training Loss: 0.6728	Validation Loss: 0.6802
Epoch 2500: 	Training Loss: 0.6292	Validation Loss: 0.6740
Early stopping at epoch 2500
Best validation loss: 0.6547
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6257	Validation Loss: 0.6445
Epoch 500: 	Training Loss: 0.6293	Validation Loss: 0.6489
Epoch 1000: 	Training Loss: 0.6259	Validation Loss: 0.6468
Epoch 1500: 	Training Loss: 0.6497	Validation Loss: 0.6528
Epoch 2000: 	Training Loss: 0.6314	Validation Loss: 0.6466
Epoch 2500: 	Training Loss: 0.6298	Validation Loss: 0.6464
Early stopping at epoch 2504
Best validation loss: 0.6365
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6581	Validation Loss: 0.6261
Epoch 500: 	Training Loss: 0.6477	Validation Loss: 0.6418
Epoch 1000: 	Training Loss: 0.6389	Validation Loss: 0.6337
Epoch 1500: 	Training Loss: 0.6394	Validation Loss: 0.6336
Epoch 2000: 	Training Loss: 0.6580	Validation Loss: 0.6596
Epoch 2500: 	Training Loss: 0.6388	Validation Loss: 0.6335
Early stopping at epoch 2507
Best validation loss: 0.6187
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6256	Validation Loss: 0.6630
Epoch 500: 	Training Loss: 0.6244	Validation Loss: 0.6670
Epoch 1000: 	Training Loss: 0.6445	Validation Loss: 0.7040
Epoch 1500: 	Training Loss: 0.6833	Validation Loss: 0.7240
Epoch 2000: 	Training Loss: 0.6288	Validation Loss: 0.6674
Epoch 2500: 	Training Loss: 0.6278	Validation Loss: 0.6621
Early stopping at epoch 2509
Best validation loss: 0.6550
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/GQNN_10-10-10_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_04_02_25_35_457312/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u27>
Subject: Job 126236026: <GQNNx10x10x10-0-0> in cluster <Janelia> Done

Job <GQNNx10x10x10-0-0> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Tue Oct  4 02:25:30 2022
Job was executed on host(s) <e10u27>, in queue <local>, as user <mohantas> in cluster <Janelia> at Tue Oct  4 02:25:31 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Tue Oct  4 02:25:31 2022
Terminated at Tue Oct  4 07:00:53 2022
Results reported at Tue Oct  4 07:00:53 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_rajagopalan.py --agent GQNN --hidden_state_sizes 10 10 10 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric no --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   32870.92 sec.
    Max Memory :                                 256 MB
    Average Memory :                             241.95 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15104.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   16521 sec.
    Turnaround time :                            16523 sec.

The output (if any) is above this job summary.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_reward_set.csv
Model: GQNN_10-10-10_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_08_20_15_39_952058
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6697	Validation Loss: 0.6294
Epoch 500: 	Training Loss: 0.6084	Validation Loss: 0.5892
Epoch 1000: 	Training Loss: 0.6036	Validation Loss: 0.5897
Epoch 1500: 	Training Loss: 0.6015	Validation Loss: 0.5886
Epoch 2000: 	Training Loss: 0.6497	Validation Loss: 0.6062
Epoch 2500: 	Training Loss: nan	Validation Loss: nan
Epoch 3000: 	Training Loss: nan	Validation Loss: nan
Epoch 3500: 	Training Loss: nan	Validation Loss: nan
Early stopping at epoch 3559
Best validation loss: 0.5819
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6076	Validation Loss: 0.5760
Epoch 500: 	Training Loss: 0.6145	Validation Loss: 0.5795
Epoch 1000: 	Training Loss: 0.6044	Validation Loss: 0.5738
Epoch 1500: 	Training Loss: 0.6053	Validation Loss: 0.5771
Epoch 2000: 	Training Loss: 0.6059	Validation Loss: 0.5781
Epoch 2500: 	Training Loss: 0.6069	Validation Loss: 0.5776
Early stopping at epoch 2508
Best validation loss: 0.5734
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5968	Validation Loss: 0.6112
Epoch 500: 	Training Loss: 0.5973	Validation Loss: 0.6155
Epoch 1000: 	Training Loss: 0.6134	Validation Loss: 0.6181
Epoch 1500: 	Training Loss: 0.6052	Validation Loss: 0.6205
Epoch 2000: 	Training Loss: 0.5952	Validation Loss: 0.6171
Epoch 2500: 	Training Loss: 0.5977	Validation Loss: 0.6171
Early stopping at epoch 2501
Best validation loss: 0.6098
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5945	Validation Loss: 0.6334
Epoch 500: 	Training Loss: 0.5926	Validation Loss: 0.6366
Epoch 1000: 	Training Loss: 0.6355	Validation Loss: 0.6615
Epoch 1500: 	Training Loss: 0.6373	Validation Loss: 0.6698
Epoch 2000: 	Training Loss: 0.6421	Validation Loss: 0.6561
Epoch 2500: 	Training Loss: 0.6368	Validation Loss: 0.6597
Early stopping at epoch 2508
Best validation loss: 0.6306
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6060	Validation Loss: 0.5741
Epoch 500: 	Training Loss: 0.6082	Validation Loss: 0.5760
Epoch 1000: 	Training Loss: 0.6386	Validation Loss: 0.6221
Epoch 1500: 	Training Loss: 0.6167	Validation Loss: 0.5851
Epoch 2000: 	Training Loss: 0.6065	Validation Loss: 0.5768
Epoch 2500: 	Training Loss: 0.6081	Validation Loss: 0.5810
Early stopping at epoch 2506
Best validation loss: 0.5731
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/GQNN_10-10-10_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_08_20_15_39_952058/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u14>
Subject: Job 126381406: <GQNNx10x10x10-0-0> in cluster <Janelia> Done

Job <GQNNx10x10x10-0-0> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Sat Oct  8 20:15:29 2022
Job was executed on host(s) <e10u14>, in queue <local>, as user <mohantas> in cluster <Janelia> at Sat Oct  8 20:15:31 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Sat Oct  8 20:15:31 2022
Terminated at Sun Oct  9 16:18:08 2022
Results reported at Sun Oct  9 16:18:08 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_mohanta.py --agent GQNN --hidden_state_sizes 10 10 10 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric no --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   143265.06 sec.
    Max Memory :                                 298 MB
    Average Memory :                             250.75 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15062.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   72159 sec.
    Turnaround time :                            72159 sec.

The output (if any) is above this job summary.

