
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_reward_set.csv
Model: GQNN_5_relu_acceptreject_symmetric_qp_no-punishment_2022_10_04_02_25_14_618298
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6834	Validation Loss: 0.6843
Epoch 500: 	Training Loss: 0.6224	Validation Loss: 0.6603
Epoch 1000: 	Training Loss: 0.6220	Validation Loss: 0.6615
Epoch 1500: 	Training Loss: 0.6225	Validation Loss: 0.6602
Epoch 2000: 	Training Loss: 0.6212	Validation Loss: 0.6601
Epoch 2500: 	Training Loss: 0.6207	Validation Loss: 0.6606
Early stopping at epoch 2547
Best validation loss: 0.6567
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6298	Validation Loss: 0.6378
Epoch 500: 	Training Loss: 0.6268	Validation Loss: 0.6400
Epoch 1000: 	Training Loss: 0.6265	Validation Loss: 0.6406
Epoch 1500: 	Training Loss: 0.6265	Validation Loss: 0.6402
Epoch 2000: 	Training Loss: 0.6265	Validation Loss: 0.6409
Epoch 2500: 	Training Loss: 0.6256	Validation Loss: 0.6403
Early stopping at epoch 2500
Best validation loss: 0.6378
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6316	Validation Loss: 0.6328
Epoch 500: 	Training Loss: 0.6287	Validation Loss: 0.6317
Epoch 1000: 	Training Loss: 0.6273	Validation Loss: 0.6305
Epoch 1500: 	Training Loss: 0.6269	Validation Loss: 0.6319
Epoch 2000: 	Training Loss: 0.6268	Validation Loss: 0.6325
Epoch 2500: 	Training Loss: 0.6273	Validation Loss: 0.6324
Epoch 3000: 	Training Loss: 0.6268	Validation Loss: 0.6306
Epoch 3500: 	Training Loss: 0.6266	Validation Loss: 0.6306
Early stopping at epoch 3540
Best validation loss: 0.6279
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6322	Validation Loss: 0.6172
Epoch 500: 	Training Loss: 0.6307	Validation Loss: 0.6191
Epoch 1000: 	Training Loss: 0.6303	Validation Loss: 0.6192
Epoch 1500: 	Training Loss: 0.6301	Validation Loss: 0.6191
Epoch 2000: 	Training Loss: 0.6300	Validation Loss: 0.6190
Epoch 2500: 	Training Loss: 0.6298	Validation Loss: 0.6198
Early stopping at epoch 2500
Best validation loss: 0.6172
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6324	Validation Loss: 0.6128
Epoch 500: 	Training Loss: 0.6315	Validation Loss: 0.6180
Epoch 1000: 	Training Loss: 0.6306	Validation Loss: 0.6183
Epoch 1500: 	Training Loss: 0.6307	Validation Loss: 0.6199
Epoch 2000: 	Training Loss: 0.6308	Validation Loss: 0.6197
Epoch 2500: 	Training Loss: 0.6290	Validation Loss: 0.6214
Early stopping at epoch 2500
Best validation loss: 0.6128
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/GQNN_5_relu_acceptreject_symmetric_qp_no-punishment_2022_10_04_02_25_14_618298/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u14>
Subject: Job 126235673: <GQNNx5-2-1> in cluster <Janelia> Done

Job <GQNNx5-2-1> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Tue Oct  4 02:24:50 2022
Job was executed on host(s) <e10u14>, in queue <local>, as user <mohantas> in cluster <Janelia> at Tue Oct  4 02:24:52 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Tue Oct  4 02:24:52 2022
Terminated at Tue Oct  4 07:01:22 2022
Results reported at Tue Oct  4 07:01:22 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_rajagopalan.py --agent GQNN --hidden_state_sizes 5 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric yes --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   33024.01 sec.
    Max Memory :                                 259 MB
    Average Memory :                             246.71 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15101.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   16594 sec.
    Turnaround time :                            16592 sec.

The output (if any) is above this job summary.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_reward_set.csv
Model: GQNN_5_relu_acceptreject_symmetric_qp_no-punishment_2022_10_08_20_15_01_659092
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6904	Validation Loss: 0.6798
Epoch 500: 	Training Loss: 0.6020	Validation Loss: 0.5888
Epoch 1000: 	Training Loss: 0.6016	Validation Loss: 0.5873
Epoch 1500: 	Training Loss: 0.6020	Validation Loss: 0.5878
Epoch 2000: 	Training Loss: 0.6013	Validation Loss: 0.5874
Epoch 2500: 	Training Loss: 0.6019	Validation Loss: 0.5879
Epoch 3000: 	Training Loss: 0.6013	Validation Loss: 0.5893
Epoch 3500: 	Training Loss: 0.6015	Validation Loss: 0.5879
Epoch 4000: 	Training Loss: 0.6035	Validation Loss: 0.5873
Epoch 4500: 	Training Loss: 0.6017	Validation Loss: 0.5875
Epoch 5000: 	Training Loss: 0.6019	Validation Loss: 0.5868
Epoch 5500: 	Training Loss: 0.6017	Validation Loss: 0.5877
Epoch 6000: 	Training Loss: 0.6020	Validation Loss: 0.5869
Epoch 6500: 	Training Loss: 0.6012	Validation Loss: 0.5879
Epoch 7000: 	Training Loss: 0.6016	Validation Loss: 0.5875
Epoch 7500: 	Training Loss: 0.6022	Validation Loss: 0.5877
Early stopping at epoch 7788
Best validation loss: 0.5862
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5979	Validation Loss: 0.6035
Epoch 500: 	Training Loss: 0.5985	Validation Loss: 0.6034
Epoch 1000: 	Training Loss: 0.5978	Validation Loss: 0.6080
Epoch 1500: 	Training Loss: 0.6057	Validation Loss: 0.6085
Epoch 2000: 	Training Loss: 0.5977	Validation Loss: 0.6037
Epoch 2500: 	Training Loss: 0.5984	Validation Loss: 0.6034
Early stopping at epoch 2501
Best validation loss: 0.6021
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6008	Validation Loss: 0.5937
Epoch 500: 	Training Loss: 0.6004	Validation Loss: 0.5928
Epoch 1000: 	Training Loss: 0.6002	Validation Loss: 0.5918
Epoch 1500: 	Training Loss: 0.6001	Validation Loss: 0.5933
Epoch 2000: 	Training Loss: 0.6040	Validation Loss: 0.5931
Epoch 2500: 	Training Loss: 0.6003	Validation Loss: 0.5929
Epoch 3000: 	Training Loss: 0.6002	Validation Loss: 0.5916
Epoch 3500: 	Training Loss: 0.6005	Validation Loss: 0.5916
Early stopping at epoch 3852
Best validation loss: 0.5912
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5895	Validation Loss: 0.6339
Epoch 500: 	Training Loss: 0.6058	Validation Loss: 0.6561
Epoch 1000: 	Training Loss: 0.5894	Validation Loss: 0.6364
Epoch 1500: 	Training Loss: 0.5898	Validation Loss: 0.6349
Epoch 2000: 	Training Loss: 0.5904	Validation Loss: 0.6364
Epoch 2500: 	Training Loss: 0.5886	Validation Loss: 0.6361
Early stopping at epoch 2501
Best validation loss: 0.6335
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6064	Validation Loss: 0.5708
Epoch 500: 	Training Loss: 0.6055	Validation Loss: 0.5716
Epoch 1000: 	Training Loss: 0.6061	Validation Loss: 0.5712
Epoch 1500: 	Training Loss: 0.6054	Validation Loss: 0.5725
Epoch 2000: 	Training Loss: 0.6053	Validation Loss: 0.5713
Epoch 2500: 	Training Loss: 0.6053	Validation Loss: 0.5713
Early stopping at epoch 2589
Best validation loss: 0.5706
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/GQNN_5_relu_acceptreject_symmetric_qp_no-punishment_2022_10_08_20_15_01_659092/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u03>
Subject: Job 126381348: <GQNNx5-2-1> in cluster <Janelia> Done

Job <GQNNx5-2-1> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Sat Oct  8 20:14:52 2022
Job was executed on host(s) <e10u03>, in queue <local>, as user <mohantas> in cluster <Janelia> at Sat Oct  8 20:14:52 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Sat Oct  8 20:14:52 2022
Terminated at Mon Oct 10 10:27:31 2022
Results reported at Mon Oct 10 10:27:31 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_mohanta.py --agent GQNN --hidden_state_sizes 5 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric yes --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   272697.06 sec.
    Max Memory :                                 365 MB
    Average Memory :                             265.97 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               14995.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   137560 sec.
    Turnaround time :                            137559 sec.

The output (if any) is above this job summary.

