
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GRNNLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_reward_set.csv
Model: GRNN_1x3_RNN_acceptreject_asymmetric_qp_no-punishment_2022_10_04_02_17_35_300321
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6862	Validation Loss: 0.6879
Epoch 500: 	Training Loss: 0.6210	Validation Loss: 0.6384
Epoch 1000: 	Training Loss: 0.6240	Validation Loss: 0.6414
Epoch 1500: 	Training Loss: 0.6198	Validation Loss: 0.6399
Epoch 2000: 	Training Loss: 0.6202	Validation Loss: 0.6370
Epoch 2500: 	Training Loss: 0.6186	Validation Loss: 0.6374
Epoch 3000: 	Training Loss: 0.6203	Validation Loss: 0.6384
Epoch 3500: 	Training Loss: 0.6173	Validation Loss: 0.6402
Epoch 4000: 	Training Loss: 0.6192	Validation Loss: 0.6375
Epoch 4500: 	Training Loss: 0.6249	Validation Loss: 0.6419
Epoch 5000: 	Training Loss: 0.6404	Validation Loss: 0.6628
Epoch 5500: 	Training Loss: 0.6175	Validation Loss: 0.6451
Early stopping at epoch 5737
Best validation loss: 0.6345
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6872	Validation Loss: 0.6819
Epoch 500: 	Training Loss: 0.6341	Validation Loss: 0.5988
Epoch 1000: 	Training Loss: 0.6331	Validation Loss: 0.5997
Epoch 1500: 	Training Loss: 0.6316	Validation Loss: 0.6360
Epoch 2000: 	Training Loss: 0.6308	Validation Loss: 0.6367
Epoch 2500: 	Training Loss: 0.6341	Validation Loss: 0.5977
Early stopping at epoch 2679
Best validation loss: 0.5930
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6818	Validation Loss: 0.7086
Epoch 500: 	Training Loss: 0.6225	Validation Loss: 0.6464
Epoch 1000: 	Training Loss: 0.6203	Validation Loss: 0.6429
Epoch 1500: 	Training Loss: 0.6171	Validation Loss: 0.6445
Epoch 2000: 	Training Loss: 0.6175	Validation Loss: 0.6507
Epoch 2500: 	Training Loss: 0.6167	Validation Loss: 0.6427
Early stopping at epoch 2862
Best validation loss: 0.6375
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6995	Validation Loss: 0.6963
Epoch 500: 	Training Loss: 0.6308	Validation Loss: 0.6131
Epoch 1000: 	Training Loss: 0.6383	Validation Loss: 0.6202
Epoch 1500: 	Training Loss: 0.6288	Validation Loss: 0.6111
Epoch 2000: 	Training Loss: 0.6306	Validation Loss: 0.6165
Epoch 2500: 	Training Loss: 0.6289	Validation Loss: 0.6193
Epoch 3000: 	Training Loss: 0.6324	Validation Loss: 0.6167
Early stopping at epoch 3296
Best validation loss: 0.6090
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6861	Validation Loss: 0.6760
Epoch 500: 	Training Loss: 0.6246	Validation Loss: 0.6389
Epoch 1000: 	Training Loss: 0.6213	Validation Loss: 0.6409
Epoch 1500: 	Training Loss: 0.6261	Validation Loss: 0.6339
Epoch 2000: 	Training Loss: 0.6208	Validation Loss: 0.6417
Epoch 2500: 	Training Loss: 0.6224	Validation Loss: 0.6419
Epoch 3000: 	Training Loss: 0.6278	Validation Loss: 0.6350
Epoch 3500: 	Training Loss: 0.6304	Validation Loss: 0.6373
Epoch 4000: 	Training Loss: 0.6233	Validation Loss: 0.6424
Early stopping at epoch 4468
Best validation loss: 0.6304
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/GRNN_1x3_RNN_acceptreject_asymmetric_qp_no-punishment_2022_10_04_02_17_35_300321/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u12>
Subject: Job 126232893: <GRNNx3-1-0> in cluster <Janelia> Done

Job <GRNNx3-1-0> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Tue Oct  4 02:17:04 2022
Job was executed on host(s) <e10u12>, in queue <local>, as user <mohantas> in cluster <Janelia> at Tue Oct  4 02:17:04 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Tue Oct  4 02:17:04 2022
Terminated at Tue Oct  4 03:20:14 2022
Results reported at Tue Oct  4 03:20:14 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_rajagopalan.py --agent GRNN --num_reservoir 1 --reservoir_size 3 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric no --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   7469.73 sec.
    Max Memory :                                 247 MB
    Average Memory :                             229.63 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15113.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   3792 sec.
    Turnaround time :                            3790 sec.

The output (if any) is above this job summary.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GRNNLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_reward_set.csv
Model: GRNN_1x3_RNN_acceptreject_asymmetric_qp_no-punishment_2022_10_08_20_14_46_228686
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6764	Validation Loss: 0.6660
Epoch 500: 	Training Loss: 0.5972	Validation Loss: 0.5932
Epoch 1000: 	Training Loss: 0.5967	Validation Loss: 0.5944
Epoch 1500: 	Training Loss: 0.5984	Validation Loss: 0.5957
Epoch 2000: 	Training Loss: 0.5972	Validation Loss: 0.5928
Epoch 2500: 	Training Loss: 0.5970	Validation Loss: 0.5941
Early stopping at epoch 2672
Best validation loss: 0.5924
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6795	Validation Loss: 0.6819
Epoch 500: 	Training Loss: 0.5978	Validation Loss: 0.5903
Epoch 1000: 	Training Loss: 0.5970	Validation Loss: 0.5914
Epoch 1500: 	Training Loss: 0.5977	Validation Loss: 0.5955
Epoch 2000: 	Training Loss: 0.5971	Validation Loss: 0.5926
Epoch 2500: 	Training Loss: 0.6020	Validation Loss: 0.5976
Early stopping at epoch 2622
Best validation loss: 0.5890
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6880	Validation Loss: 0.6873
Epoch 500: 	Training Loss: 0.6018	Validation Loss: 0.5751
Epoch 1000: 	Training Loss: 0.6024	Validation Loss: 0.5763
Epoch 1500: 	Training Loss: 0.6029	Validation Loss: 0.5747
Epoch 2000: 	Training Loss: 0.6019	Validation Loss: 0.5751
Epoch 2500: 	Training Loss: 0.6017	Validation Loss: 0.5753
Epoch 3000: 	Training Loss: 0.6020	Validation Loss: 0.5778
Early stopping at epoch 3435
Best validation loss: 0.5733
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6772	Validation Loss: 0.6557
Epoch 500: 	Training Loss: 0.5974	Validation Loss: 0.5970
Epoch 1000: 	Training Loss: 0.5966	Validation Loss: 0.5976
Epoch 1500: 	Training Loss: 0.5962	Validation Loss: 0.5975
Epoch 2000: 	Training Loss: 0.5964	Validation Loss: 0.5977
Epoch 2500: 	Training Loss: 0.5962	Validation Loss: 0.5978
Early stopping at epoch 2806
Best validation loss: 0.5957
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6910	Validation Loss: 0.6880
Epoch 500: 	Training Loss: 0.6000	Validation Loss: 0.5891
Epoch 1000: 	Training Loss: 0.5990	Validation Loss: 0.5904
Epoch 1500: 	Training Loss: 0.6001	Validation Loss: 0.5904
Epoch 2000: 	Training Loss: 0.5999	Validation Loss: 0.5961
Epoch 2500: 	Training Loss: 0.6001	Validation Loss: 0.5926
Early stopping at epoch 2899
Best validation loss: 0.5884
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/GRNN_1x3_RNN_acceptreject_asymmetric_qp_no-punishment_2022_10_08_20_14_46_228686/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u13>
Subject: Job 126381323: <GRNNx3-1-0> in cluster <Janelia> Done

Job <GRNNx3-1-0> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Sat Oct  8 20:14:32 2022
Job was executed on host(s) <e10u13>, in queue <local>, as user <mohantas> in cluster <Janelia> at Sat Oct  8 20:14:33 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Sat Oct  8 20:14:33 2022
Terminated at Sat Oct  8 23:24:48 2022
Results reported at Sat Oct  8 23:24:48 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_mohanta.py --agent GRNN --num_reservoir 1 --reservoir_size 3 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric no --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   22293.03 sec.
    Max Memory :                                 300 MB
    Average Memory :                             249.24 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15060.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   11417 sec.
    Turnaround time :                            11416 sec.

The output (if any) is above this job summary.

