
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GRNNLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_reward_set.csv
Model: GRNN_1x3_RNN_acceptreject_symmetric_qp_no-punishment_2022_10_04_02_23_57_505490
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6927	Validation Loss: 0.6919
Epoch 500: 	Training Loss: 0.6224	Validation Loss: 0.6560
Epoch 1000: 	Training Loss: 0.6272	Validation Loss: 0.6581
Epoch 1500: 	Training Loss: 0.6329	Validation Loss: 0.6679
Epoch 2000: 	Training Loss: 0.6186	Validation Loss: 0.6484
Epoch 2500: 	Training Loss: 0.6441	Validation Loss: 0.6528
Epoch 3000: 	Training Loss: 0.6218	Validation Loss: 0.6508
Early stopping at epoch 3279
Best validation loss: 0.6445
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6881	Validation Loss: 0.6872
Epoch 500: 	Training Loss: 0.6151	Validation Loss: 0.6479
Epoch 1000: 	Training Loss: 0.6183	Validation Loss: 0.6481
Epoch 1500: 	Training Loss: 0.6216	Validation Loss: 0.6581
Epoch 2000: 	Training Loss: 0.6183	Validation Loss: 0.6566
Epoch 2500: 	Training Loss: 0.6181	Validation Loss: 0.6624
Epoch 3000: 	Training Loss: 0.6177	Validation Loss: 0.6568
Epoch 3500: 	Training Loss: 0.6166	Validation Loss: 0.6630
Early stopping at epoch 3558
Best validation loss: 0.6448
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6894	Validation Loss: 0.6867
Epoch 500: 	Training Loss: 0.6274	Validation Loss: 0.6225
Epoch 1000: 	Training Loss: 0.6228	Validation Loss: 0.6255
Epoch 1500: 	Training Loss: 0.6238	Validation Loss: 0.6282
Epoch 2000: 	Training Loss: 0.6217	Validation Loss: 0.6287
Epoch 2500: 	Training Loss: 0.6287	Validation Loss: 0.6244
Early stopping at epoch 2627
Best validation loss: 0.6200
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6835	Validation Loss: 0.6820
Epoch 500: 	Training Loss: 0.6275	Validation Loss: 0.6408
Epoch 1000: 	Training Loss: 0.6226	Validation Loss: 0.6341
Epoch 1500: 	Training Loss: 0.6218	Validation Loss: 0.6338
Epoch 2000: 	Training Loss: 0.6214	Validation Loss: 0.6340
Epoch 2500: 	Training Loss: 0.6215	Validation Loss: 0.6344
Early stopping at epoch 2642
Best validation loss: 0.6296
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6948	Validation Loss: 0.6919
Epoch 500: 	Training Loss: 0.6219	Validation Loss: 0.6453
Epoch 1000: 	Training Loss: 0.6255	Validation Loss: 0.6431
Epoch 1500: 	Training Loss: 0.6370	Validation Loss: 0.6460
Epoch 2000: 	Training Loss: 0.6367	Validation Loss: 0.6452
Epoch 2500: 	Training Loss: 0.6193	Validation Loss: 0.6468
Epoch 3000: 	Training Loss: 0.6194	Validation Loss: 0.6473
Epoch 3500: 	Training Loss: 0.6182	Validation Loss: 0.6480
Epoch 4000: 	Training Loss: 0.6284	Validation Loss: 0.6455
Early stopping at epoch 4173
Best validation loss: 0.6355
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/GRNN_1x3_RNN_acceptreject_symmetric_qp_no-punishment_2022_10_04_02_23_57_505490/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u18>
Subject: Job 126235154: <GRNNx3-3-1> in cluster <Janelia> Done

Job <GRNNx3-3-1> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Tue Oct  4 02:23:23 2022
Job was executed on host(s) <e10u18>, in queue <local>, as user <mohantas> in cluster <Janelia> at Tue Oct  4 02:23:38 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Tue Oct  4 02:23:38 2022
Terminated at Tue Oct  4 03:35:10 2022
Results reported at Tue Oct  4 03:35:10 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_rajagopalan.py --agent GRNN --num_reservoir 1 --reservoir_size 3 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric yes --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   8499.24 sec.
    Max Memory :                                 252 MB
    Average Memory :                             237.22 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15108.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   4309 sec.
    Turnaround time :                            4307 sec.

The output (if any) is above this job summary.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GRNNLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_reward_set.csv
Model: GRNN_1x3_RNN_acceptreject_symmetric_qp_no-punishment_2022_10_08_20_12_08_348428
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6882	Validation Loss: 0.6807
Epoch 500: 	Training Loss: 0.5961	Validation Loss: 0.6295
Epoch 1000: 	Training Loss: 0.5923	Validation Loss: 0.6250
Epoch 1500: 	Training Loss: 0.5924	Validation Loss: 0.6270
Epoch 2000: 	Training Loss: 0.5917	Validation Loss: 0.6246
Epoch 2500: 	Training Loss: 0.5984	Validation Loss: 0.6284
Early stopping at epoch 2618
Best validation loss: 0.6218
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6926	Validation Loss: 0.6839
Epoch 500: 	Training Loss: 0.6041	Validation Loss: 0.5750
Epoch 1000: 	Training Loss: 0.6035	Validation Loss: 0.5739
Epoch 1500: 	Training Loss: 0.6042	Validation Loss: 0.5743
Epoch 2000: 	Training Loss: 0.6077	Validation Loss: 0.5756
Epoch 2500: 	Training Loss: 0.6038	Validation Loss: 0.5752
Epoch 3000: 	Training Loss: 0.6035	Validation Loss: 0.5739
Epoch 3500: 	Training Loss: 0.6061	Validation Loss: 0.5722
Epoch 4000: 	Training Loss: 0.6050	Validation Loss: 0.5813
Epoch 4500: 	Training Loss: 0.6065	Validation Loss: 0.5738
Epoch 5000: 	Training Loss: 0.6080	Validation Loss: 0.5737
Epoch 5500: 	Training Loss: 0.6053	Validation Loss: 0.5741
Early stopping at epoch 5991
Best validation loss: 0.5712
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6885	Validation Loss: 0.6613
Epoch 500: 	Training Loss: 0.6076	Validation Loss: 0.5650
Epoch 1000: 	Training Loss: 0.6100	Validation Loss: 0.5659
Epoch 1500: 	Training Loss: 0.6066	Validation Loss: 0.5651
Epoch 2000: 	Training Loss: 0.6074	Validation Loss: 0.5642
Epoch 2500: 	Training Loss: 0.6089	Validation Loss: 0.5626
Epoch 3000: 	Training Loss: 0.6084	Validation Loss: 0.5636
Early stopping at epoch 3455
Best validation loss: 0.5600
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6835	Validation Loss: 0.6596
Epoch 500: 	Training Loss: 0.5988	Validation Loss: 0.5992
Epoch 1000: 	Training Loss: 0.5987	Validation Loss: 0.5989
Epoch 1500: 	Training Loss: 0.5985	Validation Loss: 0.5990
Epoch 2000: 	Training Loss: 0.5985	Validation Loss: 0.5998
Epoch 2500: 	Training Loss: 0.5988	Validation Loss: 0.6005
Epoch 3000: 	Training Loss: 0.5983	Validation Loss: 0.6007
Epoch 3500: 	Training Loss: 0.5986	Validation Loss: 0.6009
Epoch 4000: 	Training Loss: 0.5983	Validation Loss: 0.6015
Epoch 4500: 	Training Loss: 0.5986	Validation Loss: 0.6011
Epoch 5000: 	Training Loss: 0.5981	Validation Loss: 0.6014
Early stopping at epoch 5290
Best validation loss: 0.5968
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6799	Validation Loss: 0.6451
Epoch 500: 	Training Loss: 0.6057	Validation Loss: 0.5746
Epoch 1000: 	Training Loss: 0.6065	Validation Loss: 0.5746
Epoch 1500: 	Training Loss: 0.6048	Validation Loss: 0.5786
Epoch 2000: 	Training Loss: 0.6037	Validation Loss: 0.5751
Epoch 2500: 	Training Loss: 0.6067	Validation Loss: 0.5767
Epoch 3000: 	Training Loss: 0.6043	Validation Loss: 0.5746
Early stopping at epoch 3216
Best validation loss: 0.5728
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/GRNN_1x3_RNN_acceptreject_symmetric_qp_no-punishment_2022_10_08_20_12_08_348428/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u17>
Subject: Job 126381301: <GRNNx3-3-1> in cluster <Janelia> Done

Job <GRNNx3-3-1> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Sat Oct  8 20:11:32 2022
Job was executed on host(s) <e10u17>, in queue <local>, as user <mohantas> in cluster <Janelia> at Sat Oct  8 20:11:33 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Sat Oct  8 20:11:33 2022
Terminated at Sun Oct  9 02:31:50 2022
Results reported at Sun Oct  9 02:31:50 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_mohanta.py --agent GRNN --num_reservoir 1 --reservoir_size 3 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric yes --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   44799.92 sec.
    Max Memory :                                 335 MB
    Average Memory :                             253.12 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15025.00 MB
    Max Swap :                                   -
    Max Processes :                              6
    Max Threads :                                15
    Run time :                                   22818 sec.
    Turnaround time :                            22818 sec.

The output (if any) is above this job summary.

