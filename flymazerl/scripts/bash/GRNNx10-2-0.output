
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GRNNLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_reward_set.csv
Model: GRNN_1x10_RNN_acceptreject_asymmetric_qp_no-punishment_2022_10_04_02_17_35_300320
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6810	Validation Loss: 0.6890
Epoch 500: 	Training Loss: 0.6486	Validation Loss: 0.6907
Epoch 1000: 	Training Loss: 0.5901	Validation Loss: 0.6858
Epoch 1500: 	Training Loss: 0.6160	Validation Loss: 0.6609
Epoch 2000: 	Training Loss: 0.6144	Validation Loss: 0.6703
Epoch 2500: 	Training Loss: 0.6022	Validation Loss: 0.6734
Early stopping at epoch 2881
Best validation loss: 0.6511
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6896	Validation Loss: 0.6891
Epoch 500: 	Training Loss: 0.5911	Validation Loss: 0.6447
Epoch 1000: 	Training Loss: 0.6435	Validation Loss: 0.6687
Epoch 1500: 	Training Loss: 0.6207	Validation Loss: 0.6390
Epoch 2000: 	Training Loss: 0.6528	Validation Loss: 0.6498
Epoch 2500: 	Training Loss: 0.6177	Validation Loss: 0.6349
Early stopping at epoch 2523
Best validation loss: 0.6221
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6876	Validation Loss: 0.6820
Epoch 500: 	Training Loss: 0.6249	Validation Loss: 0.6427
Epoch 1000: 	Training Loss: 0.6194	Validation Loss: 0.6482
Epoch 1500: 	Training Loss: 0.6746	Validation Loss: 0.6961
Epoch 2000: 	Training Loss: 0.6322	Validation Loss: 0.6704
Epoch 2500: 	Training Loss: 0.6432	Validation Loss: 0.6708
Early stopping at epoch 2867
Best validation loss: 0.6380
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6918	Validation Loss: 0.6827
Epoch 500: 	Training Loss: 0.6277	Validation Loss: 0.6360
Epoch 1000: 	Training Loss: 0.6216	Validation Loss: 0.6401
Epoch 1500: 	Training Loss: 0.6519	Validation Loss: 0.6371
Epoch 2000: 	Training Loss: 0.6250	Validation Loss: 0.6145
Epoch 2500: 	Training Loss: 0.6549	Validation Loss: 0.6424
Early stopping at epoch 2545
Best validation loss: 0.6050
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6913	Validation Loss: 0.6896
Epoch 500: 	Training Loss: 0.6213	Validation Loss: 0.6340
Epoch 1000: 	Training Loss: 0.6166	Validation Loss: 0.6368
Epoch 1500: 	Training Loss: 0.6513	Validation Loss: 0.6496
Epoch 2000: 	Training Loss: 0.6581	Validation Loss: 0.6596
Epoch 2500: 	Training Loss: 0.6344	Validation Loss: 0.6493
Early stopping at epoch 2587
Best validation loss: 0.6072
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/GRNN_1x10_RNN_acceptreject_asymmetric_qp_no-punishment_2022_10_04_02_17_35_300320/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u12>
Subject: Job 126232923: <GRNNx10-2-0> in cluster <Janelia> Done

Job <GRNNx10-2-0> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Tue Oct  4 02:17:09 2022
Job was executed on host(s) <e10u12>, in queue <local>, as user <mohantas> in cluster <Janelia> at Tue Oct  4 02:17:09 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Tue Oct  4 02:17:09 2022
Terminated at Tue Oct  4 03:04:10 2022
Results reported at Tue Oct  4 03:04:10 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_rajagopalan.py --agent GRNN --num_reservoir 1 --reservoir_size 10 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric no --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   5552.95 sec.
    Max Memory :                                 240 MB
    Average Memory :                             229.49 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15120.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   2824 sec.
    Turnaround time :                            2821 sec.

The output (if any) is above this job summary.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GRNNLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_reward_set.csv
Model: GRNN_1x10_RNN_acceptreject_asymmetric_qp_no-punishment_2022_10_08_20_14_45_134391
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6776	Validation Loss: 0.6305
Epoch 500: 	Training Loss: 0.5904	Validation Loss: 0.5887
Epoch 1000: 	Training Loss: 0.5960	Validation Loss: 0.5867
Epoch 1500: 	Training Loss: 0.6011	Validation Loss: 0.5913
Epoch 2000: 	Training Loss: 0.5964	Validation Loss: 0.5898
Epoch 2500: 	Training Loss: 0.6007	Validation Loss: 0.5896
Early stopping at epoch 2563
Best validation loss: 0.5808
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6623	Validation Loss: 0.6057
Epoch 500: 	Training Loss: 0.5979	Validation Loss: 0.5866
Epoch 1000: 	Training Loss: 0.6086	Validation Loss: 0.5911
Epoch 1500: 	Training Loss: 0.6055	Validation Loss: 0.5813
Epoch 2000: 	Training Loss: 0.6002	Validation Loss: 0.5789
Epoch 2500: 	Training Loss: 0.6076	Validation Loss: 0.5837
Early stopping at epoch 2522
Best validation loss: 0.5742
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6642	Validation Loss: 0.6499
Epoch 500: 	Training Loss: 0.5919	Validation Loss: 0.6248
Epoch 1000: 	Training Loss: 0.5820	Validation Loss: 0.6304
Epoch 1500: 	Training Loss: 0.5940	Validation Loss: 0.6231
Epoch 2000: 	Training Loss: 0.6030	Validation Loss: 0.6339
Epoch 2500: 	Training Loss: 0.6028	Validation Loss: 0.6282
Epoch 3000: 	Training Loss: 0.5962	Validation Loss: 0.6296
Epoch 3500: 	Training Loss: 0.6000	Validation Loss: 0.6347
Epoch 4000: 	Training Loss: 0.5994	Validation Loss: 0.6309
Early stopping at epoch 4108
Best validation loss: 0.6180
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6530	Validation Loss: 0.6580
Epoch 500: 	Training Loss: 0.5902	Validation Loss: 0.6108
Epoch 1000: 	Training Loss: 0.6458	Validation Loss: 0.6803
Epoch 1500: 	Training Loss: 0.5967	Validation Loss: 0.6206
Epoch 2000: 	Training Loss: 0.5933	Validation Loss: 0.6151
Epoch 2500: 	Training Loss: 0.5938	Validation Loss: 0.6133
Early stopping at epoch 2551
Best validation loss: 0.6070
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6642	Validation Loss: 0.6572
Epoch 500: 	Training Loss: 0.5998	Validation Loss: 0.6447
Epoch 1000: 	Training Loss: 0.5843	Validation Loss: 0.6420
Epoch 1500: 	Training Loss: 0.6138	Validation Loss: 0.6654
Epoch 2000: 	Training Loss: 0.5987	Validation Loss: 0.6398
Epoch 2500: 	Training Loss: 0.5905	Validation Loss: 0.6372
Early stopping at epoch 2517
Best validation loss: 0.6322
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/GRNN_1x10_RNN_acceptreject_asymmetric_qp_no-punishment_2022_10_08_20_14_45_134391/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u10>
Subject: Job 126381332: <GRNNx10-2-0> in cluster <Janelia> Done

Job <GRNNx10-2-0> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Sat Oct  8 20:14:37 2022
Job was executed on host(s) <e10u10>, in queue <local>, as user <mohantas> in cluster <Janelia> at Sat Oct  8 20:14:37 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Sat Oct  8 20:14:37 2022
Terminated at Sat Oct  8 23:24:51 2022
Results reported at Sat Oct  8 23:24:51 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_mohanta.py --agent GRNN --num_reservoir 1 --reservoir_size 10 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric no --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   22291.08 sec.
    Max Memory :                                 303 MB
    Average Memory :                             247.12 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15057.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   11414 sec.
    Turnaround time :                            11414 sec.

The output (if any) is above this job summary.

