
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_reward_set.csv
Model: GQNN_100-100_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_04_02_25_55_496080
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6725	Validation Loss: 0.6391
Epoch 500: 	Training Loss: 0.6713	Validation Loss: 0.6867
Epoch 1000: 	Training Loss: 0.6701	Validation Loss: 0.6870
Epoch 1500: 	Training Loss: 0.7016	Validation Loss: 0.6415
Epoch 2000: 	Training Loss: 0.6427	Validation Loss: 0.6168
Epoch 2500: 	Training Loss: 0.6686	Validation Loss: 0.6308
Early stopping at epoch 2613
Best validation loss: 0.6052
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6342	Validation Loss: 0.6245
Epoch 500: 	Training Loss: 0.6926	Validation Loss: 0.6931
Epoch 1000: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 1500: 	Training Loss: 0.6706	Validation Loss: 0.6806
Epoch 2000: 	Training Loss: 0.6309	Validation Loss: 0.6310
Epoch 2500: 	Training Loss: 0.6631	Validation Loss: 0.6572
Epoch 3000: 	Training Loss: 0.6397	Validation Loss: 0.6366
Epoch 3500: 	Training Loss: 0.6415	Validation Loss: 0.6306
Epoch 4000: 	Training Loss: 0.6421	Validation Loss: 0.6320
Early stopping at epoch 4312
Best validation loss: 0.6222
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6247	Validation Loss: 0.6672
Epoch 500: 	Training Loss: 0.6530	Validation Loss: 0.6897
Epoch 1000: 	Training Loss: 0.6528	Validation Loss: 0.6921
Epoch 1500: 	Training Loss: 0.6518	Validation Loss: 0.6891
Epoch 2000: 	Training Loss: 0.6524	Validation Loss: 0.6908
Epoch 2500: 	Training Loss: 0.6533	Validation Loss: 0.6906
Epoch 3000: 	Training Loss: 0.6792	Validation Loss: 0.6630
Epoch 3500: 	Training Loss: 0.6294	Validation Loss: 0.6636
Epoch 4000: 	Training Loss: 0.6792	Validation Loss: 0.6629
Early stopping at epoch 4195
Best validation loss: 0.6549
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6406	Validation Loss: 0.6367
Epoch 500: 	Training Loss: 0.6630	Validation Loss: 0.6621
Epoch 1000: 	Training Loss: 0.6595	Validation Loss: 0.6594
Epoch 1500: 	Training Loss: 0.6607	Validation Loss: 0.6615
Epoch 2000: 	Training Loss: 0.6320	Validation Loss: 0.6361
Epoch 2500: 	Training Loss: 0.6359	Validation Loss: 0.6460
Early stopping at epoch 2506
Best validation loss: 0.6266
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6525	Validation Loss: 0.6058
Epoch 500: 	Training Loss: 0.6407	Validation Loss: 0.6118
Epoch 1000: 	Training Loss: 0.6366	Validation Loss: 0.6116
Epoch 1500: 	Training Loss: 0.6600	Validation Loss: 0.6699
Epoch 2000: 	Training Loss: 0.6811	Validation Loss: 0.6605
Epoch 2500: 	Training Loss: 0.6573	Validation Loss: 0.6110
Early stopping at epoch 2710
Best validation loss: 0.5969
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/GQNN_100-100_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_04_02_25_55_496080/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u15>
Subject: Job 126236023: <GQNNx100x100-2-0> in cluster <Janelia> Done

Job <GQNNx100x100-2-0> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Tue Oct  4 02:25:29 2022
Job was executed on host(s) <e10u15>, in queue <local>, as user <mohantas> in cluster <Janelia> at Tue Oct  4 02:25:29 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Tue Oct  4 02:25:29 2022
Terminated at Tue Oct  4 11:28:37 2022
Results reported at Tue Oct  4 11:28:37 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_rajagopalan.py --agent GQNN --hidden_state_sizes 100 100 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric no --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   64846.41 sec.
    Max Memory :                                 266 MB
    Average Memory :                             250.13 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15094.00 MB
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                14
    Run time :                                   32593 sec.
    Turnaround time :                            32588 sec.

The output (if any) is above this job summary.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_reward_set.csv
Model: GQNN_100-100_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_08_20_15_39_951652
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6514	Validation Loss: 0.6460
Epoch 500: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 1000: 	Training Loss: 0.6367	Validation Loss: 0.6421
Epoch 1500: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 2000: 	Training Loss: 0.6483	Validation Loss: 0.6594
Epoch 2500: 	Training Loss: 0.6026	Validation Loss: 0.6287
Epoch 3000: 	Training Loss: 0.6483	Validation Loss: 0.6594
Epoch 3500: 	Training Loss: 0.6102	Validation Loss: 0.6280
Epoch 4000: 	Training Loss: 0.6931	Validation Loss: 0.6931
Early stopping at epoch 4129
Best validation loss: 0.6188
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6092	Validation Loss: 0.5776
Epoch 500: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 1000: 	Training Loss: 0.6118	Validation Loss: 0.5769
Epoch 1500: 	Training Loss: 0.6633	Validation Loss: 0.6931
Epoch 2000: 	Training Loss: 0.6543	Validation Loss: 0.6378
Epoch 2500: 	Training Loss: 0.6431	Validation Loss: 0.6335
Epoch 3000: 	Training Loss: 0.6682	Validation Loss: 0.6370
Early stopping at epoch 3473
Best validation loss: 0.5736
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6071	Validation Loss: 0.5874
Epoch 500: 	Training Loss: 0.6374	Validation Loss: 0.6451
Epoch 1000: 	Training Loss: 0.6677	Validation Loss: 0.6326
Epoch 1500: 	Training Loss: 0.6391	Validation Loss: 0.6448
Epoch 2000: 	Training Loss: 0.6337	Validation Loss: 0.6041
Epoch 2500: 	Training Loss: 0.6427	Validation Loss: 0.6449
Early stopping at epoch 2700
Best validation loss: 0.5763
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6060	Validation Loss: 0.5799
Epoch 500: 	Training Loss: 0.6097	Validation Loss: 0.5883
Epoch 1000: 	Training Loss: 0.6251	Validation Loss: 0.5973
Epoch 1500: 	Training Loss: 0.6534	Validation Loss: 0.6312
Epoch 2000: 	Training Loss: 0.6697	Validation Loss: 0.6607
Epoch 2500: 	Training Loss: 0.6310	Validation Loss: 0.5996
Early stopping at epoch 2572
Best validation loss: 0.5780
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6008	Validation Loss: 0.5965
Epoch 500: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 1000: 	Training Loss: 0.6372	Validation Loss: 0.6482
Epoch 1500: 	Training Loss: 0.6634	Validation Loss: 0.6604
Epoch 2000: 	Training Loss: nan	Validation Loss: nan
Epoch 2500: 	Training Loss: nan	Validation Loss: nan
Early stopping at epoch 2540
Best validation loss: 0.5947
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/GQNN_100-100_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_08_20_15_39_951652/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u14>
Subject: Job 126381404: <GQNNx100x100-2-0> in cluster <Janelia> Done

Job <GQNNx100x100-2-0> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Sat Oct  8 20:15:28 2022
Job was executed on host(s) <e10u14>, in queue <local>, as user <mohantas> in cluster <Janelia> at Sat Oct  8 20:15:28 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Sat Oct  8 20:15:28 2022
Terminated at Sun Oct  9 20:03:29 2022
Results reported at Sun Oct  9 20:03:29 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_mohanta.py --agent GQNN --hidden_state_sizes 100 100 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric no --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   170218.05 sec.
    Max Memory :                                 359 MB
    Average Memory :                             287.01 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15001.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   85682 sec.
    Turnaround time :                            85681 sec.

The output (if any) is above this job summary.

