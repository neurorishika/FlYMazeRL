
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_reward_set.csv
Model: GQNN_10_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_04_02_25_43_650163
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.7037	Validation Loss: 0.6795
Epoch 500: 	Training Loss: 0.6216	Validation Loss: 0.6586
Epoch 1000: 	Training Loss: 0.6211	Validation Loss: 0.6539
Epoch 1500: 	Training Loss: 0.6211	Validation Loss: 0.6627
Epoch 2000: 	Training Loss: 0.6193	Validation Loss: 0.6599
Epoch 2500: 	Training Loss: 0.6227	Validation Loss: 0.6643
Epoch 3000: 	Training Loss: 0.6272	Validation Loss: 0.6503
Epoch 3500: 	Training Loss: 0.6224	Validation Loss: 0.6571
Epoch 4000: 	Training Loss: 0.6250	Validation Loss: 0.6529
Epoch 4500: 	Training Loss: 0.6301	Validation Loss: 0.6517
Epoch 5000: 	Training Loss: 0.7514	Validation Loss: 0.8700
Early stopping at epoch 5197
Best validation loss: 0.6432
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6384	Validation Loss: 0.6210
Epoch 500: 	Training Loss: 0.6275	Validation Loss: 0.6209
Epoch 1000: 	Training Loss: 0.6263	Validation Loss: 0.6223
Epoch 1500: 	Training Loss: 0.6329	Validation Loss: 0.6395
Epoch 2000: 	Training Loss: 0.6294	Validation Loss: 0.6262
Epoch 2500: 	Training Loss: 0.6256	Validation Loss: 0.6262
Early stopping at epoch 2509
Best validation loss: 0.6165
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6334	Validation Loss: 0.6273
Epoch 500: 	Training Loss: 0.6719	Validation Loss: 0.6595
Epoch 1000: 	Training Loss: 0.6249	Validation Loss: 0.6289
Epoch 1500: 	Training Loss: 0.6226	Validation Loss: 0.6292
Epoch 2000: 	Training Loss: 0.6381	Validation Loss: 0.6385
Epoch 2500: 	Training Loss: 0.6318	Validation Loss: 0.6331
Early stopping at epoch 2788
Best validation loss: 0.6248
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6308	Validation Loss: 0.6162
Epoch 500: 	Training Loss: 0.6268	Validation Loss: 0.6275
Epoch 1000: 	Training Loss: 0.6335	Validation Loss: 0.6516
Epoch 1500: 	Training Loss: 0.6266	Validation Loss: 0.6317
Epoch 2000: 	Training Loss: 0.6533	Validation Loss: 0.6786
Epoch 2500: 	Training Loss: 0.6301	Validation Loss: 0.6332
Early stopping at epoch 2500
Best validation loss: 0.6162
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6402	Validation Loss: 0.5918
Epoch 500: 	Training Loss: 0.6661	Validation Loss: 0.6457
Epoch 1000: 	Training Loss: 0.6535	Validation Loss: 0.6273
Epoch 1500: 	Training Loss: 0.6527	Validation Loss: 0.6287
Epoch 2000: 	Training Loss: 0.6516	Validation Loss: 0.6250
Epoch 2500: 	Training Loss: 0.6638	Validation Loss: 0.6460
Early stopping at epoch 2507
Best validation loss: 0.5867
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/GQNN_10_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_04_02_25_43_650163/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u21>
Subject: Job 126235977: <GQNNx10-3-0> in cluster <Janelia> Done

Job <GQNNx10-3-0> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Tue Oct  4 02:25:21 2022
Job was executed on host(s) <e10u21>, in queue <local>, as user <mohantas> in cluster <Janelia> at Tue Oct  4 02:25:22 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Tue Oct  4 02:25:22 2022
Terminated at Tue Oct  4 06:13:37 2022
Results reported at Tue Oct  4 06:13:37 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_rajagopalan.py --agent GQNN --hidden_state_sizes 10 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric no --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   27240.56 sec.
    Max Memory :                                 256 MB
    Average Memory :                             237.59 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15104.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   13699 sec.
    Turnaround time :                            13696 sec.

The output (if any) is above this job summary.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_reward_set.csv
Model: GQNN_10_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_08_20_15_24_457600
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6752	Validation Loss: 0.6620
Epoch 500: 	Training Loss: 0.6017	Validation Loss: 0.5820
Epoch 1000: 	Training Loss: 0.6017	Validation Loss: 0.5791
Epoch 1500: 	Training Loss: 0.6214	Validation Loss: 0.5778
Epoch 2000: 	Training Loss: 0.6015	Validation Loss: 0.5920
Epoch 2500: 	Training Loss: 0.6025	Validation Loss: 0.5786
Epoch 3000: 	Training Loss: 0.6016	Validation Loss: 0.5764
Epoch 3500: 	Training Loss: 0.6017	Validation Loss: 0.5786
Epoch 4000: 	Training Loss: 0.6021	Validation Loss: 0.5784
Epoch 4500: 	Training Loss: 0.6028	Validation Loss: 0.5784
Epoch 5000: 	Training Loss: 0.6062	Validation Loss: 0.5812
Epoch 5500: 	Training Loss: 0.6027	Validation Loss: 0.5788
Early stopping at epoch 5520
Best validation loss: 0.5751
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6084	Validation Loss: 0.5647
Epoch 500: 	Training Loss: 0.6071	Validation Loss: 0.5594
Epoch 1000: 	Training Loss: 0.6060	Validation Loss: 0.5597
Epoch 1500: 	Training Loss: 0.6139	Validation Loss: 0.5623
Epoch 2000: 	Training Loss: 0.6071	Validation Loss: 0.5594
Epoch 2500: 	Training Loss: 0.6062	Validation Loss: 0.5588
Epoch 3000: 	Training Loss: 0.6103	Validation Loss: 0.5592
Epoch 3500: 	Training Loss: 0.6067	Validation Loss: 0.5587
Early stopping at epoch 3516
Best validation loss: 0.5577
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5954	Validation Loss: 0.6040
Epoch 500: 	Training Loss: 0.5963	Validation Loss: 0.6061
Epoch 1000: 	Training Loss: 0.5966	Validation Loss: 0.6069
Epoch 1500: 	Training Loss: 0.5965	Validation Loss: 0.6056
Epoch 2000: 	Training Loss: 0.5956	Validation Loss: 0.6053
Epoch 2500: 	Training Loss: 0.5950	Validation Loss: 0.6054
Epoch 3000: 	Training Loss: 0.5962	Validation Loss: 0.6043
Epoch 3500: 	Training Loss: 0.5943	Validation Loss: 0.6028
Epoch 4000: 	Training Loss: 0.5947	Validation Loss: 0.6037
Epoch 4500: 	Training Loss: 0.5945	Validation Loss: 0.6058
Epoch 5000: 	Training Loss: 0.5985	Validation Loss: 0.6352
Early stopping at epoch 5415
Best validation loss: 0.6027
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6076	Validation Loss: 0.5597
Epoch 500: 	Training Loss: 0.6074	Validation Loss: 0.5589
Epoch 1000: 	Training Loss: 0.6066	Validation Loss: 0.5593
Epoch 1500: 	Training Loss: 0.6067	Validation Loss: 0.5590
Epoch 2000: 	Training Loss: 0.6064	Validation Loss: 0.5592
Epoch 2500: 	Training Loss: 0.6082	Validation Loss: 0.5593
Early stopping at epoch 2947
Best validation loss: 0.5573
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6025	Validation Loss: 0.5808
Epoch 500: 	Training Loss: 0.6002	Validation Loss: 0.5813
Epoch 1000: 	Training Loss: 0.6010	Validation Loss: 0.5798
Epoch 1500: 	Training Loss: 0.6023	Validation Loss: 0.5796
Epoch 2000: 	Training Loss: 0.6009	Validation Loss: 0.5798
Epoch 2500: 	Training Loss: 0.6008	Validation Loss: 0.5811
Epoch 3000: 	Training Loss: 0.6010	Validation Loss: 0.5801
Epoch 3500: 	Training Loss: 0.6009	Validation Loss: 0.5803
Epoch 4000: 	Training Loss: 0.6030	Validation Loss: 0.5808
Epoch 4500: 	Training Loss: 0.6007	Validation Loss: 0.5797
Early stopping at epoch 4854
Best validation loss: 0.5788
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/GQNN_10_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_08_20_15_24_457600/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u22>
Subject: Job 126381389: <GQNNx10-3-0> in cluster <Janelia> Done

Job <GQNNx10-3-0> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Sat Oct  8 20:15:20 2022
Job was executed on host(s) <e10u22>, in queue <local>, as user <mohantas> in cluster <Janelia> at Sat Oct  8 20:15:20 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Sat Oct  8 20:15:20 2022
Terminated at Mon Oct 10 07:10:33 2022
Results reported at Mon Oct 10 07:10:33 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_mohanta.py --agent GQNN --hidden_state_sizes 10 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric no --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   249738.12 sec.
    Max Memory :                                 355 MB
    Average Memory :                             271.40 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15005.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   125712 sec.
    Turnaround time :                            125713 sec.

The output (if any) is above this job summary.

