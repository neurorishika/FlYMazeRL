
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_reward_set.csv
Model: GQNN_100-100-100_relu_acceptreject_symmetric_qp_no-punishment_2022_10_04_02_25_11_418812
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6680	Validation Loss: 0.6542
Epoch 500: 	Training Loss: 0.6498	Validation Loss: 0.6389
Epoch 1000: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 1500: 	Training Loss: 0.6327	Validation Loss: 0.6212
Epoch 2000: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 2500: 	Training Loss: 0.6327	Validation Loss: 0.6181
Epoch 3000: 	Training Loss: 0.6308	Validation Loss: 0.6173
Epoch 3500: 	Training Loss: 0.6299	Validation Loss: 0.6211
Epoch 4000: 	Training Loss: 0.6348	Validation Loss: 0.6232
Epoch 4500: 	Training Loss: 0.6306	Validation Loss: 0.6203
Epoch 5000: 	Training Loss: 0.6299	Validation Loss: 0.6205
Early stopping at epoch 5112
Best validation loss: 0.6141
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6315	Validation Loss: 0.6254
Epoch 500: 	Training Loss: 0.6367	Validation Loss: 0.6320
Epoch 1000: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 1500: 	Training Loss: 0.6932	Validation Loss: 0.6931
Epoch 2000: 	Training Loss: 0.6297	Validation Loss: 0.6289
Epoch 2500: 	Training Loss: 0.6337	Validation Loss: 0.6334
Early stopping at epoch 2513
Best validation loss: 0.6245
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6301	Validation Loss: 0.6344
Epoch 500: 	Training Loss: 0.6302	Validation Loss: 0.6327
Epoch 1000: 	Training Loss: 0.6285	Validation Loss: 0.6454
Epoch 1500: 	Training Loss: 0.6269	Validation Loss: 0.6343
Epoch 2000: 	Training Loss: 0.6283	Validation Loss: 0.6324
Epoch 2500: 	Training Loss: 0.6285	Validation Loss: 0.6353
Epoch 3000: 	Training Loss: 0.6281	Validation Loss: 0.6360
Epoch 3500: 	Training Loss: 0.6278	Validation Loss: 0.6354
Epoch 4000: 	Training Loss: 0.6257	Validation Loss: 0.6374
Early stopping at epoch 4083
Best validation loss: 0.6255
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6397	Validation Loss: 0.6047
Epoch 500: 	Training Loss: 0.6368	Validation Loss: 0.6076
Epoch 1000: 	Training Loss: 0.6391	Validation Loss: 0.6057
Epoch 1500: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 2000: 	Training Loss: 0.6371	Validation Loss: 0.6020
Epoch 2500: 	Training Loss: 0.6452	Validation Loss: 0.6111
Epoch 3000: 	Training Loss: 0.6418	Validation Loss: 0.6084
Epoch 3500: 	Training Loss: 0.6416	Validation Loss: 0.6060
Epoch 4000: 	Training Loss: 0.6410	Validation Loss: 0.6075
Early stopping at epoch 4495
Best validation loss: 0.6004
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6417	Validation Loss: 0.6151
Epoch 500: 	Training Loss: 0.6310	Validation Loss: 0.6147
Epoch 1000: 	Training Loss: 0.6931	Validation Loss: 0.6932
Epoch 1500: 	Training Loss: 0.6331	Validation Loss: 0.6145
Epoch 2000: 	Training Loss: 0.6932	Validation Loss: 0.6932
Epoch 2500: 	Training Loss: 0.6931	Validation Loss: 0.6932
Early stopping at epoch 2507
Best validation loss: 0.6105
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/GQNN_100-100-100_relu_acceptreject_symmetric_qp_no-punishment_2022_10_04_02_25_11_418812/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u21>
Subject: Job 126235811: <GQNNx100x100x100-3-1> in cluster <Janelia> Done

Job <GQNNx100x100x100-3-1> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Tue Oct  4 02:25:06 2022
Job was executed on host(s) <e10u21>, in queue <local>, as user <mohantas> in cluster <Janelia> at Tue Oct  4 02:25:07 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Tue Oct  4 02:25:07 2022
Terminated at Tue Oct  4 13:52:02 2022
Results reported at Tue Oct  4 13:52:02 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_rajagopalan.py --agent GQNN --hidden_state_sizes 100 100 100 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric yes --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   81923.72 sec.
    Max Memory :                                 276 MB
    Average Memory :                             257.52 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15084.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   41218 sec.
    Turnaround time :                            41216 sec.

The output (if any) is above this job summary.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_reward_set.csv
Model: GQNN_100-100-100_relu_acceptreject_symmetric_qp_no-punishment_2022_10_08_20_15_15_070551
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6249	Validation Loss: 0.6115
Epoch 500: 	Training Loss: 0.6000	Validation Loss: 0.6032
Epoch 1000: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 1500: 	Training Loss: 0.6173	Validation Loss: 0.6266
Epoch 2000: 	Training Loss: nan	Validation Loss: nan
Epoch 2500: 	Training Loss: nan	Validation Loss: nan
Early stopping at epoch 2956
Best validation loss: 0.6020
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5998	Validation Loss: 0.6064
Epoch 500: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 1000: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 1500: 	Training Loss: 0.5989	Validation Loss: 0.6050
Epoch 2000: 	Training Loss: 0.5993	Validation Loss: 0.6134
Epoch 2500: 	Training Loss: 0.5980	Validation Loss: 0.6050
Epoch 3000: 	Training Loss: 0.5994	Validation Loss: 0.6075
Epoch 3500: 	Training Loss: 0.5987	Validation Loss: 0.6114
Epoch 4000: 	Training Loss: 0.5989	Validation Loss: 0.6113
Early stopping at epoch 4117
Best validation loss: 0.6026
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5961	Validation Loss: 0.6198
Epoch 500: 	Training Loss: 0.5970	Validation Loss: 0.6190
Epoch 1000: 	Training Loss: 0.6191	Validation Loss: 0.6777
Epoch 1500: 	Training Loss: 0.6005	Validation Loss: 0.6387
Epoch 2000: 	Training Loss: 0.5972	Validation Loss: 0.6206
Epoch 2500: 	Training Loss: 0.6116	Validation Loss: 0.6294
Early stopping at epoch 2501
Best validation loss: 0.6173
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6014	Validation Loss: 0.6011
Epoch 500: 	Training Loss: 0.6024	Validation Loss: 0.6038
Epoch 1000: 	Training Loss: 0.6034	Validation Loss: 0.6173
Epoch 1500: 	Training Loss: 0.6005	Validation Loss: 0.6005
Epoch 2000: 	Training Loss: 0.8200	Validation Loss: 0.9476
Epoch 2500: 	Training Loss: 0.6010	Validation Loss: 0.6008
Epoch 3000: 	Training Loss: 0.6072	Validation Loss: 0.6277
Early stopping at epoch 3187
Best validation loss: 0.5957
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5944	Validation Loss: 0.6212
Epoch 500: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 1000: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 1500: 	Training Loss: 0.5966	Validation Loss: 0.6183
Epoch 2000: 	Training Loss: 0.6080	Validation Loss: 0.6233
Epoch 2500: 	Training Loss: 0.5958	Validation Loss: 0.6186
Early stopping at epoch 2538
Best validation loss: 0.6173
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/GQNN_100-100-100_relu_acceptreject_symmetric_qp_no-punishment_2022_10_08_20_15_15_070551/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u22>
Subject: Job 126381377: <GQNNx100x100x100-3-1> in cluster <Janelia> Done

Job <GQNNx100x100x100-3-1> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Sat Oct  8 20:15:07 2022
Job was executed on host(s) <e10u22>, in queue <local>, as user <mohantas> in cluster <Janelia> at Sat Oct  8 20:15:09 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Sat Oct  8 20:15:09 2022
Terminated at Tue Oct 11 04:11:35 2022
Results reported at Tue Oct 11 04:11:35 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_mohanta.py --agent GQNN --hidden_state_sizes 100 100 100 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric yes --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   396935.47 sec.
    Max Memory :                                 380 MB
    Average Memory :                             317.78 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               14980.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   201388 sec.
    Turnaround time :                            201388 sec.

The output (if any) is above this job summary.

