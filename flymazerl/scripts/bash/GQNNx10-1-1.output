
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_reward_set.csv
Model: GQNN_10_relu_acceptreject_symmetric_qp_no-punishment_2022_10_04_02_25_14_618287
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6970	Validation Loss: 0.6827
Epoch 500: 	Training Loss: 0.6244	Validation Loss: 0.6432
Epoch 1000: 	Training Loss: 0.6234	Validation Loss: 0.6440
Epoch 1500: 	Training Loss: 0.6233	Validation Loss: 0.6437
Epoch 2000: 	Training Loss: 0.6231	Validation Loss: 0.6447
Epoch 2500: 	Training Loss: 0.6223	Validation Loss: 0.6451
Early stopping at epoch 2927
Best validation loss: 0.6424
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6204	Validation Loss: 0.6597
Epoch 500: 	Training Loss: 0.6196	Validation Loss: 0.6596
Epoch 1000: 	Training Loss: 0.6191	Validation Loss: 0.6599
Epoch 1500: 	Training Loss: 0.6190	Validation Loss: 0.6578
Epoch 2000: 	Training Loss: 0.6171	Validation Loss: 0.6588
Epoch 2500: 	Training Loss: 0.6176	Validation Loss: 0.6569
Epoch 3000: 	Training Loss: 0.6164	Validation Loss: 0.6611
Epoch 3500: 	Training Loss: 0.6171	Validation Loss: 0.6644
Epoch 4000: 	Training Loss: 0.6321	Validation Loss: 0.6570
Early stopping at epoch 4487
Best validation loss: 0.6550
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6298	Validation Loss: 0.6169
Epoch 500: 	Training Loss: 0.6283	Validation Loss: 0.6212
Epoch 1000: 	Training Loss: 0.6317	Validation Loss: 0.6208
Epoch 1500: 	Training Loss: 0.6315	Validation Loss: 0.6274
Epoch 2000: 	Training Loss: 0.6285	Validation Loss: 0.6214
Epoch 2500: 	Training Loss: 0.6285	Validation Loss: 0.6245
Early stopping at epoch 2500
Best validation loss: 0.6169
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6303	Validation Loss: 0.6182
Epoch 500: 	Training Loss: 0.6254	Validation Loss: 0.6345
Epoch 1000: 	Training Loss: 0.6268	Validation Loss: 0.6317
Epoch 1500: 	Training Loss: 0.6306	Validation Loss: 0.6232
Epoch 2000: 	Training Loss: 0.6244	Validation Loss: 0.6329
Epoch 2500: 	Training Loss: 0.6339	Validation Loss: 0.6315
Early stopping at epoch 2501
Best validation loss: 0.6179
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6283	Validation Loss: 0.6269
Epoch 500: 	Training Loss: 0.6270	Validation Loss: 0.6326
Epoch 1000: 	Training Loss: 0.6285	Validation Loss: 0.6258
Epoch 1500: 	Training Loss: 0.6258	Validation Loss: 0.6281
Epoch 2000: 	Training Loss: 0.6285	Validation Loss: 0.6254
Epoch 2500: 	Training Loss: 0.6265	Validation Loss: 0.6284
Epoch 3000: 	Training Loss: 0.6255	Validation Loss: 0.6250
Early stopping at epoch 3349
Best validation loss: 0.6189
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/GQNN_10_relu_acceptreject_symmetric_qp_no-punishment_2022_10_04_02_25_14_618287/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u14>
Subject: Job 126235684: <GQNNx10-1-1> in cluster <Janelia> Done

Job <GQNNx10-1-1> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Tue Oct  4 02:24:52 2022
Job was executed on host(s) <e10u14>, in queue <local>, as user <mohantas> in cluster <Janelia> at Tue Oct  4 02:24:56 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Tue Oct  4 02:24:56 2022
Terminated at Tue Oct  4 07:38:24 2022
Results reported at Tue Oct  4 07:38:24 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_rajagopalan.py --agent GQNN --hidden_state_sizes 10 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric yes --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   37459.62 sec.
    Max Memory :                                 256 MB
    Average Memory :                             241.73 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15104.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   18810 sec.
    Turnaround time :                            18812 sec.

The output (if any) is above this job summary.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_reward_set.csv
Model: GQNN_10_relu_acceptreject_symmetric_qp_no-punishment_2022_10_08_20_15_11_386813
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6697	Validation Loss: 0.6167
Epoch 500: 	Training Loss: 0.6068	Validation Loss: 0.5699
Epoch 1000: 	Training Loss: 0.6077	Validation Loss: 0.5819
Epoch 1500: 	Training Loss: 0.6066	Validation Loss: 0.5708
Epoch 2000: 	Training Loss: 0.6065	Validation Loss: 0.5707
Epoch 2500: 	Training Loss: 0.6060	Validation Loss: 0.5694
Epoch 3000: 	Training Loss: 0.6060	Validation Loss: 0.5697
Epoch 3500: 	Training Loss: 0.6061	Validation Loss: 0.5697
Epoch 4000: 	Training Loss: 0.6059	Validation Loss: 0.5693
Epoch 4500: 	Training Loss: 0.6099	Validation Loss: 0.5694
Epoch 5000: 	Training Loss: 0.6057	Validation Loss: 0.5697
Epoch 5500: 	Training Loss: 0.6057	Validation Loss: 0.5699
Epoch 6000: 	Training Loss: 0.6054	Validation Loss: 0.5701
Early stopping at epoch 6082
Best validation loss: 0.5676
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5952	Validation Loss: 0.6164
Epoch 500: 	Training Loss: 0.5985	Validation Loss: 0.6167
Epoch 1000: 	Training Loss: 0.5936	Validation Loss: 0.6174
Epoch 1500: 	Training Loss: 0.5934	Validation Loss: 0.6171
Epoch 2000: 	Training Loss: 0.5979	Validation Loss: 0.6197
Epoch 2500: 	Training Loss: 0.5934	Validation Loss: 0.6182
Early stopping at epoch 2623
Best validation loss: 0.6152
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5886	Validation Loss: 0.6390
Epoch 500: 	Training Loss: 0.5880	Validation Loss: 0.6397
Epoch 1000: 	Training Loss: 0.5915	Validation Loss: 0.6403
Epoch 1500: 	Training Loss: 0.5883	Validation Loss: 0.6416
Epoch 2000: 	Training Loss: 0.5879	Validation Loss: 0.6413
Epoch 2500: 	Training Loss: 0.5873	Validation Loss: 0.6408
Early stopping at epoch 2544
Best validation loss: 0.6388
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5926	Validation Loss: 0.6314
Epoch 500: 	Training Loss: 0.5904	Validation Loss: 0.6316
Epoch 1000: 	Training Loss: 0.5903	Validation Loss: 0.6307
Epoch 1500: 	Training Loss: 0.5908	Validation Loss: 0.6303
Epoch 2000: 	Training Loss: 0.5909	Validation Loss: 0.6334
Epoch 2500: 	Training Loss: 0.5911	Validation Loss: 0.6305
Early stopping at epoch 2510
Best validation loss: 0.6294
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5932	Validation Loss: 0.6202
Epoch 500: 	Training Loss: 0.5924	Validation Loss: 0.6210
Epoch 1000: 	Training Loss: 0.5932	Validation Loss: 0.6248
Epoch 1500: 	Training Loss: 0.5925	Validation Loss: 0.6226
Epoch 2000: 	Training Loss: 0.5940	Validation Loss: 0.6235
Epoch 2500: 	Training Loss: 0.5978	Validation Loss: 0.6238
Early stopping at epoch 2981
Best validation loss: 0.6200
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/GQNN_10_relu_acceptreject_symmetric_qp_no-punishment_2022_10_08_20_15_11_386813/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u03>
Subject: Job 126381351: <GQNNx10-1-1> in cluster <Janelia> Done

Job <GQNNx10-1-1> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Sat Oct  8 20:14:53 2022
Job was executed on host(s) <e10u03>, in queue <local>, as user <mohantas> in cluster <Janelia> at Sat Oct  8 20:14:54 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Sat Oct  8 20:14:54 2022
Terminated at Mon Oct 10 05:31:29 2022
Results reported at Mon Oct 10 05:31:29 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_mohanta.py --agent GQNN --hidden_state_sizes 10 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric yes --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   237519.75 sec.
    Max Memory :                                 338 MB
    Average Memory :                             257.02 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15022.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   119796 sec.
    Turnaround time :                            119796 sec.

The output (if any) is above this job summary.

