
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_reward_set.csv
Model: GQNN_10-10_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_04_02_25_55_496079
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6966	Validation Loss: 0.6822
Epoch 500: 	Training Loss: 0.6314	Validation Loss: 0.6303
Epoch 1000: 	Training Loss: 0.6253	Validation Loss: 0.6237
Epoch 1500: 	Training Loss: 0.6262	Validation Loss: 0.6283
Epoch 2000: 	Training Loss: 0.6238	Validation Loss: 0.6268
Epoch 2500: 	Training Loss: 0.6358	Validation Loss: 0.6328
Epoch 3000: 	Training Loss: 0.6328	Validation Loss: 0.6275
Epoch 3500: 	Training Loss: 0.6643	Validation Loss: 0.6683
Early stopping at epoch 3922
Best validation loss: 0.6181
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6270	Validation Loss: 0.6457
Epoch 500: 	Training Loss: 0.6266	Validation Loss: 0.6486
Epoch 1000: 	Training Loss: 0.6204	Validation Loss: 0.6525
Epoch 1500: 	Training Loss: 0.6788	Validation Loss: 0.6691
Epoch 2000: 	Training Loss: 0.6229	Validation Loss: 0.6552
Epoch 2500: 	Training Loss: 0.6264	Validation Loss: 0.6582
Early stopping at epoch 2591
Best validation loss: 0.6376
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6320	Validation Loss: 0.5985
Epoch 500: 	Training Loss: 0.6357	Validation Loss: 0.5984
Epoch 1000: 	Training Loss: 0.6371	Validation Loss: 0.5993
Epoch 1500: 	Training Loss: 0.6782	Validation Loss: 0.6899
Epoch 2000: 	Training Loss: 0.6739	Validation Loss: 0.6802
Epoch 2500: 	Training Loss: 0.6724	Validation Loss: 0.6792
Early stopping at epoch 2511
Best validation loss: 0.5943
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6127	Validation Loss: 0.6750
Epoch 500: 	Training Loss: 0.6120	Validation Loss: 0.6841
Epoch 1000: 	Training Loss: 0.6104	Validation Loss: 0.6871
Epoch 1500: 	Training Loss: 0.6157	Validation Loss: 0.6815
Epoch 2000: 	Training Loss: 0.6082	Validation Loss: 0.6877
Epoch 2500: 	Training Loss: 0.6489	Validation Loss: 0.6831
Epoch 3000: 	Training Loss: 0.6365	Validation Loss: 0.6706
Epoch 3500: 	Training Loss: 0.6447	Validation Loss: 0.6921
Epoch 4000: 	Training Loss: 0.6703	Validation Loss: 0.6914
Epoch 4500: 	Training Loss: 0.6699	Validation Loss: 0.6908
Epoch 5000: 	Training Loss: 0.6269	Validation Loss: 0.6832
Early stopping at epoch 5498
Best validation loss: 0.6654
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6441	Validation Loss: 0.6687
Epoch 500: 	Training Loss: 0.6604	Validation Loss: 0.7075
Epoch 1000: 	Training Loss: 0.6585	Validation Loss: 0.6698
Epoch 1500: 	Training Loss: 0.6489	Validation Loss: 0.6877
Epoch 2000: 	Training Loss: 0.6482	Validation Loss: 0.6778
Epoch 2500: 	Training Loss: 0.6471	Validation Loss: 0.6735
Early stopping at epoch 2535
Best validation loss: 0.6545
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/GQNN_10-10_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_04_02_25_55_496079/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u15>
Subject: Job 126236020: <GQNNx10x10-3-0> in cluster <Janelia> Done

Job <GQNNx10x10-3-0> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Tue Oct  4 02:25:27 2022
Job was executed on host(s) <e10u15>, in queue <local>, as user <mohantas> in cluster <Janelia> at Tue Oct  4 02:25:29 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Tue Oct  4 02:25:29 2022
Terminated at Tue Oct  4 10:35:29 2022
Results reported at Tue Oct  4 10:35:29 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_rajagopalan.py --agent GQNN --hidden_state_sizes 10 10 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric no --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   58507.07 sec.
    Max Memory :                                 258 MB
    Average Memory :                             239.84 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15102.00 MB
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                14
    Run time :                                   29403 sec.
    Turnaround time :                            29402 sec.

The output (if any) is above this job summary.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_reward_set.csv
Model: GQNN_10-10_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_08_20_15_39_572430
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6563	Validation Loss: 0.6510
Epoch 500: 	Training Loss: 0.6011	Validation Loss: 0.5914
Epoch 1000: 	Training Loss: 0.6048	Validation Loss: 0.5902
Epoch 1500: 	Training Loss: 0.6037	Validation Loss: 0.5913
Epoch 2000: 	Training Loss: 0.6015	Validation Loss: 0.5899
Epoch 2500: 	Training Loss: 0.5995	Validation Loss: 0.5920
Epoch 3000: 	Training Loss: 0.6003	Validation Loss: 0.5888
Epoch 3500: 	Training Loss: 0.6001	Validation Loss: 0.5891
Early stopping at epoch 3817
Best validation loss: 0.5871
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5992	Validation Loss: 0.6051
Epoch 500: 	Training Loss: 0.5978	Validation Loss: 0.6081
Epoch 1000: 	Training Loss: 0.6004	Validation Loss: 0.6129
Epoch 1500: 	Training Loss: 0.5973	Validation Loss: 0.6046
Epoch 2000: 	Training Loss: 0.5983	Validation Loss: 0.6041
Epoch 2500: 	Training Loss: 0.6607	Validation Loss: 0.6582
Epoch 3000: 	Training Loss: 0.5996	Validation Loss: 0.6008
Early stopping at epoch 3421
Best validation loss: 0.5995
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6109	Validation Loss: 0.5585
Epoch 500: 	Training Loss: 0.6841	Validation Loss: 0.6751
Epoch 1000: 	Training Loss: 0.6092	Validation Loss: 0.5760
Epoch 1500: 	Training Loss: 0.6084	Validation Loss: 0.5589
Epoch 2000: 	Training Loss: 0.6080	Validation Loss: 0.5605
Epoch 2500: 	Training Loss: 0.6126	Validation Loss: 0.5608
Epoch 3000: 	Training Loss: 0.6085	Validation Loss: 0.5602
Epoch 3500: 	Training Loss: 0.6090	Validation Loss: 0.5595
Epoch 4000: 	Training Loss: 0.6571	Validation Loss: 0.6251
Epoch 4500: 	Training Loss: 0.6534	Validation Loss: 0.5988
Epoch 5000: 	Training Loss: 0.6095	Validation Loss: 0.5616
Epoch 5500: 	Training Loss: 0.6117	Validation Loss: 0.5618
Early stopping at epoch 5904
Best validation loss: 0.5578
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5968	Validation Loss: 0.6053
Epoch 500: 	Training Loss: 0.6079	Validation Loss: 0.6162
Epoch 1000: 	Training Loss: 0.5967	Validation Loss: 0.6047
Epoch 1500: 	Training Loss: 0.5969	Validation Loss: 0.6057
Epoch 2000: 	Training Loss: 0.6379	Validation Loss: 0.6308
Epoch 2500: 	Training Loss: 0.5954	Validation Loss: 0.6065
Early stopping at epoch 2505
Best validation loss: 0.6038
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5962	Validation Loss: 0.6076
Epoch 500: 	Training Loss: 0.6111	Validation Loss: 0.6343
Epoch 1000: 	Training Loss: 0.5978	Validation Loss: 0.6088
Epoch 1500: 	Training Loss: 0.5998	Validation Loss: 0.6093
Epoch 2000: 	Training Loss: 0.6384	Validation Loss: 0.6637
Epoch 2500: 	Training Loss: 0.6041	Validation Loss: 0.6128
Epoch 3000: 	Training Loss: 0.6027	Validation Loss: 0.6121
Epoch 3500: 	Training Loss: 0.5982	Validation Loss: 0.6084
Early stopping at epoch 3721
Best validation loss: 0.6064
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/GQNN_10-10_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_08_20_15_39_572430/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u14>
Subject: Job 126381401: <GQNNx10x10-3-0> in cluster <Janelia> Done

Job <GQNNx10x10-3-0> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Sat Oct  8 20:15:27 2022
Job was executed on host(s) <e10u14>, in queue <local>, as user <mohantas> in cluster <Janelia> at Sat Oct  8 20:15:27 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Sat Oct  8 20:15:27 2022
Terminated at Sun Oct  9 20:07:27 2022
Results reported at Sun Oct  9 20:07:27 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_mohanta.py --agent GQNN --hidden_state_sizes 10 10 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric no --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   170511.08 sec.
    Max Memory :                                 347 MB
    Average Memory :                             261.77 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15013.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   85919 sec.
    Turnaround time :                            85920 sec.

The output (if any) is above this job summary.

