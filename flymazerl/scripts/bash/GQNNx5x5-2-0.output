
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_reward_set.csv
Model: GQNN_5-5_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_04_02_25_55_496081
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6914	Validation Loss: 0.6919
Epoch 500: 	Training Loss: 0.6220	Validation Loss: 0.6549
Epoch 1000: 	Training Loss: 0.6177	Validation Loss: 0.6564
Epoch 1500: 	Training Loss: 0.6185	Validation Loss: 0.6624
Epoch 2000: 	Training Loss: 0.6284	Validation Loss: 0.6601
Epoch 2500: 	Training Loss: 0.6753	Validation Loss: 0.6792
Early stopping at epoch 2669
Best validation loss: 0.6517
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6297	Validation Loss: 0.6475
Epoch 500: 	Training Loss: 0.6248	Validation Loss: 0.6485
Epoch 1000: 	Training Loss: 0.6210	Validation Loss: 0.6479
Epoch 1500: 	Training Loss: 0.6813	Validation Loss: 0.6751
Epoch 2000: 	Training Loss: 0.6218	Validation Loss: 0.6514
Epoch 2500: 	Training Loss: 0.6383	Validation Loss: 0.6642
Epoch 3000: 	Training Loss: 0.6317	Validation Loss: 0.6590
Early stopping at epoch 3205
Best validation loss: 0.6445
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6257	Validation Loss: 0.6451
Epoch 500: 	Training Loss: 0.6201	Validation Loss: 0.6520
Epoch 1000: 	Training Loss: 0.6748	Validation Loss: 0.6766
Epoch 1500: 	Training Loss: 0.6255	Validation Loss: 0.6616
Epoch 2000: 	Training Loss: 0.6377	Validation Loss: 0.6747
Epoch 2500: 	Training Loss: 0.6347	Validation Loss: 0.6728
Early stopping at epoch 2501
Best validation loss: 0.6450
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6291	Validation Loss: 0.6207
Epoch 500: 	Training Loss: 0.6284	Validation Loss: 0.6240
Epoch 1000: 	Training Loss: 0.6556	Validation Loss: 0.6707
Epoch 1500: 	Training Loss: 0.6779	Validation Loss: 0.6651
Epoch 2000: 	Training Loss: 0.6770	Validation Loss: 0.6663
Epoch 2500: 	Training Loss: 0.6762	Validation Loss: 0.6654
Early stopping at epoch 2509
Best validation loss: 0.6174
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6342	Validation Loss: 0.6076
Epoch 500: 	Training Loss: 0.6326	Validation Loss: 0.6147
Epoch 1000: 	Training Loss: 0.6523	Validation Loss: 0.6215
Epoch 1500: 	Training Loss: 0.6789	Validation Loss: 0.6753
Epoch 2000: 	Training Loss: 0.6758	Validation Loss: 0.6715
Epoch 2500: 	Training Loss: 0.6417	Validation Loss: 0.6179
Early stopping at epoch 2596
Best validation loss: 0.6036
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/GQNN_5-5_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_04_02_25_55_496081/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u15>
Subject: Job 126235994: <GQNNx5x5-2-0> in cluster <Janelia> Done

Job <GQNNx5x5-2-0> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Tue Oct  4 02:25:24 2022
Job was executed on host(s) <e10u15>, in queue <local>, as user <mohantas> in cluster <Janelia> at Tue Oct  4 02:25:29 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Tue Oct  4 02:25:29 2022
Terminated at Tue Oct  4 09:00:59 2022
Results reported at Tue Oct  4 09:00:59 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_rajagopalan.py --agent GQNN --hidden_state_sizes 5 5 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric no --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   47168.75 sec.
    Max Memory :                                 253 MB
    Average Memory :                             239.42 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15107.00 MB
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                14
    Run time :                                   23735 sec.
    Turnaround time :                            23735 sec.

The output (if any) is above this job summary.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_reward_set.csv
Model: GQNN_5-5_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_08_20_15_28_098471
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6680	Validation Loss: 0.6460
Epoch 500: 	Training Loss: 0.6025	Validation Loss: 0.5879
Epoch 1000: 	Training Loss: 0.6015	Validation Loss: 0.5871
Epoch 1500: 	Training Loss: 0.6005	Validation Loss: 0.5888
Epoch 2000: 	Training Loss: 0.6048	Validation Loss: 0.5897
Epoch 2500: 	Training Loss: 0.6080	Validation Loss: 0.5939
Epoch 3000: 	Training Loss: 0.6073	Validation Loss: 0.5907
Epoch 3500: 	Training Loss: 0.6035	Validation Loss: 0.5885
Epoch 4000: 	Training Loss: 0.6093	Validation Loss: 0.5961
Epoch 4500: 	Training Loss: 0.6021	Validation Loss: 0.5906
Epoch 5000: 	Training Loss: 0.6365	Validation Loss: 0.6269
Epoch 5500: 	Training Loss: 0.6027	Validation Loss: 0.5865
Epoch 6000: 	Training Loss: 0.6070	Validation Loss: 0.5925
Epoch 6500: 	Training Loss: 0.6018	Validation Loss: 0.5885
Epoch 7000: 	Training Loss: 0.6016	Validation Loss: 0.5868
Early stopping at epoch 7464
Best validation loss: 0.5849
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6006	Validation Loss: 0.6101
Epoch 500: 	Training Loss: 0.5981	Validation Loss: 0.6057
Epoch 1000: 	Training Loss: 0.5969	Validation Loss: 0.6026
Epoch 1500: 	Training Loss: 0.5966	Validation Loss: 0.6040
Epoch 2000: 	Training Loss: 0.5972	Validation Loss: 0.6031
Epoch 2500: 	Training Loss: 0.6057	Validation Loss: 0.6041
Epoch 3000: 	Training Loss: 0.5963	Validation Loss: 0.6033
Epoch 3500: 	Training Loss: 0.5971	Validation Loss: 0.6065
Epoch 4000: 	Training Loss: 0.5968	Validation Loss: 0.6057
Epoch 4500: 	Training Loss: 0.5964	Validation Loss: 0.6058
Epoch 5000: 	Training Loss: 0.5974	Validation Loss: 0.6037
Epoch 5500: 	Training Loss: 0.5978	Validation Loss: 0.6049
Early stopping at epoch 5503
Best validation loss: 0.6008
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5968	Validation Loss: 0.6070
Epoch 500: 	Training Loss: 0.6290	Validation Loss: 0.6643
Epoch 1000: 	Training Loss: 0.5965	Validation Loss: 0.6088
Epoch 1500: 	Training Loss: 0.5983	Validation Loss: 0.6095
Epoch 2000: 	Training Loss: 0.5958	Validation Loss: 0.6069
Epoch 2500: 	Training Loss: 0.5951	Validation Loss: 0.6059
Early stopping at epoch 2505
Best validation loss: 0.6049
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5851	Validation Loss: 0.6495
Epoch 500: 	Training Loss: 0.5854	Validation Loss: 0.6509
Epoch 1000: 	Training Loss: 0.5854	Validation Loss: 0.6544
Epoch 1500: 	Training Loss: 0.5880	Validation Loss: 0.6551
Epoch 2000: 	Training Loss: 0.5884	Validation Loss: 0.6520
Epoch 2500: 	Training Loss: 0.5851	Validation Loss: 0.6529
Epoch 3000: 	Training Loss: 0.5923	Validation Loss: 0.6550
Epoch 3500: 	Training Loss: 0.5845	Validation Loss: 0.6516
Epoch 4000: 	Training Loss: 0.5840	Validation Loss: 0.6489
Epoch 4500: 	Training Loss: 0.5856	Validation Loss: 0.6511
Epoch 5000: 	Training Loss: 0.5853	Validation Loss: 0.6502
Epoch 5500: 	Training Loss: 0.5839	Validation Loss: 0.6495
Epoch 6000: 	Training Loss: 0.5835	Validation Loss: 0.6505
Early stopping at epoch 6252
Best validation loss: 0.6482
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5916	Validation Loss: 0.6232
Epoch 500: 	Training Loss: 0.5922	Validation Loss: 0.6250
Epoch 1000: 	Training Loss: 0.5908	Validation Loss: 0.6278
Epoch 1500: 	Training Loss: 0.5909	Validation Loss: 0.6236
Epoch 2000: 	Training Loss: 0.5908	Validation Loss: 0.6239
Epoch 2500: 	Training Loss: 0.5907	Validation Loss: 0.6253
Early stopping at epoch 2512
Best validation loss: 0.6225
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/GQNN_5-5_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_08_20_15_28_098471/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u18>
Subject: Job 126381396: <GQNNx5x5-2-0> in cluster <Janelia> Done

Job <GQNNx5x5-2-0> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Sat Oct  8 20:15:24 2022
Job was executed on host(s) <e10u18>, in queue <local>, as user <mohantas> in cluster <Janelia> at Sat Oct  8 20:15:24 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Sat Oct  8 20:15:24 2022
Terminated at Mon Oct 10 02:55:22 2022
Results reported at Mon Oct 10 02:55:22 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_mohanta.py --agent GQNN --hidden_state_sizes 5 5 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric no --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   219115.33 sec.
    Max Memory :                                 380 MB
    Average Memory :                             271.85 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               14980.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   110398 sec.
    Turnaround time :                            110398 sec.

The output (if any) is above this job summary.

