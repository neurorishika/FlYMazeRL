
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_reward_set.csv
Model: GQNN_100-100_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_04_02_25_55_496083
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6695	Validation Loss: 0.6541
Epoch 500: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 1000: 	Training Loss: 0.6791	Validation Loss: 0.6649
Epoch 1500: 	Training Loss: 0.6791	Validation Loss: 0.6649
Epoch 2000: 	Training Loss: 0.6729	Validation Loss: 0.6857
Epoch 2500: 	Training Loss: 0.6931	Validation Loss: 0.6931
Early stopping at epoch 2722
Best validation loss: 0.6515
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6434	Validation Loss: 0.6189
Epoch 500: 	Training Loss: 0.6411	Validation Loss: 0.6223
Epoch 1000: 	Training Loss: 0.6724	Validation Loss: 0.6843
Epoch 1500: 	Training Loss: 0.6450	Validation Loss: 0.6134
Epoch 2000: 	Training Loss: 0.6330	Validation Loss: 0.6369
Epoch 2500: 	Training Loss: 0.6423	Validation Loss: 0.6240
Epoch 3000: 	Training Loss: 0.6365	Validation Loss: 0.6397
Epoch 3500: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 4000: 	Training Loss: 0.6577	Validation Loss: 0.6418
Epoch 4500: 	Training Loss: 0.6561	Validation Loss: 0.6447
Early stopping at epoch 4534
Best validation loss: 0.6007
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6338	Validation Loss: 0.6491
Epoch 500: 	Training Loss: 0.6263	Validation Loss: 0.6511
Epoch 1000: 	Training Loss: 0.6304	Validation Loss: 0.6564
Epoch 1500: 	Training Loss: 0.6542	Validation Loss: 0.6570
Epoch 2000: 	Training Loss: 0.6540	Validation Loss: 0.6575
Epoch 2500: 	Training Loss: 0.6406	Validation Loss: 0.6506
Early stopping at epoch 2546
Best validation loss: 0.6395
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6333	Validation Loss: 0.6268
Epoch 500: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 1000: 	Training Loss: 0.6522	Validation Loss: 0.6862
Epoch 1500: 	Training Loss: 0.6517	Validation Loss: 0.6564
Epoch 2000: 	Training Loss: 0.6472	Validation Loss: 0.6541
Epoch 2500: 	Training Loss: 0.6258	Validation Loss: 0.6333
Epoch 3000: 	Training Loss: 0.6312	Validation Loss: 0.6334
Epoch 3500: 	Training Loss: 0.6410	Validation Loss: 0.6346
Epoch 4000: 	Training Loss: 0.6303	Validation Loss: 0.6329
Epoch 4500: 	Training Loss: 0.6354	Validation Loss: 0.6368
Epoch 5000: 	Training Loss: 0.6652	Validation Loss: 0.6639
Epoch 5500: 	Training Loss: 0.6302	Validation Loss: 0.6374
Epoch 6000: 	Training Loss: 0.6280	Validation Loss: 0.6378
Epoch 6500: 	Training Loss: 0.6803	Validation Loss: 0.6577
Early stopping at epoch 6502
Best validation loss: 0.6212
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6344	Validation Loss: 0.6194
Epoch 500: 	Training Loss: 0.6418	Validation Loss: 0.6462
Epoch 1000: 	Training Loss: 0.6768	Validation Loss: 0.6743
Epoch 1500: 	Training Loss: 0.6290	Validation Loss: 0.6333
Epoch 2000: 	Training Loss: 0.6302	Validation Loss: 0.6237
Epoch 2500: 	Training Loss: 0.6492	Validation Loss: 0.6543
Epoch 3000: 	Training Loss: 0.6253	Validation Loss: 0.6329
Epoch 3500: 	Training Loss: 0.6340	Validation Loss: 0.6326
Early stopping at epoch 3753
Best validation loss: 0.6160
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/GQNN_100-100_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_04_02_25_55_496083/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u15>
Subject: Job 126236021: <GQNNx100x100-0-0> in cluster <Janelia> Done

Job <GQNNx100x100-0-0> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Tue Oct  4 02:25:28 2022
Job was executed on host(s) <e10u15>, in queue <local>, as user <mohantas> in cluster <Janelia> at Tue Oct  4 02:25:29 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Tue Oct  4 02:25:29 2022
Terminated at Tue Oct  4 13:17:25 2022
Results reported at Tue Oct  4 13:17:25 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_rajagopalan.py --agent GQNN --hidden_state_sizes 100 100 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric no --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   77855.88 sec.
    Max Memory :                                 271 MB
    Average Memory :                             250.38 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15089.00 MB
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                14
    Run time :                                   39122 sec.
    Turnaround time :                            39117 sec.

The output (if any) is above this job summary.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_reward_set.csv
Model: GQNN_100-100_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_08_20_15_39_572412
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6612	Validation Loss: 0.6553
Epoch 500: 	Training Loss: 0.5937	Validation Loss: 0.6200
Epoch 1000: 	Training Loss: 0.5961	Validation Loss: 0.6184
Epoch 1500: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 2000: 	Training Loss: 0.6080	Validation Loss: 0.6319
Epoch 2500: 	Training Loss: 0.6096	Validation Loss: 0.6393
Epoch 3000: 	Training Loss: 0.6148	Validation Loss: 0.6307
Early stopping at epoch 3365
Best validation loss: 0.6167
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5988	Validation Loss: 0.6065
Epoch 500: 	Training Loss: 0.5985	Validation Loss: 0.6103
Epoch 1000: 	Training Loss: 0.5965	Validation Loss: 0.6204
Epoch 1500: 	Training Loss: 0.6036	Validation Loss: 0.6150
Epoch 2000: 	Training Loss: 0.5971	Validation Loss: 0.6095
Epoch 2500: 	Training Loss: 0.6050	Validation Loss: 0.6094
Early stopping at epoch 2534
Best validation loss: 0.6043
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5959	Validation Loss: 0.6136
Epoch 500: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 1000: 	Training Loss: 0.6159	Validation Loss: 0.6245
Epoch 1500: 	Training Loss: 0.6616	Validation Loss: 0.6438
Epoch 2000: 	Training Loss: 0.6390	Validation Loss: 0.6347
Epoch 2500: 	Training Loss: 0.6375	Validation Loss: 0.6238
Early stopping at epoch 2590
Best validation loss: 0.6095
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6009	Validation Loss: 0.5860
Epoch 500: 	Training Loss: 0.6590	Validation Loss: 0.6262
Epoch 1000: 	Training Loss: 0.6541	Validation Loss: 0.6523
Epoch 1500: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 2000: 	Training Loss: 0.6212	Validation Loss: 0.5926
Epoch 2500: 	Training Loss: 0.6138	Validation Loss: 0.5996
Early stopping at epoch 2501
Best validation loss: 0.5850
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6066	Validation Loss: 0.5727
Epoch 500: 	Training Loss: 0.6549	Validation Loss: 0.7159
Epoch 1000: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 1500: 	Training Loss: 0.6927	Validation Loss: 0.6931
Epoch 2000: 	Training Loss: 0.6087	Validation Loss: 0.5774
Epoch 2500: 	Training Loss: 0.6576	Validation Loss: 0.6231
Early stopping at epoch 2525
Best validation loss: 0.5711
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/GQNN_100-100_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_08_20_15_39_572412/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u14>
Subject: Job 126381402: <GQNNx100x100-0-0> in cluster <Janelia> Done

Job <GQNNx100x100-0-0> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Sat Oct  8 20:15:27 2022
Job was executed on host(s) <e10u14>, in queue <local>, as user <mohantas> in cluster <Janelia> at Sat Oct  8 20:15:28 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Sat Oct  8 20:15:28 2022
Terminated at Sun Oct  9 17:54:26 2022
Results reported at Sun Oct  9 17:54:26 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_mohanta.py --agent GQNN --hidden_state_sizes 100 100 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric no --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   154806.73 sec.
    Max Memory :                                 341 MB
    Average Memory :                             287.75 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15019.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   77936 sec.
    Turnaround time :                            77939 sec.

The output (if any) is above this job summary.

