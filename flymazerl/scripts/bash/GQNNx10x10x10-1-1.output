
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_reward_set.csv
Model: GQNN_10-10-10_relu_acceptreject_symmetric_qp_no-punishment_2022_10_04_02_25_23_590101
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6835	Validation Loss: 0.6781
Epoch 500: 	Training Loss: 0.6236	Validation Loss: 0.6479
Epoch 1000: 	Training Loss: 0.6223	Validation Loss: 0.6473
Epoch 1500: 	Training Loss: 0.6218	Validation Loss: 0.6510
Epoch 2000: 	Training Loss: 0.6222	Validation Loss: 0.6479
Epoch 2500: 	Training Loss: 0.6930	Validation Loss: 0.6930
Epoch 3000: 	Training Loss: 0.6229	Validation Loss: 0.6510
Epoch 3500: 	Training Loss: 0.7518	Validation Loss: 0.8870
Epoch 4000: 	Training Loss: 0.6229	Validation Loss: 0.6464
Early stopping at epoch 4423
Best validation loss: 0.6425
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6398	Validation Loss: 0.6363
Epoch 500: 	Training Loss: 0.6287	Validation Loss: 0.6333
Epoch 1000: 	Training Loss: 0.7639	Validation Loss: 0.8230
Epoch 1500: 	Training Loss: 0.6278	Validation Loss: 0.6406
Epoch 2000: 	Training Loss: 0.6272	Validation Loss: 0.6391
Epoch 2500: 	Training Loss: 0.6277	Validation Loss: 0.6431
Early stopping at epoch 2516
Best validation loss: 0.6285
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6244	Validation Loss: 0.6453
Epoch 500: 	Training Loss: 0.6255	Validation Loss: 0.6527
Epoch 1000: 	Training Loss: 0.6234	Validation Loss: 0.6494
Epoch 1500: 	Training Loss: 0.6237	Validation Loss: 0.6508
Epoch 2000: 	Training Loss: 0.6204	Validation Loss: 0.6469
Epoch 2500: 	Training Loss: 0.6264	Validation Loss: 0.6573
Epoch 3000: 	Training Loss: 0.6228	Validation Loss: 0.6534
Epoch 3500: 	Training Loss: 0.6277	Validation Loss: 0.6529
Epoch 4000: 	Training Loss: 0.6211	Validation Loss: 0.6479
Early stopping at epoch 4321
Best validation loss: 0.6427
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6274	Validation Loss: 0.6345
Epoch 500: 	Training Loss: 0.6239	Validation Loss: 0.6328
Epoch 1000: 	Training Loss: 0.6260	Validation Loss: 0.6419
Epoch 1500: 	Training Loss: 0.6261	Validation Loss: 0.6338
Epoch 2000: 	Training Loss: 0.6932	Validation Loss: 0.6932
Epoch 2500: 	Training Loss: 0.6272	Validation Loss: 0.6358
Early stopping at epoch 2800
Best validation loss: 0.6299
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6272	Validation Loss: 0.6350
Epoch 500: 	Training Loss: 0.6279	Validation Loss: 0.6438
Epoch 1000: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 1500: 	Training Loss: 0.6280	Validation Loss: 0.6364
Epoch 2000: 	Training Loss: 0.7608	Validation Loss: 0.8970
Epoch 2500: 	Training Loss: 0.6349	Validation Loss: 0.6471
Early stopping at epoch 2922
Best validation loss: 0.6305
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/GQNN_10-10-10_relu_acceptreject_symmetric_qp_no-punishment_2022_10_04_02_25_23_590101/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u27>
Subject: Job 126235767: <GQNNx10x10x10-1-1> in cluster <Janelia> Done

Job <GQNNx10x10x10-1-1> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Tue Oct  4 02:25:03 2022
Job was executed on host(s) <e10u27>, in queue <local>, as user <mohantas> in cluster <Janelia> at Tue Oct  4 02:25:06 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Tue Oct  4 02:25:06 2022
Terminated at Tue Oct  4 10:40:19 2022
Results reported at Tue Oct  4 10:40:19 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_rajagopalan.py --agent GQNN --hidden_state_sizes 10 10 10 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric yes --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   59088.17 sec.
    Max Memory :                                 266 MB
    Average Memory :                             249.87 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15094.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   29721 sec.
    Turnaround time :                            29716 sec.

The output (if any) is above this job summary.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_reward_set.csv
Model: GQNN_10-10-10_relu_acceptreject_symmetric_qp_no-punishment_2022_10_08_20_15_19_609473
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6446	Validation Loss: 0.6345
Epoch 500: 	Training Loss: 0.5962	Validation Loss: 0.6153
Epoch 1000: 	Training Loss: 0.5957	Validation Loss: 0.6170
Epoch 1500: 	Training Loss: 0.5972	Validation Loss: 0.6171
Epoch 2000: 	Training Loss: 0.5951	Validation Loss: 0.6154
Epoch 2500: 	Training Loss: 0.5949	Validation Loss: 0.6192
Epoch 3000: 	Training Loss: 0.5943	Validation Loss: 0.6166
Epoch 3500: 	Training Loss: 0.5946	Validation Loss: 0.6160
Early stopping at epoch 3556
Best validation loss: 0.6134
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6068	Validation Loss: 0.5764
Epoch 500: 	Training Loss: 0.6068	Validation Loss: 0.5778
Epoch 1000: 	Training Loss: 0.6092	Validation Loss: 0.5767
Epoch 1500: 	Training Loss: 0.6059	Validation Loss: 0.5763
Epoch 2000: 	Training Loss: 0.6078	Validation Loss: 0.5775
Epoch 2500: 	Training Loss: 0.6056	Validation Loss: 0.5759
Early stopping at epoch 2690
Best validation loss: 0.5753
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5981	Validation Loss: 0.6098
Epoch 500: 	Training Loss: 0.5967	Validation Loss: 0.6085
Epoch 1000: 	Training Loss: 0.5970	Validation Loss: 0.6102
Epoch 1500: 	Training Loss: 0.5978	Validation Loss: 0.6119
Epoch 2000: 	Training Loss: 0.5979	Validation Loss: 0.6259
Epoch 2500: 	Training Loss: 0.5975	Validation Loss: 0.6156
Early stopping at epoch 2890
Best validation loss: 0.6068
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5997	Validation Loss: 0.5994
Epoch 500: 	Training Loss: 0.6009	Validation Loss: 0.6064
Epoch 1000: 	Training Loss: 0.5993	Validation Loss: 0.6011
Epoch 1500: 	Training Loss: 0.5991	Validation Loss: 0.6004
Epoch 2000: 	Training Loss: 0.5994	Validation Loss: 0.6071
Epoch 2500: 	Training Loss: 0.6060	Validation Loss: 0.6296
Early stopping at epoch 2619
Best validation loss: 0.5985
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6022	Validation Loss: 0.5978
Epoch 500: 	Training Loss: 0.6039	Validation Loss: 0.5990
Epoch 1000: 	Training Loss: 0.6010	Validation Loss: 0.5967
Epoch 1500: 	Training Loss: 0.5992	Validation Loss: 0.5978
Epoch 2000: 	Training Loss: 0.6000	Validation Loss: 0.5970
Epoch 2500: 	Training Loss: 0.5994	Validation Loss: 0.5971
Epoch 3000: 	Training Loss: 0.6011	Validation Loss: 0.6001
Early stopping at epoch 3223
Best validation loss: 0.5956
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/GQNN_10-10-10_relu_acceptreject_symmetric_qp_no-punishment_2022_10_08_20_15_19_609473/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u18>
Subject: Job 126381371: <GQNNx10x10x10-1-1> in cluster <Janelia> Done

Job <GQNNx10x10x10-1-1> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Sat Oct  8 20:15:04 2022
Job was executed on host(s) <e10u18>, in queue <local>, as user <mohantas> in cluster <Janelia> at Sat Oct  8 20:15:05 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Sat Oct  8 20:15:05 2022
Terminated at Mon Oct 10 05:05:48 2022
Results reported at Mon Oct 10 05:05:48 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_mohanta.py --agent GQNN --hidden_state_sizes 10 10 10 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric yes --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   234598.72 sec.
    Max Memory :                                 321 MB
    Average Memory :                             264.25 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15039.00 MB
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                14
    Run time :                                   118250 sec.
    Turnaround time :                            118244 sec.

The output (if any) is above this job summary.

