
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_reward_set.csv
Model: GQNN_100-100_relu_acceptreject_symmetric_qp_no-punishment_2022_10_04_02_25_23_590104
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6709	Validation Loss: 0.6506
Epoch 500: 	Training Loss: 0.6316	Validation Loss: 0.6155
Epoch 1000: 	Training Loss: 0.6297	Validation Loss: 0.6172
Epoch 1500: 	Training Loss: 0.6325	Validation Loss: 0.6155
Epoch 2000: 	Training Loss: 0.6341	Validation Loss: 0.6154
Epoch 2500: 	Training Loss: 0.6932	Validation Loss: 0.6932
Early stopping at epoch 2748
Best validation loss: 0.6104
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6352	Validation Loss: 0.6177
Epoch 500: 	Training Loss: 0.6281	Validation Loss: 0.6272
Epoch 1000: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 1500: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 2000: 	Training Loss: 0.6260	Validation Loss: 0.6288
Epoch 2500: 	Training Loss: 0.6560	Validation Loss: 0.6509
Early stopping at epoch 2500
Best validation loss: 0.6177
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6220	Validation Loss: 0.7054
Epoch 500: 	Training Loss: 0.6489	Validation Loss: 0.6777
Epoch 1000: 	Training Loss: 0.6124	Validation Loss: 0.6885
Epoch 1500: 	Training Loss: 0.6248	Validation Loss: 0.6839
Epoch 2000: 	Training Loss: 0.6152	Validation Loss: 0.6860
Epoch 2500: 	Training Loss: 0.6533	Validation Loss: 0.6880
Epoch 3000: 	Training Loss: 0.6490	Validation Loss: 0.6765
Epoch 3500: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 4000: 	Training Loss: 0.6118	Validation Loss: 0.6867
Early stopping at epoch 4466
Best validation loss: 0.6728
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6336	Validation Loss: 0.6399
Epoch 500: 	Training Loss: 0.6287	Validation Loss: 0.6415
Epoch 1000: 	Training Loss: 0.6268	Validation Loss: 0.6384
Epoch 1500: 	Training Loss: 0.6544	Validation Loss: 0.6609
Epoch 2000: 	Training Loss: 0.6534	Validation Loss: 0.6607
Epoch 2500: 	Training Loss: 0.6241	Validation Loss: 0.6397
Epoch 3000: 	Training Loss: 0.6312	Validation Loss: 0.6365
Epoch 3500: 	Training Loss: 0.6932	Validation Loss: 0.6931
Epoch 4000: 	Training Loss: 0.6270	Validation Loss: 0.6371
Epoch 4500: 	Training Loss: 0.6262	Validation Loss: 0.6375
Epoch 5000: 	Training Loss: 0.6229	Validation Loss: 0.6359
Epoch 5500: 	Training Loss: 0.6932	Validation Loss: 0.6931
Epoch 6000: 	Training Loss: 0.6238	Validation Loss: 0.6360
Epoch 6500: 	Training Loss: 0.6248	Validation Loss: 0.6376
Epoch 7000: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 7500: 	Training Loss: 0.6262	Validation Loss: 0.6368
Epoch 8000: 	Training Loss: 0.6272	Validation Loss: 0.6445
Epoch 8500: 	Training Loss: 0.6218	Validation Loss: 0.6421
Early stopping at epoch 8747
Best validation loss: 0.6289
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6478	Validation Loss: 0.6240
Epoch 500: 	Training Loss: 0.6335	Validation Loss: 0.6249
Epoch 1000: 	Training Loss: 0.6553	Validation Loss: 0.6209
Epoch 1500: 	Training Loss: 0.6427	Validation Loss: 0.6295
Epoch 2000: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 2500: 	Training Loss: 0.6327	Validation Loss: 0.6180
Early stopping at epoch 2543
Best validation loss: 0.6146
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/GQNN_100-100_relu_acceptreject_symmetric_qp_no-punishment_2022_10_04_02_25_23_590104/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u27>
Subject: Job 126235744: <GQNNx100x100-0-1> in cluster <Janelia> Done

Job <GQNNx100x100-0-1> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Tue Oct  4 02:25:00 2022
Job was executed on host(s) <e10u27>, in queue <local>, as user <mohantas> in cluster <Janelia> at Tue Oct  4 02:25:06 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Tue Oct  4 02:25:06 2022
Terminated at Tue Oct  4 12:29:40 2022
Results reported at Tue Oct  4 12:29:40 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_rajagopalan.py --agent GQNN --hidden_state_sizes 100 100 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric yes --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   72128.88 sec.
    Max Memory :                                 280 MB
    Average Memory :                             254.50 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15080.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   36283 sec.
    Turnaround time :                            36280 sec.

The output (if any) is above this job summary.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_reward_set.csv
Model: GQNN_100-100_relu_acceptreject_symmetric_qp_no-punishment_2022_10_08_20_15_19_609469
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6216	Validation Loss: 0.6333
Epoch 500: 	Training Loss: 0.5948	Validation Loss: 0.6238
Epoch 1000: 	Training Loss: 0.5940	Validation Loss: 0.6230
Epoch 1500: 	Training Loss: 0.5971	Validation Loss: 0.6327
Epoch 2000: 	Training Loss: 0.5966	Validation Loss: 0.6264
Epoch 2500: 	Training Loss: 0.6025	Validation Loss: 0.6276
Epoch 3000: 	Training Loss: 0.5941	Validation Loss: 0.6228
Epoch 3500: 	Training Loss: 0.6153	Validation Loss: 0.6235
Epoch 4000: 	Training Loss: 0.5976	Validation Loss: 0.6255
Epoch 4500: 	Training Loss: 0.5993	Validation Loss: 0.6254
Early stopping at epoch 4731
Best validation loss: 0.6206
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5999	Validation Loss: 0.6018
Epoch 500: 	Training Loss: 0.5989	Validation Loss: 0.6006
Epoch 1000: 	Training Loss: 0.6004	Validation Loss: 0.6005
Epoch 1500: 	Training Loss: 0.5997	Validation Loss: 0.6017
Epoch 2000: 	Training Loss: 0.5991	Validation Loss: 0.6019
Epoch 2500: 	Training Loss: 0.6008	Validation Loss: 0.6018
Early stopping at epoch 2635
Best validation loss: 0.5994
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6109	Validation Loss: 0.5600
Epoch 500: 	Training Loss: 0.6144	Validation Loss: 0.5597
Epoch 1000: 	Training Loss: 0.6123	Validation Loss: 0.5638
Epoch 1500: 	Training Loss: 0.6114	Validation Loss: 0.5601
Epoch 2000: 	Training Loss: 0.6098	Validation Loss: 0.5611
Epoch 2500: 	Training Loss: 0.6236	Validation Loss: 0.5737
Epoch 3000: 	Training Loss: 0.6096	Validation Loss: 0.5600
Early stopping at epoch 3198
Best validation loss: 0.5583
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6028	Validation Loss: 0.5889
Epoch 500: 	Training Loss: 0.6027	Validation Loss: 0.5891
Epoch 1000: 	Training Loss: 0.6017	Validation Loss: 0.5889
Epoch 1500: 	Training Loss: 0.6072	Validation Loss: 0.5930
Epoch 2000: 	Training Loss: 0.6047	Validation Loss: 0.5909
Epoch 2500: 	Training Loss: 0.6018	Validation Loss: 0.5884
Epoch 3000: 	Training Loss: 0.6041	Validation Loss: 0.6003
Early stopping at epoch 3401
Best validation loss: 0.5876
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6082	Validation Loss: 0.5809
Epoch 500: 	Training Loss: 0.6101	Validation Loss: 0.5841
Epoch 1000: 	Training Loss: 0.6298	Validation Loss: 0.6504
Epoch 1500: 	Training Loss: 0.6458	Validation Loss: 0.6194
Epoch 2000: 	Training Loss: 0.7811	Validation Loss: 0.8312
Epoch 2500: 	Training Loss: 0.6931	Validation Loss: 0.6932
Early stopping at epoch 2503
Best validation loss: 0.5788
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/GQNN_100-100_relu_acceptreject_symmetric_qp_no-punishment_2022_10_08_20_15_19_609469/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u18>
Subject: Job 126381366: <GQNNx100x100-0-1> in cluster <Janelia> Done

Job <GQNNx100x100-0-1> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Sat Oct  8 20:15:01 2022
Job was executed on host(s) <e10u18>, in queue <local>, as user <mohantas> in cluster <Janelia> at Sat Oct  8 20:15:03 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Sat Oct  8 20:15:03 2022
Terminated at Mon Oct 10 07:38:08 2022
Results reported at Mon Oct 10 07:38:08 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_mohanta.py --agent GQNN --hidden_state_sizes 100 100 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric yes --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   252882.66 sec.
    Max Memory :                                 370 MB
    Average Memory :                             284.73 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               14990.00 MB
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                14
    Run time :                                   127389 sec.
    Turnaround time :                            127387 sec.

The output (if any) is above this job summary.

