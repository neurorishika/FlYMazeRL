
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GRNNLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_reward_set.csv
Model: GRNN_1x10_RNN_acceptreject_asymmetric_qp_no-punishment_2022_10_04_02_17_35_300316
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6981	Validation Loss: 0.6902
Epoch 500: 	Training Loss: 0.5892	Validation Loss: 0.6618
Epoch 1000: 	Training Loss: 0.6174	Validation Loss: 0.6507
Epoch 1500: 	Training Loss: 0.6224	Validation Loss: 0.6370
Epoch 2000: 	Training Loss: 0.6462	Validation Loss: 0.6510
Epoch 2500: 	Training Loss: 0.6155	Validation Loss: 0.6438
Epoch 3000: 	Training Loss: 0.6271	Validation Loss: 0.6494
Epoch 3500: 	Training Loss: 0.6356	Validation Loss: 0.6522
Epoch 4000: 	Training Loss: 0.6190	Validation Loss: 0.6483
Early stopping at epoch 4048
Best validation loss: 0.6262
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6841	Validation Loss: 0.6862
Epoch 500: 	Training Loss: 0.6137	Validation Loss: 0.6279
Epoch 1000: 	Training Loss: 0.6638	Validation Loss: 0.6656
Epoch 1500: 	Training Loss: 0.6240	Validation Loss: 0.6307
Epoch 2000: 	Training Loss: 0.6195	Validation Loss: 0.6353
Epoch 2500: 	Training Loss: 0.6214	Validation Loss: 0.6317
Early stopping at epoch 2935
Best validation loss: 0.6215
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6837	Validation Loss: 0.6833
Epoch 500: 	Training Loss: 0.6025	Validation Loss: 0.6714
Epoch 1000: 	Training Loss: 0.6257	Validation Loss: 0.6440
Epoch 1500: 	Training Loss: 0.6297	Validation Loss: 0.6497
Epoch 2000: 	Training Loss: 0.6226	Validation Loss: 0.6452
Epoch 2500: 	Training Loss: 0.6300	Validation Loss: 0.6663
Epoch 3000: 	Training Loss: 0.6481	Validation Loss: 0.6619
Epoch 3500: 	Training Loss: 0.6177	Validation Loss: 0.6452
Early stopping at epoch 3833
Best validation loss: 0.6351
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6839	Validation Loss: 0.6804
Epoch 500: 	Training Loss: 0.6092	Validation Loss: 0.6598
Epoch 1000: 	Training Loss: 0.6030	Validation Loss: 0.6650
Epoch 1500: 	Training Loss: 0.6180	Validation Loss: 0.6719
Epoch 2000: 	Training Loss: 0.6099	Validation Loss: 0.6776
Epoch 2500: 	Training Loss: 0.6609	Validation Loss: 0.6921
Epoch 3000: 	Training Loss: 0.6588	Validation Loss: 0.6927
Epoch 3500: 	Training Loss: 0.6484	Validation Loss: 0.6943
Epoch 4000: 	Training Loss: 0.6484	Validation Loss: 0.6969
Early stopping at epoch 4042
Best validation loss: 0.6546
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6923	Validation Loss: 0.6876
Epoch 500: 	Training Loss: 0.6113	Validation Loss: 0.6663
Epoch 1000: 	Training Loss: 0.6289	Validation Loss: 0.6425
Epoch 1500: 	Training Loss: 0.6180	Validation Loss: 0.6472
Epoch 2000: 	Training Loss: 0.6445	Validation Loss: 0.6735
Epoch 2500: 	Training Loss: 0.6409	Validation Loss: 0.6601
Epoch 3000: 	Training Loss: 0.6620	Validation Loss: 0.6712
Epoch 3500: 	Training Loss: 0.6562	Validation Loss: 0.6729
Early stopping at epoch 3693
Best validation loss: 0.6385
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/GRNN_1x10_RNN_acceptreject_asymmetric_qp_no-punishment_2022_10_04_02_17_35_300316/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u12>
Subject: Job 126232922: <GRNNx10-1-0> in cluster <Janelia> Done

Job <GRNNx10-1-0> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Tue Oct  4 02:17:08 2022
Job was executed on host(s) <e10u12>, in queue <local>, as user <mohantas> in cluster <Janelia> at Tue Oct  4 02:17:09 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Tue Oct  4 02:17:09 2022
Terminated at Tue Oct  4 03:20:18 2022
Results reported at Tue Oct  4 03:20:18 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_rajagopalan.py --agent GRNN --num_reservoir 1 --reservoir_size 10 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric no --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   7476.00 sec.
    Max Memory :                                 246 MB
    Average Memory :                             232.21 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15114.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   3792 sec.
    Turnaround time :                            3790 sec.

The output (if any) is above this job summary.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GRNNLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_reward_set.csv
Model: GRNN_1x10_RNN_acceptreject_asymmetric_qp_no-punishment_2022_10_08_20_14_45_134390
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6898	Validation Loss: 0.6683
Epoch 500: 	Training Loss: 0.5972	Validation Loss: 0.5936
Epoch 1000: 	Training Loss: 0.6058	Validation Loss: 0.5914
Epoch 1500: 	Training Loss: 0.6027	Validation Loss: 0.5879
Epoch 2000: 	Training Loss: 0.6224	Validation Loss: 0.5952
Epoch 2500: 	Training Loss: 0.6185	Validation Loss: 0.5963
Epoch 3000: 	Training Loss: 0.6432	Validation Loss: 0.6196
Epoch 3500: 	Training Loss: 0.6471	Validation Loss: 0.6222
Epoch 4000: 	Training Loss: 0.6248	Validation Loss: 0.6027
Early stopping at epoch 4483
Best validation loss: 0.5816
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6660	Validation Loss: 0.6097
Epoch 500: 	Training Loss: 0.6048	Validation Loss: 0.5690
Epoch 1000: 	Training Loss: 0.6098	Validation Loss: 0.5751
Epoch 1500: 	Training Loss: 0.6104	Validation Loss: 0.5753
Epoch 2000: 	Training Loss: 0.6032	Validation Loss: 0.5698
Epoch 2500: 	Training Loss: 0.6059	Validation Loss: 0.5741
Early stopping at epoch 2554
Best validation loss: 0.5657
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6528	Validation Loss: 0.6358
Epoch 500: 	Training Loss: 0.5850	Validation Loss: 0.6287
Epoch 1000: 	Training Loss: 0.5987	Validation Loss: 0.6127
Epoch 1500: 	Training Loss: 0.5966	Validation Loss: 0.6132
Epoch 2000: 	Training Loss: 0.5927	Validation Loss: 0.6091
Epoch 2500: 	Training Loss: 0.6345	Validation Loss: 0.6332
Early stopping at epoch 2521
Best validation loss: 0.6052
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6636	Validation Loss: 0.5823
Epoch 500: 	Training Loss: 0.6040	Validation Loss: 0.5643
Epoch 1000: 	Training Loss: 0.6039	Validation Loss: 0.5511
Epoch 1500: 	Training Loss: 0.6119	Validation Loss: 0.5504
Epoch 2000: 	Training Loss: 0.6104	Validation Loss: 0.5555
Epoch 2500: 	Training Loss: 0.6216	Validation Loss: 0.5536
Early stopping at epoch 2519
Best validation loss: 0.5432
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6676	Validation Loss: 0.6124
Epoch 500: 	Training Loss: 0.5939	Validation Loss: 0.5887
Epoch 1000: 	Training Loss: 0.6022	Validation Loss: 0.5808
Epoch 1500: 	Training Loss: 0.6020	Validation Loss: 0.5840
Epoch 2000: 	Training Loss: 0.6093	Validation Loss: 0.5865
Epoch 2500: 	Training Loss: 0.6104	Validation Loss: 0.5836
Early stopping at epoch 2530
Best validation loss: 0.5748
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/GRNN_1x10_RNN_acceptreject_asymmetric_qp_no-punishment_2022_10_08_20_14_45_134390/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u10>
Subject: Job 126381331: <GRNNx10-1-0> in cluster <Janelia> Done

Job <GRNNx10-1-0> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Sat Oct  8 20:14:36 2022
Job was executed on host(s) <e10u10>, in queue <local>, as user <mohantas> in cluster <Janelia> at Sat Oct  8 20:14:36 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Sat Oct  8 20:14:36 2022
Terminated at Sat Oct  8 23:29:06 2022
Results reported at Sat Oct  8 23:29:06 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_mohanta.py --agent GRNN --num_reservoir 1 --reservoir_size 10 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric no --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   22811.66 sec.
    Max Memory :                                 308 MB
    Average Memory :                             249.16 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15052.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   11668 sec.
    Turnaround time :                            11670 sec.

The output (if any) is above this job summary.

