
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_reward_set.csv
Model: GQNN_100-100_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_04_02_25_55_496081
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6762	Validation Loss: 0.6500
Epoch 500: 	Training Loss: 0.6402	Validation Loss: 0.6100
Epoch 1000: 	Training Loss: 0.6583	Validation Loss: 0.6444
Epoch 1500: 	Training Loss: 0.6784	Validation Loss: 0.6634
Epoch 2000: 	Training Loss: 0.6429	Validation Loss: 0.6087
Epoch 2500: 	Training Loss: 0.6466	Validation Loss: 0.6157
Epoch 3000: 	Training Loss: 0.6428	Validation Loss: 0.6100
Epoch 3500: 	Training Loss: 0.6660	Validation Loss: 0.6565
Epoch 4000: 	Training Loss: 0.6924	Validation Loss: 0.6927
Epoch 4500: 	Training Loss: 0.6368	Validation Loss: 0.6073
Epoch 5000: 	Training Loss: 0.6395	Validation Loss: 0.6067
Early stopping at epoch 5305
Best validation loss: 0.6014
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6329	Validation Loss: 0.6339
Epoch 500: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 1000: 	Training Loss: 0.7634	Validation Loss: 0.8289
Epoch 1500: 	Training Loss: 0.6805	Validation Loss: 0.6606
Epoch 2000: 	Training Loss: 0.6784	Validation Loss: 0.6596
Epoch 2500: 	Training Loss: 0.6273	Validation Loss: 0.6295
Early stopping at epoch 2501
Best validation loss: 0.6209
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6241	Validation Loss: 0.6730
Epoch 500: 	Training Loss: 0.6725	Validation Loss: 0.6866
Epoch 1000: 	Training Loss: 0.6241	Validation Loss: 0.6759
Epoch 1500: 	Training Loss: 0.6532	Validation Loss: 0.6788
Epoch 2000: 	Training Loss: 0.6735	Validation Loss: 0.6873
Epoch 2500: 	Training Loss: 0.7773	Validation Loss: 0.7802
Early stopping at epoch 2505
Best validation loss: 0.6660
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6329	Validation Loss: 0.6218
Epoch 500: 	Training Loss: 0.6740	Validation Loss: 0.6729
Epoch 1000: 	Training Loss: 0.7730	Validation Loss: 0.7952
Epoch 1500: 	Training Loss: 0.6407	Validation Loss: 0.6463
Epoch 2000: 	Training Loss: 0.6468	Validation Loss: 0.6542
Epoch 2500: 	Training Loss: 0.6498	Validation Loss: 0.6565
Early stopping at epoch 2508
Best validation loss: 0.6130
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6339	Validation Loss: 0.6179
Epoch 500: 	Training Loss: 0.6402	Validation Loss: 0.6238
Epoch 1000: 	Training Loss: 0.6619	Validation Loss: 0.6514
Epoch 1500: 	Training Loss: 0.6638	Validation Loss: 0.6523
Epoch 2000: 	Training Loss: 0.6644	Validation Loss: 0.6521
Epoch 2500: 	Training Loss: 0.6364	Validation Loss: 0.6267
Early stopping at epoch 2519
Best validation loss: 0.6112
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/GQNN_100-100_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_04_02_25_55_496081/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u15>
Subject: Job 126236025: <GQNNx100x100-3-0> in cluster <Janelia> Done

Job <GQNNx100x100-3-0> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Tue Oct  4 02:25:29 2022
Job was executed on host(s) <e10u15>, in queue <local>, as user <mohantas> in cluster <Janelia> at Tue Oct  4 02:25:40 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Tue Oct  4 02:25:40 2022
Terminated at Tue Oct  4 10:56:42 2022
Results reported at Tue Oct  4 10:56:42 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_rajagopalan.py --agent GQNN --hidden_state_sizes 100 100 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric no --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   61032.06 sec.
    Max Memory :                                 269 MB
    Average Memory :                             250.22 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15091.00 MB
    Max Swap :                                   -
    Max Processes :                              5
    Max Threads :                                14
    Run time :                                   30677 sec.
    Turnaround time :                            30673 sec.

The output (if any) is above this job summary.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GQLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_reward_set.csv
Model: GQNN_100-100_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_08_20_15_39_952409
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6401	Validation Loss: 0.7133
Epoch 500: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 1000: 	Training Loss: 0.5873	Validation Loss: 0.6603
Epoch 1500: 	Training Loss: 0.6063	Validation Loss: 0.6889
Epoch 2000: 	Training Loss: 0.5864	Validation Loss: 0.6639
Epoch 2500: 	Training Loss: 0.5858	Validation Loss: 0.6663
Epoch 3000: 	Training Loss: 0.6403	Validation Loss: 0.6706
Epoch 3500: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 4000: 	Training Loss: 0.6931	Validation Loss: 0.6931
Early stopping at epoch 4026
Best validation loss: 0.6581
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6097	Validation Loss: 0.5972
Epoch 500: 	Training Loss: 0.6134	Validation Loss: 0.5986
Epoch 1000: 	Training Loss: 0.6050	Validation Loss: 0.5911
Epoch 1500: 	Training Loss: 0.6371	Validation Loss: 0.6344
Epoch 2000: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 2500: 	Training Loss: 0.6505	Validation Loss: 0.6462
Epoch 3000: 	Training Loss: 0.6094	Validation Loss: 0.5943
Epoch 3500: 	Training Loss: 0.6622	Validation Loss: 0.6669
Early stopping at epoch 3773
Best validation loss: 0.5869
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.5963	Validation Loss: 0.6238
Epoch 500: 	Training Loss: 0.6492	Validation Loss: 0.6753
Epoch 1000: 	Training Loss: 0.6617	Validation Loss: 0.6672
Epoch 1500: 	Training Loss: 0.6421	Validation Loss: 0.6574
Epoch 2000: 	Training Loss: 0.6712	Validation Loss: 0.6793
Epoch 2500: 	Training Loss: 0.6931	Validation Loss: 0.6931
Early stopping at epoch 2502
Best validation loss: 0.6235
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6031	Validation Loss: 0.6065
Epoch 500: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 1000: 	Training Loss: 0.6929	Validation Loss: 0.6666
Epoch 1500: 	Training Loss: 0.6599	Validation Loss: 0.6454
Epoch 2000: 	Training Loss: 0.6589	Validation Loss: 0.6661
Epoch 2500: 	Training Loss: 0.6639	Validation Loss: 0.6645
Early stopping at epoch 2611
Best validation loss: 0.6017
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6100	Validation Loss: 0.5719
Epoch 500: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 1000: 	Training Loss: 0.6812	Validation Loss: 0.6524
Epoch 1500: 	Training Loss: 0.6547	Validation Loss: 0.6349
Epoch 2000: 	Training Loss: 0.6079	Validation Loss: 0.5679
Epoch 2500: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 3000: 	Training Loss: 0.6778	Validation Loss: 0.6267
Epoch 3500: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 4000: 	Training Loss: 0.6836	Validation Loss: 0.6931
Early stopping at epoch 4477
Best validation loss: 0.5639
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/GQNN_100-100_relu_acceptreject_asymmetric_qp_no-punishment_2022_10_08_20_15_39_952409/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u14>
Subject: Job 126381405: <GQNNx100x100-3-0> in cluster <Janelia> Done

Job <GQNNx100x100-3-0> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Sat Oct  8 20:15:29 2022
Job was executed on host(s) <e10u14>, in queue <local>, as user <mohantas> in cluster <Janelia> at Sat Oct  8 20:15:31 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Sat Oct  8 20:15:31 2022
Terminated at Sun Oct  9 23:07:59 2022
Results reported at Sun Oct  9 23:07:59 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_mohanta.py --agent GQNN --hidden_state_sizes 100 100 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric no --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   192212.30 sec.
    Max Memory :                                 370 MB
    Average Memory :                             293.66 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               14990.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   96750 sec.
    Turnaround time :                            96750 sec.

The output (if any) is above this job summary.

