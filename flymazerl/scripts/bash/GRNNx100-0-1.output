/groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash/../nn_fitting_rajagopalan.py:336: RuntimeWarning: divide by zero encountered in log
  np.log(1 - pred_action_prob[obs_actions == 0])
/groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash/../nn_fitting_rajagopalan.py:336: RuntimeWarning: divide by zero encountered in log
  np.log(1 - pred_action_prob[obs_actions == 0])
/groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash/../nn_fitting_rajagopalan.py:336: RuntimeWarning: divide by zero encountered in log
  np.log(1 - pred_action_prob[obs_actions == 0])
/groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash/../nn_fitting_rajagopalan.py:336: RuntimeWarning: divide by zero encountered in log
  np.log(1 - pred_action_prob[obs_actions == 0])
/groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash/../nn_fitting_rajagopalan.py:336: RuntimeWarning: divide by zero encountered in log
  np.log(1 - pred_action_prob[obs_actions == 0])
/groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash/../nn_fitting_rajagopalan.py:336: RuntimeWarning: divide by zero encountered in log
  np.log(1 - pred_action_prob[obs_actions == 0])
/groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash/../nn_fitting_rajagopalan.py:336: RuntimeWarning: divide by zero encountered in log
  np.log(1 - pred_action_prob[obs_actions == 0])
/groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash/../nn_fitting_rajagopalan.py:336: RuntimeWarning: divide by zero encountered in log
  np.log(1 - pred_action_prob[obs_actions == 0])

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GRNNLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/rajagopalan2022/training_reward_set.csv
Model: GRNN_1x100_RNN_acceptreject_symmetric_qp_no-punishment_2022_10_04_02_23_52_653610
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6639	Validation Loss: 0.6733
Epoch 500: 	Training Loss: 0.6121	Validation Loss: 0.6713
Epoch 1000: 	Training Loss: 0.6204	Validation Loss: 0.6847
Epoch 1500: 	Training Loss: 0.6177	Validation Loss: 0.6858
Epoch 2000: 	Training Loss: 0.6324	Validation Loss: 0.6863
Epoch 2500: 	Training Loss: 0.6183	Validation Loss: 0.6889
Epoch 3000: 	Training Loss: 0.6373	Validation Loss: 0.6751
Early stopping at epoch 3392
Best validation loss: 0.6610
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6694	Validation Loss: 0.6661
Epoch 500: 	Training Loss: 0.6276	Validation Loss: 0.6581
Epoch 1000: 	Training Loss: 0.6288	Validation Loss: 0.6520
Epoch 1500: 	Training Loss: 0.6191	Validation Loss: 0.6590
Epoch 2000: 	Training Loss: 0.6091	Validation Loss: 0.6838
Epoch 2500: 	Training Loss: 0.5961	Validation Loss: 0.6573
Epoch 3000: 	Training Loss: 0.6441	Validation Loss: 0.6637
Epoch 3500: 	Training Loss: 0.6368	Validation Loss: 0.6682
Epoch 4000: 	Training Loss: 0.6427	Validation Loss: 0.6770
Epoch 4500: 	Training Loss: 0.6502	Validation Loss: 0.6767
Epoch 5000: 	Training Loss: 0.6393	Validation Loss: 0.6666
Early stopping at epoch 5016
Best validation loss: 0.6431
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6817	Validation Loss: 0.6129
Epoch 500: 	Training Loss: 0.6881	Validation Loss: 0.6482
Epoch 1000: 	Training Loss: 0.6739	Validation Loss: 0.6407
Epoch 1500: 	Training Loss: 0.6527	Validation Loss: 0.6205
Epoch 2000: 	Training Loss: 0.6518	Validation Loss: 0.6375
Epoch 2500: 	Training Loss: 0.6594	Validation Loss: 0.6359
Early stopping at epoch 2555
Best validation loss: 0.5939
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6830	Validation Loss: 0.6921
Epoch 500: 	Training Loss: 0.6606	Validation Loss: 0.6847
Epoch 1000: 	Training Loss: 0.6069	Validation Loss: 0.6883
Epoch 1500: 	Training Loss: 0.6252	Validation Loss: 0.6764
Epoch 2000: 	Training Loss: 0.6381	Validation Loss: 0.6919
Epoch 2500: 	Training Loss: 0.6290	Validation Loss: 0.6954
Epoch 3000: 	Training Loss: 0.6140	Validation Loss: 0.6741
Epoch 3500: 	Training Loss: 0.6172	Validation Loss: 0.6945
Epoch 4000: 	Training Loss: 0.6280	Validation Loss: 0.6852
Early stopping at epoch 4036
Best validation loss: 0.6647
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6591	Validation Loss: 0.6682
Epoch 500: 	Training Loss: 0.6353	Validation Loss: 0.6685
Epoch 1000: 	Training Loss: 0.6189	Validation Loss: 0.6685
Epoch 1500: 	Training Loss: 0.6388	Validation Loss: 0.6720
Epoch 2000: 	Training Loss: 0.6517	Validation Loss: 0.6985
Epoch 2500: 	Training Loss: 0.6287	Validation Loss: 0.6764
Epoch 3000: 	Training Loss: 0.6015	Validation Loss: 0.6810
Early stopping at epoch 3470
Best validation loss: 0.6483
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/GRNN_1x100_RNN_acceptreject_symmetric_qp_no-punishment_2022_10_04_02_23_52_653610/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u04>
Subject: Job 126235174: <GRNNx100-0-1> in cluster <Janelia> Done

Job <GRNNx100-0-1> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Tue Oct  4 02:23:27 2022
Job was executed on host(s) <e10u04>, in queue <local>, as user <mohantas> in cluster <Janelia> at Tue Oct  4 02:23:28 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Tue Oct  4 02:23:28 2022
Terminated at Tue Oct  4 04:11:16 2022
Results reported at Tue Oct  4 04:11:16 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_rajagopalan.py --agent GRNN --num_reservoir 1 --reservoir_size 100 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric yes --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/rajagopalan2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   12822.63 sec.
    Max Memory :                                 268 MB
    Average Memory :                             241.73 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               15092.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                14
    Run time :                                   6471 sec.
    Turnaround time :                            6469 sec.

The output (if any) is above this job summary.


++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
███████╗██╗     ██╗   ██╗███╗   ███╗ █████╗ ███████╗███████╗██████╗ ██╗     
██╔════╝██║     ╚██╗ ██╔╝████╗ ████║██╔══██╗╚══███╔╝██╔════╝██╔══██╗██║     
█████╗  ██║      ╚████╔╝ ██╔████╔██║███████║  ███╔╝ █████╗  ██████╔╝██║     
██╔══╝  ██║       ╚██╔╝  ██║╚██╔╝██║██╔══██║ ███╔╝  ██╔══╝  ██╔══██╗██║     
██║     ███████╗   ██║   ██║ ╚═╝ ██║██║  ██║███████╗███████╗██║  ██║███████╗
╚═╝     ╚══════╝   ╚═╝   ╚═╝     ╚═╝╚═╝  ╚═╝╚══════╝╚══════╝╚═╝  ╚═╝╚══════╝
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Developed by:
    Rishika Mohanta, Research Technician, Turner Lab, Janelia Research Campus

Fitting agent: GRNNLearner
Loading data from:
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_choice_set.csv
/groups/turner/home/mohantas/project/FlYMazeRL//data/mohanta2022/training_reward_set.csv
Model: GRNN_1x100_RNN_acceptreject_symmetric_qp_no-punishment_2022_10_08_20_12_13_736567
Fitting model 1/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6779	Validation Loss: 0.6527
Epoch 500: 	Training Loss: 0.6931	Validation Loss: 0.6932
Epoch 1000: 	Training Loss: 0.6068	Validation Loss: 0.6433
Epoch 1500: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 2000: 	Training Loss: 0.6050	Validation Loss: 0.6408
Epoch 2500: 	Training Loss: 0.6038	Validation Loss: 0.6570
Early stopping at epoch 2878
Best validation loss: 0.6331
Fitting model 2/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6339	Validation Loss: 0.6589
Epoch 500: 	Training Loss: 0.6931	Validation Loss: 0.6931
Epoch 1000: 	Training Loss: 0.6073	Validation Loss: 0.6297
Epoch 1500: 	Training Loss: 0.6033	Validation Loss: 0.6241
Epoch 2000: 	Training Loss: 0.6085	Validation Loss: 0.6258
Epoch 2500: 	Training Loss: 0.6017	Validation Loss: 0.6218
Epoch 3000: 	Training Loss: 0.6931	Validation Loss: 0.6932
Epoch 3500: 	Training Loss: 0.6598	Validation Loss: 0.6705
Epoch 4000: 	Training Loss: 0.6244	Validation Loss: 0.6396
Early stopping at epoch 4218
Best validation loss: 0.6172
Fitting model 3/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6365	Validation Loss: 0.6234
Epoch 500: 	Training Loss: 0.6132	Validation Loss: 0.6202
Epoch 1000: 	Training Loss: 0.6218	Validation Loss: 0.6226
Epoch 1500: 	Training Loss: 0.6092	Validation Loss: 0.6185
Epoch 2000: 	Training Loss: 0.6139	Validation Loss: 0.6210
Epoch 2500: 	Training Loss: 0.6099	Validation Loss: 0.6158
Epoch 3000: 	Training Loss: 0.6886	Validation Loss: 0.6937
Epoch 3500: 	Training Loss: 0.6369	Validation Loss: 0.6420
Epoch 4000: 	Training Loss: 0.6621	Validation Loss: 0.6617
Epoch 4500: 	Training Loss: 0.6931	Validation Loss: 0.6931
Early stopping at epoch 4696
Best validation loss: 0.6063
Fitting model 4/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6794	Validation Loss: 0.6623
Epoch 500: 	Training Loss: 0.6076	Validation Loss: 0.6350
Epoch 1000: 	Training Loss: 0.6131	Validation Loss: 0.6351
Epoch 1500: 	Training Loss: 0.6897	Validation Loss: 0.6939
Epoch 2000: 	Training Loss: 0.6943	Validation Loss: 0.6936
Epoch 2500: 	Training Loss: 0.6025	Validation Loss: 0.6262
Epoch 3000: 	Training Loss: 0.6448	Validation Loss: 0.6788
Epoch 3500: 	Training Loss: 0.6055	Validation Loss: 0.6299
Epoch 4000: 	Training Loss: 0.6460	Validation Loss: 0.6543
Epoch 4500: 	Training Loss: 0.6075	Validation Loss: 0.6355
Epoch 5000: 	Training Loss: 0.6111	Validation Loss: 0.6511
Early stopping at epoch 5041
Best validation loss: 0.6234
Fitting model 5/5. Fold 1/1
Epoch 0: 	Training Loss: 0.6345	Validation Loss: 0.5955
Epoch 500: 	Training Loss: 0.6198	Validation Loss: 0.5843
Epoch 1000: 	Training Loss: 0.6299	Validation Loss: 0.5936
Epoch 1500: 	Training Loss: 0.6228	Validation Loss: 0.5923
Epoch 2000: 	Training Loss: 0.6820	Validation Loss: 0.6892
Epoch 2500: 	Training Loss: 0.6602	Validation Loss: 0.6425
Early stopping at epoch 2645
Best validation loss: 0.5790
Fitting is complete. The model fitting log is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/model_fitting_log.csv.
The model is available at /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/GRNN_1x100_RNN_acceptreject_symmetric_qp_no-punishment_2022_10_08_20_12_13_736567/.
Thank you for using flymazerl. Have a nice day :)

------------------------------------------------------------
Sender: LSF System <lsfadmin@e10u28>
Subject: Job 126381310: <GRNNx100-0-1> in cluster <Janelia> Done

Job <GRNNx100-0-1> was submitted from host <e05u15> by user <mohantas> in cluster <Janelia> at Sat Oct  8 20:11:37 2022
Job was executed on host(s) <e10u28>, in queue <local>, as user <mohantas> in cluster <Janelia> at Sat Oct  8 20:11:37 2022
</groups/turner/home/mohantas> was used as the home directory.
</groups/turner/home/mohantas/project/FlYMazeRL/flymazerl/scripts/bash> was used as the working directory.
Started at Sat Oct  8 20:11:37 2022
Terminated at Sun Oct  9 03:49:33 2022
Results reported at Sun Oct  9 03:49:33 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python ../nn_fitting_mohanta.py --agent GRNN --num_reservoir 1 --reservoir_size 100 --n_folds 1 --n_ensemble 5 --early_stopping 2500 --symmetric yes --save_path /groups/turner/turnerlab/Rishika/FlYMazeRL_Fits/nn/mohanta2022/ 
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   54118.05 sec.
    Max Memory :                                 365 MB
    Average Memory :                             273.97 MB
    Total Requested Memory :                     15360.00 MB
    Delta Memory :                               14995.00 MB
    Max Swap :                                   -
    Max Processes :                              6
    Max Threads :                                15
    Run time :                                   27479 sec.
    Turnaround time :                            27476 sec.

The output (if any) is above this job summary.

