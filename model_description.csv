Model Category,Model,ModelAbv,Variant,Parameter Name,Parameter Type,Description,Prior Distribution,Default Prior Distribution,AgentClass,SHORTCODE,FittingExtras,OptimizationAlgorithm,FitDir,RPE,Forgetting,Future Discounting,Perseverance,On-Policy
Value-Based RL,RPE-free Q-Learning,RF-QL,e-greedy,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",RewardLearner_egreedy,RE,None,NUTS,None,-,-,-,-,-
Value-Based RL,RPE-free Q-Learning,RF-QL,e-greedy,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",RewardLearner_egreedy,RE,None,NUTS,None,-,-,-,-,-
Value-Based RL,RPE-free Q-Learning,RF-QL,softmax,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",RewardLearner_softmax,RS,None,NUTS,None,-,-,-,-,-
Value-Based RL,RPE-free Q-Learning,RF-QL,softmax,beta,policy,Softmax Temperature,HalfNormal,Halfnormal(1),RewardLearner_softmax,RS,None,NUTS,None,-,-,-,-,-
Value-Based RL,RPE-free Q-Learning,RF-QL,e-softmax,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",RewardLearner_esoftmax,RES,None,NUTS,None,-,-,-,-,-
Value-Based RL,RPE-free Q-Learning,RF-QL,e-softmax,beta,policy,Softmax Temperature,HalfNormal,Halfnormal(1),RewardLearner_esoftmax,RES,None,NUTS,None,-,-,-,-,-
Value-Based RL,RPE-free Q-Learning,RF-QL,e-softmax,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",RewardLearner_esoftmax,RES,None,NUTS,None,-,-,-,-,-
Value-Based RL,RPE-free Q-Learning,RF-QL,acceptreject,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",RewardLearner_acceptreject,RBR,None,NUTS,modelfits/acceptreject/RBR_2022_04_09_19_31_45.nc,-,-,-,-,-
Value-Based RL,RPE-free Q-Learning,RF-QL,acceptreject,weight,policy,Q-value weight,Normal,"Normal(0,1)",RewardLearner_acceptreject,RBR,None,NUTS,modelfits/acceptreject/RBR_2022_04_09_19_31_45.nc,-,-,-,-,-
Value-Based RL,RPE-free Q-Learning,RF-QL,acceptreject,intercept,policy,Q-value intercept,Normal,"Normal(0,1)",RewardLearner_acceptreject,RBR,None,NUTS,modelfits/acceptreject/RBR_2022_04_09_19_31_45.nc,-,-,-,-,-
Value-Based RL,Forgetting RPE-free Q-Learning,F-RF-QL,e-greedy,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",ForgettingRewardLearner_egreedy,FRE,None,NUTS,None,-,+,-,-,-
Value-Based RL,Forgetting RPE-free Q-Learning,F-RF-QL,e-greedy,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",ForgettingRewardLearner_egreedy,FRE,None,NUTS,None,-,+,-,-,-
Value-Based RL,Forgetting RPE-free Q-Learning,F-RF-QL,softmax,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",ForgettingRewardLearner_softmax,FRS,None,NUTS,None,-,+,-,-,-
Value-Based RL,Forgetting RPE-free Q-Learning,F-RF-QL,softmax,beta,policy,Softmax Temperature,HalfNormal,Halfnormal(1),ForgettingRewardLearner_softmax,FRS,None,NUTS,None,-,+,-,-,-
Value-Based RL,Forgetting RPE-free Q-Learning,F-RF-QL,e-softmax,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",ForgettingRewardLearner_esoftmax,FRES,None,NUTS,None,-,+,-,-,-
Value-Based RL,Forgetting RPE-free Q-Learning,F-RF-QL,e-softmax,beta,policy,Softmax Temperature,HalfNormal,Halfnormal(1),ForgettingRewardLearner_esoftmax,FRES,None,NUTS,None,-,+,-,-,-
Value-Based RL,Forgetting RPE-free Q-Learning,F-RF-QL,e-softmax,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",ForgettingRewardLearner_esoftmax,FRES,None,NUTS,None,-,+,-,-,-
Value-Based RL,Forgetting RPE-free Q-Learning,F-RF-QL,acceptreject,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",ForgettingRewardLearner_acceptreject,FRBR,None,NUTS,modelfits/acceptreject/FRBR_2022_04_22_22_08_26.nc,-,+,-,-,-
Value-Based RL,Forgetting RPE-free Q-Learning,F-RF-QL,acceptreject,weight,policy,Q-value weight,Normal,"Normal(0,1)",ForgettingRewardLearner_acceptreject,FRBR,None,NUTS,modelfits/acceptreject/FRBR_2022_04_22_22_08_26.nc,-,+,-,-,-
Value-Based RL,Forgetting RPE-free Q-Learning,F-RF-QL,acceptreject,intercept,policy,Q-value intercept,Normal,"Normal(0,1)",ForgettingRewardLearner_acceptreject,FRBR,None,NUTS,modelfits/acceptreject/FRBR_2022_04_22_22_08_26.nc,-,+,-,-,-
Value-Based RL,Immediate Q-Learning,I-QL,e-greedy,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",IQLearner_egreedy,IQE,None,NUTS,None,+,-,-,-,-
Value-Based RL,Immediate Q-Learning,I-QL,e-greedy,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",IQLearner_egreedy,IQE,None,NUTS,None,+,-,-,-,-
Value-Based RL,Immediate Q-Learning,I-QL,softmax,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",IQLearner_softmax,IQS,None,NUTS,None,+,-,-,-,-
Value-Based RL,Immediate Q-Learning,I-QL,softmax,beta,policy,Softmax Temperature,HalfNormal,Halfnormal(1),IQLearner_softmax,IQS,None,NUTS,None,+,-,-,-,-
Value-Based RL,Immediate Q-Learning,I-QL,e-softmax,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",IQLearner_esoftmax,IQES,None,NUTS,modelfits/IQES_2022_02_25_12_22_05.nc,+,-,-,-,-
Value-Based RL,Immediate Q-Learning,I-QL,e-softmax,beta,policy,Softmax Temperature,HalfNormal,Halfnormal(1),IQLearner_esoftmax,IQES,None,NUTS,modelfits/IQES_2022_02_25_12_22_05.nc,+,-,-,-,-
Value-Based RL,Immediate Q-Learning,I-QL,e-softmax,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",IQLearner_esoftmax,IQES,None,NUTS,modelfits/IQES_2022_02_25_12_22_05.nc,+,-,-,-,-
Value-Based RL,Immediate Q-Learning,I-QL,acceptreject,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",IQLearner_acceptreject,IQBR,None,NUTS,modelfits/acceptreject/IQBR_2022_04_05_09_06_43.nc,+,-,-,-,-
Value-Based RL,Immediate Q-Learning,I-QL,acceptreject,weight,policy,Q-value weight,Normal,"Normal(0,1)",IQLearner_acceptreject,IQBR,None,NUTS,modelfits/acceptreject/IQBR_2022_04_05_09_06_43.nc,+,-,-,-,-
Value-Based RL,Immediate Q-Learning,I-QL,acceptreject,intercept,policy,Q-value intercept,Normal,"Normal(0,1)",IQLearner_acceptreject,IQBR,None,NUTS,modelfits/acceptreject/IQBR_2022_04_05_09_06_43.nc,+,-,-,-,-
Value-Based RL,Long-Term Q Learning,LT-QL,e-greedy,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",CQLearner_egreedy,CQE,None,NUTS,modelfits/acceptreject/IQBR_2022_04_05_09_06_43.nc,+,-,+,-,-
Value-Based RL,Long-Term Q Learning,LT-QL,e-greedy,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",CQLearner_egreedy,CQE,None,NUTS,None,+,-,+,-,-
Value-Based RL,Long-Term Q Learning,LT-QL,e-greedy,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",CQLearner_egreedy,CQE,None,NUTS,None,+,-,+,-,-
Value-Based RL,Long-Term Q Learning,LT-QL,softmax,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",CQLearner_softmax,CQS,None,NUTS,None,+,-,+,-,-
Value-Based RL,Long-Term Q Learning,LT-QL,softmax,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",CQLearner_softmax,CQS,None,NUTS,None,+,-,+,-,-
Value-Based RL,Long-Term Q Learning,LT-QL,softmax,beta,policy,Softmax Temperature,HalfNormal,Halfnormal(1),CQLearner_softmax,CQS,None,NUTS,None,+,-,+,-,-
Value-Based RL,Long-Term Q Learning,LT-QL,e-softmax,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",CQLearner_esoftmax,CQES,None,NUTS,modelfits/CQES_2022_02_26_16_57_44.nc,+,-,+,-,-
Value-Based RL,Long-Term Q Learning,LT-QL,e-softmax,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",CQLearner_esoftmax,CQES,None,NUTS,modelfits/CQES_2022_02_26_16_57_44.nc,+,-,+,-,-
Value-Based RL,Long-Term Q Learning,LT-QL,e-softmax,beta,policy,Softmax Temperature,HalfNormal,Halfnormal(1),CQLearner_esoftmax,CQES,None,NUTS,modelfits/CQES_2022_02_26_16_57_44.nc,+,-,+,-,-
Value-Based RL,Long-Term Q Learning,LT-QL,e-softmax,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",CQLearner_esoftmax,CQES,None,NUTS,modelfits/CQES_2022_02_26_16_57_44.nc,+,-,+,-,-
Value-Based RL,Long-Term Q Learning,LT-QL,acceptreject,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",CQLearner_acceptreject,CQBR,None,NUTS,modelfits/acceptreject/CQBR_2022_04_07_14_56_03.nc,+,-,+,-,-
Value-Based RL,Long-Term Q Learning,LT-QL,acceptreject,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",CQLearner_acceptreject,CQBR,None,NUTS,modelfits/acceptreject/CQBR_2022_04_07_14_56_03.nc,+,-,+,-,-
Value-Based RL,Long-Term Q Learning,LT-QL,acceptreject,weight,policy,Q-value weight,Normal,"Normal(0,1)",CQLearner_acceptreject,CQBR,None,NUTS,modelfits/acceptreject/CQBR_2022_04_07_14_56_03.nc,+,-,+,-,-
Value-Based RL,Long-Term Q Learning,LT-QL,acceptreject,intercept,policy,Q-value intercept,Normal,"Normal(0,1)",CQLearner_acceptreject,CQBR,None,NUTS,modelfits/acceptreject/CQBR_2022_04_07_14_56_03.nc,+,-,+,-,-
Value-Based RL,Forgetting Immediate Q-Learning,F-I-QL,e-greedy,alpha,learningrule,Learning/Forgetting Rate,Beta,"Beta(1,1)",FQLearner_egreedy,FQE,None,NUTS,None,+,+,-,-,-
Value-Based RL,Forgetting Immediate Q-Learning,F-I-QL,e-greedy,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",FQLearner_egreedy,FQE,None,NUTS,None,+,+,-,-,-
Value-Based RL,Forgetting Immediate Q-Learning,F-I-QL,softmax,alpha,learningrule,Learning/Forgetting Rate,Beta,"Beta(1,1)",FQLearner_softmax,FQS,None,NUTS,None,+,+,-,-,-
Value-Based RL,Forgetting Immediate Q-Learning,F-I-QL,softmax,beta,policy,Softmax Temperature,HalfNormal,Halfnormal(1),FQLearner_softmax,FQS,None,NUTS,None,+,+,-,-,-
Value-Based RL,Forgetting Immediate Q-Learning,F-I-QL,e-softmax,alpha,learningrule,Learning/Forgetting Rate,Beta,"Beta(1,1)",FQLearner_esoftmax,FQES,None,NUTS,modelfits/FQES_2022_02_24_17_57_57.nc,+,+,-,-,-
Value-Based RL,Forgetting Immediate Q-Learning,F-I-QL,e-softmax,beta,policy,Softmax Temperature,HalfNormal,Halfnormal(1),FQLearner_esoftmax,FQES,None,NUTS,modelfits/FQES_2022_02_24_17_57_57.nc,+,+,-,-,-
Value-Based RL,Forgetting Immediate Q-Learning,F-I-QL,e-softmax,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",FQLearner_esoftmax,FQES,None,NUTS,modelfits/FQES_2022_02_24_17_57_57.nc,+,+,-,-,-
Value-Based RL,Forgetting Immediate Q-Learning,F-I-QL,acceptreject,alpha,learningrule,Learning/Forgetting Rate,Beta,"Beta(1,1)",FQLearner_acceptreject,FQBR,None,NUTS,modelfits/acceptreject/FQBR_2022_04_07_14_56_35.nc,+,+,-,-,-
Value-Based RL,Forgetting Immediate Q-Learning,F-I-QL,acceptreject,weight,policy,Q-value weight,Normal,"Normal(0,1)",FQLearner_acceptreject,FQBR,None,NUTS,modelfits/acceptreject/FQBR_2022_04_07_14_56_35.nc,+,+,-,-,-
Value-Based RL,Forgetting Immediate Q-Learning,F-I-QL,acceptreject,intercept,policy,Q-value intercept,Normal,"Normal(0,1)",FQLearner_acceptreject,FQBR,None,NUTS,modelfits/acceptreject/FQBR_2022_04_07_14_56_35.nc,+,+,-,-,-
Value-Based RL,Forgetting Long-Term Q Learning,F-LT-QL,e-greedy,alpha,learningrule,Learning/Forgetting Rate,Beta,"Beta(1,1)",FCQLearner_egreedy,FCQE,None,NUTS,None,+,+,+,-,-
Value-Based RL,Forgetting Long-Term Q Learning,F-LT-QL,e-greedy,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",FCQLearner_egreedy,FCQE,None,NUTS,None,+,+,+,-,-
Value-Based RL,Forgetting Long-Term Q Learning,F-LT-QL,e-greedy,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",FCQLearner_egreedy,FCQE,None,NUTS,None,+,+,+,-,-
Value-Based RL,Forgetting Long-Term Q Learning,F-LT-QL,softmax,alpha,learningrule,Learning/Forgetting Rate,Beta,"Beta(1,1)",FCQLearner_softmax,FCQS,None,NUTS,None,+,+,+,-,-
Value-Based RL,Forgetting Long-Term Q Learning,F-LT-QL,softmax,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",FCQLearner_softmax,FCQS,None,NUTS,None,+,+,+,-,-
Value-Based RL,Forgetting Long-Term Q Learning,F-LT-QL,softmax,beta,policy,Softmax Temperature,HalfNormal,Halfnormal(1),FCQLearner_softmax,FCQS,None,NUTS,None,+,+,+,-,-
Value-Based RL,Forgetting Long-Term Q Learning,F-LT-QL,e-softmax,alpha,learningrule,Learning/Forgetting Rate,Beta,"Beta(1,1)",FCQLearner_esoftmax,FCQES,None,NUTS,modelfits/FCQES_2022_03_21_10_17_33.nc,+,+,+,-,-
Value-Based RL,Forgetting Long-Term Q Learning,F-LT-QL,e-softmax,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",FCQLearner_esoftmax,FCQES,None,NUTS,modelfits/FCQES_2022_03_21_10_17_33.nc,+,+,+,-,-
Value-Based RL,Forgetting Long-Term Q Learning,F-LT-QL,e-softmax,beta,policy,Softmax Temperature,HalfNormal,Halfnormal(1),FCQLearner_esoftmax,FCQES,None,NUTS,modelfits/FCQES_2022_03_21_10_17_33.nc,+,+,+,-,-
Value-Based RL,Forgetting Long-Term Q Learning,F-LT-QL,e-softmax,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",FCQLearner_esoftmax,FCQES,None,NUTS,modelfits/FCQES_2022_03_21_10_17_33.nc,+,+,+,-,-
Value-Based RL,Forgetting Long-Term Q Learning,F-LT-QL,acceptreject,alpha,learningrule,Learning/Forgetting Rate,Beta,"Beta(1,1)",FCQLearner_acceptreject,FCQBR,None,NUTS,modelfits/acceptreject/FCQBR_2022_04_07_14_56_43.nc,+,+,+,-,-
Value-Based RL,Forgetting Long-Term Q Learning,F-LT-QL,acceptreject,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",FCQLearner_acceptreject,FCQBR,None,NUTS,modelfits/acceptreject/FCQBR_2022_04_07_14_56_43.nc,+,+,+,-,-
Value-Based RL,Forgetting Long-Term Q Learning,F-LT-QL,acceptreject,weight,policy,Q-value weight,Normal,"Normal(0,1)",FCQLearner_acceptreject,FCQBR,None,NUTS,modelfits/acceptreject/FCQBR_2022_04_07_14_56_43.nc,+,+,+,-,-
Value-Based RL,Forgetting Long-Term Q Learning,F-LT-QL,acceptreject,intercept,policy,Q-value intercept,Normal,"Normal(0,1)",FCQLearner_acceptreject,FCQBR,None,NUTS,modelfits/acceptreject/FCQBR_2022_04_07_14_56_43.nc,+,+,+,-,-
Value-Based RL,Differential Forgetting Immediate Q-Learning,DF-I-QL,e-greedy,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",DFQLearner_egreedy,DFQE,None,NUTS,None,+,+,-,-,-
Value-Based RL,Differential Forgetting Immediate Q-Learning,DF-I-QL,e-greedy,kappa,learningrule,Forgetting Rate,Beta,"Beta(1,1)",DFQLearner_egreedy,DFQE,None,NUTS,None,+,+,-,-,-
Value-Based RL,Differential Forgetting Immediate Q-Learning,DF-I-QL,e-greedy,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",DFQLearner_egreedy,DFQE,None,NUTS,None,+,+,-,-,-
Value-Based RL,Differential Forgetting Immediate Q-Learning,DF-I-QL,softmax,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",DFQLearner_softmax,DFQS,None,NUTS,None,+,+,-,-,-
Value-Based RL,Differential Forgetting Immediate Q-Learning,DF-I-QL,softmax,kappa,learningrule,Forgetting Rate,Beta,"Beta(1,1)",DFQLearner_softmax,DFQS,None,NUTS,None,+,+,-,-,-
Value-Based RL,Differential Forgetting Immediate Q-Learning,DF-I-QL,softmax,beta,policy,Softmax Temperature,HalfNormal,Halfnormal(1),DFQLearner_softmax,DFQS,None,NUTS,None,+,+,-,-,-
Value-Based RL,Differential Forgetting Immediate Q-Learning,DF-I-QL,e-softmax,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",DFQLearner_esoftmax,DFQES,None,NUTS,modelfits/DFQES_2022_02_25_17_50_06.nc,+,+,-,-,-
Value-Based RL,Differential Forgetting Immediate Q-Learning,DF-I-QL,e-softmax,kappa,learningrule,Forgetting Rate,Beta,"Beta(1,1)",DFQLearner_esoftmax,DFQES,None,NUTS,modelfits/DFQES_2022_02_25_17_50_06.nc,+,+,-,-,-
Value-Based RL,Differential Forgetting Immediate Q-Learning,DF-I-QL,e-softmax,beta,policy,Softmax Temperature,HalfNormal,Halfnormal(1),DFQLearner_esoftmax,DFQES,None,NUTS,modelfits/DFQES_2022_02_25_17_50_06.nc,+,+,-,-,-
Value-Based RL,Differential Forgetting Immediate Q-Learning,DF-I-QL,e-softmax,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",DFQLearner_esoftmax,DFQES,None,NUTS,modelfits/DFQES_2022_02_25_17_50_06.nc,+,+,-,-,-
Value-Based RL,Differential Forgetting Immediate Q-Learning,DF-I-QL,acceptreject,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",DFQLearner_acceptreject,DFQBR,None,NUTS,modelfits/acceptreject/DFQBR_2022_04_22_22_06_02.nc,+,+,-,-,-
Value-Based RL,Differential Forgetting Immediate Q-Learning,DF-I-QL,acceptreject,kappa,learningrule,Forgetting Rate,Beta,"Beta(1,1)",DFQLearner_acceptreject,DFQBR,None,NUTS,modelfits/acceptreject/DFQBR_2022_04_22_22_06_02.nc,+,+,-,-,-
Value-Based RL,Differential Forgetting Immediate Q-Learning,DF-I-QL,acceptreject,weight,policy,Q-value weight,Normal,"Normal(0,1)",DFQLearner_acceptreject,DFQBR,None,NUTS,modelfits/acceptreject/DFQBR_2022_04_22_22_06_02.nc,+,+,-,-,-
Value-Based RL,Differential Forgetting Immediate Q-Learning,DF-I-QL,acceptreject,intercept,policy,Q-value intercept,Normal,"Normal(0,1)",DFQLearner_acceptreject,DFQBR,None,NUTS,modelfits/acceptreject/DFQBR_2022_04_22_22_06_02.nc,+,+,-,-,-
Value-Based RL,Differential Forgetting Long-Term Q Learning,DF-LT-QL,e-greedy,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",DFCQLearner_egreedy,DFCQE,None,NUTS,None,+,+,+,-,-
Value-Based RL,Differential Forgetting Long-Term Q Learning,DF-LT-QL,e-greedy,kappa,learningrule,Forgetting Rate,Beta,"Beta(1,1)",DFCQLearner_egreedy,DFCQE,None,NUTS,None,+,+,+,-,-
Value-Based RL,Differential Forgetting Long-Term Q Learning,DF-LT-QL,e-greedy,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",DFCQLearner_egreedy,DFCQE,None,NUTS,None,+,+,+,-,-
Value-Based RL,Differential Forgetting Long-Term Q Learning,DF-LT-QL,e-greedy,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",DFCQLearner_egreedy,DFCQE,None,NUTS,None,+,+,+,-,-
Value-Based RL,Differential Forgetting Long-Term Q Learning,DF-LT-QL,softmax,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",DFCQLearner_softmax,DFCQS,None,NUTS,None,+,+,+,-,-
Value-Based RL,Differential Forgetting Long-Term Q Learning,DF-LT-QL,softmax,kappa,learningrule,Forgetting Rate,Beta,"Beta(1,1)",DFCQLearner_softmax,DFCQS,None,NUTS,None,+,+,+,-,-
Value-Based RL,Differential Forgetting Long-Term Q Learning,DF-LT-QL,softmax,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",DFCQLearner_softmax,DFCQS,None,NUTS,None,+,+,+,-,-
Value-Based RL,Differential Forgetting Long-Term Q Learning,DF-LT-QL,softmax,beta,policy,Softmax Temperature,HalfNormal,Halfnormal(1),DFCQLearner_softmax,DFCQS,None,NUTS,None,+,+,+,-,-
Value-Based RL,Differential Forgetting Long-Term Q Learning,DF-LT-QL,e-softmax,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",DFCQLearner_esoftmax,DFCQES,None,NUTS,modelfits/DFCQES_2022_03_21_10_17_40.nc,+,+,+,-,-
Value-Based RL,Differential Forgetting Long-Term Q Learning,DF-LT-QL,e-softmax,kappa,learningrule,Forgetting Rate,Beta,"Beta(1,1)",DFCQLearner_esoftmax,DFCQES,None,NUTS,modelfits/DFCQES_2022_03_21_10_17_40.nc,+,+,+,-,-
Value-Based RL,Differential Forgetting Long-Term Q Learning,DF-LT-QL,e-softmax,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",DFCQLearner_esoftmax,DFCQES,None,NUTS,modelfits/DFCQES_2022_03_21_10_17_40.nc,+,+,+,-,-
Value-Based RL,Differential Forgetting Long-Term Q Learning,DF-LT-QL,e-softmax,beta,policy,Softmax Temperature,HalfNormal,Halfnormal(1),DFCQLearner_esoftmax,DFCQES,None,NUTS,modelfits/DFCQES_2022_03_21_10_17_40.nc,+,+,+,-,-
Value-Based RL,Differential Forgetting Long-Term Q Learning,DF-LT-QL,e-softmax,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",DFCQLearner_esoftmax,DFCQES,None,NUTS,modelfits/DFCQES_2022_03_21_10_17_40.nc,+,+,+,-,-
Value-Based RL,Differential Forgetting Long-Term Q Learning,DF-LT-QL,acceptreject,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",DFCQLearner_acceptreject,DFCQBR,None,NUTS,modelfits/acceptreject/DFCQBR_2022_04_20_17_02_18.nc,+,+,+,-,-
Value-Based RL,Differential Forgetting Long-Term Q Learning,DF-LT-QL,acceptreject,kappa,learningrule,Forgetting Rate,Beta,"Beta(1,1)",DFCQLearner_acceptreject,DFCQBR,None,NUTS,modelfits/acceptreject/DFCQBR_2022_04_20_17_02_18.nc,+,+,+,-,-
Value-Based RL,Differential Forgetting Long-Term Q Learning,DF-LT-QL,acceptreject,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",DFCQLearner_acceptreject,DFCQBR,None,NUTS,modelfits/acceptreject/DFCQBR_2022_04_20_17_02_18.nc,+,+,+,-,-
Value-Based RL,Differential Forgetting Long-Term Q Learning,DF-LT-QL,acceptreject,weight,policy,Q-value weight,Normal,"Normal(0,1)",DFCQLearner_acceptreject,DFCQBR,None,NUTS,modelfits/acceptreject/DFCQBR_2022_04_20_17_02_18.nc,+,+,+,-,-
Value-Based RL,Differential Forgetting Long-Term Q Learning,DF-LT-QL,acceptreject,intercept,policy,Q-value intercept,Normal,"Normal(0,1)",DFCQLearner_acceptreject,DFCQBR,None,NUTS,modelfits/acceptreject/DFCQBR_2022_04_20_17_02_18.nc,+,+,+,-,-
Value-Based RL,Differential Extinction Immediate Q Learning,DE-I-QL,e-greedy,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",DEQLearner_egreedy,DEQE,None,NUTS,None,+,-,-,-,-
Value-Based RL,Differential Extinction Immediate Q Learning,DE-I-QL,e-greedy,kappa,learningrule,Extinction Rate,Beta,"Beta(1,1)",DEQLearner_egreedy,DEQE,None,NUTS,None,+,-,-,-,-
Value-Based RL,Differential Extinction Immediate Q Learning,DE-I-QL,e-greedy,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",DEQLearner_egreedy,DEQE,None,NUTS,None,+,-,-,-,-
Value-Based RL,Differential Extinction Immediate Q Learning,DE-I-QL,softmax,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",DEQLearner_softmax,DEQS,None,NUTS,None,+,-,-,-,-
Value-Based RL,Differential Extinction Immediate Q Learning,DE-I-QL,softmax,tau,learningrule,Extinction Rate,Beta,"Beta(1,1)",DEQLearner_softmax,DEQS,None,NUTS,None,+,-,-,-,-
Value-Based RL,Differential Extinction Immediate Q Learning,DE-I-QL,softmax,beta,policy,Softmax Temperature,HalfNormal,Halfnormal(1),DEQLearner_softmax,DEQS,None,NUTS,None,+,-,-,-,-
Value-Based RL,Differential Extinction Immediate Q Learning,DE-I-QL,e-softmax,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",DEQLearner_esoftmax,DEQES,None,NUTS,modelfits/DEQES_2022_04_02_17_41_39.nc,+,-,-,-,-
Value-Based RL,Differential Extinction Immediate Q Learning,DE-I-QL,e-softmax,tau,learningrule,Extinction Rate,Beta,"Beta(1,1)",DEQLearner_esoftmax,DEQES,None,NUTS,modelfits/DEQES_2022_04_02_17_41_39.nc,+,-,-,-,-
Value-Based RL,Differential Extinction Immediate Q Learning,DE-I-QL,e-softmax,beta,policy,Softmax Temperature,HalfNormal,Halfnormal(1),DEQLearner_esoftmax,DEQES,None,NUTS,modelfits/DEQES_2022_04_02_17_41_39.nc,+,-,-,-,-
Value-Based RL,Differential Extinction Immediate Q Learning,DE-I-QL,e-softmax,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",DEQLearner_esoftmax,DEQES,None,NUTS,modelfits/DEQES_2022_04_02_17_41_39.nc,+,-,-,-,-
Value-Based RL,Differential Extinction Immediate Q Learning,DE-I-QL,acceptreject,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",DEQLearner_acceptreject,DEQBR,None,NUTS,modelfits/acceptreject/DEQBR_2022_04_09_13_43_11.nc,+,-,-,-,-
Value-Based RL,Differential Extinction Immediate Q Learning,DE-I-QL,acceptreject,tau,learningrule,Extinction Rate,Beta,"Beta(1,1)",DEQLearner_acceptreject,DEQBR,None,NUTS,modelfits/acceptreject/DEQBR_2022_04_09_13_43_11.nc,+,-,-,-,-
Value-Based RL,Differential Extinction Immediate Q Learning,DE-I-QL,acceptreject,weight,policy,Q-value weight,Normal,"Normal(0,1)",DEQLearner_acceptreject,DEQBR,None,NUTS,modelfits/acceptreject/DEQBR_2022_04_09_13_43_11.nc,+,-,-,-,-
Value-Based RL,Differential Extinction Immediate Q Learning,DE-I-QL,acceptreject,intercept,policy,Q-value intercept,Normal,"Normal(0,1)",DEQLearner_acceptreject,DEQBR,None,NUTS,modelfits/acceptreject/DEQBR_2022_04_09_13_43_11.nc,+,-,-,-,-
Value-Based RL,Differential Extinction Long-Term Q Learning,DE-LT-QL,e-greedy,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",DECQLearner_egreedy,DECQE,None,NUTS,None,+,-,+,-,-
Value-Based RL,Differential Extinction Long-Term Q Learning,DE-LT-QL,e-greedy,tau,learningrule,Extinction Rate,Beta,"Beta(1,1)",DECQLearner_egreedy,DECQE,None,NUTS,None,+,-,+,-,-
Value-Based RL,Differential Extinction Long-Term Q Learning,DE-LT-QL,e-greedy,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",DECQLearner_egreedy,DECQE,None,NUTS,None,+,-,+,-,-
Value-Based RL,Differential Extinction Long-Term Q Learning,DE-LT-QL,e-greedy,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",DECQLearner_egreedy,DECQE,None,NUTS,None,+,-,+,-,-
Value-Based RL,Differential Extinction Long-Term Q Learning,DE-LT-QL,softmax,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",DECQLearner_softmax,DECQS,None,NUTS,None,+,-,+,-,-
Value-Based RL,Differential Extinction Long-Term Q Learning,DE-LT-QL,softmax,tau,learningrule,Extinction Rate,Beta,"Beta(1,1)",DECQLearner_softmax,DECQS,None,NUTS,None,+,-,+,-,-
Value-Based RL,Differential Extinction Long-Term Q Learning,DE-LT-QL,softmax,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",DECQLearner_softmax,DECQS,None,NUTS,None,+,-,+,-,-
Value-Based RL,Differential Extinction Long-Term Q Learning,DE-LT-QL,softmax,beta,policy,Softmax Temperature,HalfNormal,Halfnormal(1),DECQLearner_softmax,DECQS,None,NUTS,None,+,-,+,-,-
Value-Based RL,Differential Extinction Long-Term Q Learning,DE-LT-QL,e-softmax,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",DECQLearner_esoftmax,DECQES,None,NUTS,None,+,-,+,-,-
Value-Based RL,Differential Extinction Long-Term Q Learning,DE-LT-QL,e-softmax,tau,learningrule,Extinction Rate,Beta,"Beta(1,1)",DECQLearner_esoftmax,DECQES,None,NUTS,None,+,-,+,-,-
Value-Based RL,Differential Extinction Long-Term Q Learning,DE-LT-QL,e-softmax,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",DECQLearner_esoftmax,DECQES,None,NUTS,None,+,-,+,-,-
Value-Based RL,Differential Extinction Long-Term Q Learning,DE-LT-QL,e-softmax,beta,policy,Softmax Temperature,HalfNormal,Halfnormal(1),DECQLearner_esoftmax,DECQES,None,NUTS,None,+,-,+,-,-
Value-Based RL,Differential Extinction Long-Term Q Learning,DE-LT-QL,e-softmax,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",DECQLearner_esoftmax,DECQES,None,NUTS,None,+,-,+,-,-
Value-Based RL,Differential Extinction Long-Term Q Learning,DE-LT-QL,acceptreject,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",DECQLearner_acceptreject,DECQBR,None,NUTS,modelfits/acceptreject/DECQBR_2022_04_09_13_43_22.nc,+,-,+,-,-
Value-Based RL,Differential Extinction Long-Term Q Learning,DE-LT-QL,acceptreject,tau,learningrule,Extinction Rate,Beta,"Beta(1,1)",DECQLearner_acceptreject,DECQBR,None,NUTS,modelfits/acceptreject/DECQBR_2022_04_09_13_43_22.nc,+,-,+,-,-
Value-Based RL,Differential Extinction Long-Term Q Learning,DE-LT-QL,acceptreject,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",DECQLearner_acceptreject,DECQBR,None,NUTS,modelfits/acceptreject/DECQBR_2022_04_09_13_43_22.nc,+,-,+,-,-
Value-Based RL,Differential Extinction Long-Term Q Learning,DE-LT-QL,acceptreject,weight,policy,Q-value weight,Normal,"Normal(0,1)",DECQLearner_acceptreject,DECQBR,None,NUTS,modelfits/acceptreject/DECQBR_2022_04_09_13_43_22.nc,+,-,+,-,-
Value-Based RL,Differential Extinction Long-Term Q Learning,DE-LT-QL,acceptreject,intercept,policy,Q-value intercept,Normal,"Normal(0,1)",DECQLearner_acceptreject,DECQBR,None,NUTS,modelfits/acceptreject/DECQBR_2022_04_09_13_43_22.nc,+,-,+,-,-
Value-Based RL,Immediate Omission Sensitive Q Learning ,I-OS-QL,e-greedy,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",OSQLearner_egreedy,OSQE,None,NUTS,None,+,-,-,+,-
Value-Based RL,Immediate Omission Sensitive Q Learning ,I-OS-QL,e-greedy,theta,learningrule,Omission Sensitivity,Normal,"Normal(0,1)",OSQLearner_egreedy,OSQE,None,NUTS,None,+,-,-,+,-
Value-Based RL,Immediate Omission Sensitive Q Learning ,I-OS-QL,e-greedy,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",OSQLearner_egreedy,OSQE,None,NUTS,None,+,-,-,+,-
Value-Based RL,Immediate Omission Sensitive Q Learning ,I-OS-QL,softmax,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",OSQLearner_softmax,OSQS,None,NUTS,None,+,-,-,+,-
Value-Based RL,Immediate Omission Sensitive Q Learning ,I-OS-QL,softmax,theta,learningrule,Omission Sensitivity,Normal,"Normal(0,1)",OSQLearner_softmax,OSQS,None,NUTS,None,+,-,-,+,-
Value-Based RL,Immediate Omission Sensitive Q Learning ,I-OS-QL,softmax,beta,policy,Softmax Temperature,HalfNormal,Halfnormal(1),OSQLearner_softmax,OSQS,None,NUTS,None,+,-,-,+,-
Value-Based RL,Immediate Omission Sensitive Q Learning ,I-OS-QL,e-softmax,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",OSQLearner_esoftmax,OSQES,None,NUTS,modelfits/OSQES_2022_03_09_19_19_49.nc,+,-,-,+,-
Value-Based RL,Immediate Omission Sensitive Q Learning ,I-OS-QL,e-softmax,theta,learningrule,Omission Sensitivity,Normal,"Normal(0,1)",OSQLearner_esoftmax,OSQES,None,NUTS,modelfits/OSQES_2022_03_09_19_19_49.nc,+,-,-,+,-
Value-Based RL,Immediate Omission Sensitive Q Learning ,I-OS-QL,e-softmax,beta,policy,Softmax Temperature,HalfNormal,Halfnormal(1),OSQLearner_esoftmax,OSQES,None,NUTS,modelfits/OSQES_2022_03_09_19_19_49.nc,+,-,-,+,-
Value-Based RL,Immediate Omission Sensitive Q Learning ,I-OS-QL,e-softmax,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",OSQLearner_esoftmax,OSQES,None,NUTS,modelfits/OSQES_2022_03_09_19_19_49.nc,+,-,-,+,-
Value-Based RL,Immediate Omission Sensitive Q Learning ,I-OS-QL,acceptreject,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",OSQLearner_acceptreject,OSQBR,None,NUTS,modelfits/acceptreject/OSQBR_2022_04_09_19_41_05.nc,+,-,-,+,-
Value-Based RL,Immediate Omission Sensitive Q Learning ,I-OS-QL,acceptreject,theta,learningrule,Omission Sensitivity,Normal,"Normal(0,1)",OSQLearner_acceptreject,OSQBR,None,NUTS,modelfits/acceptreject/OSQBR_2022_04_09_19_41_05.nc,+,-,-,+,-
Value-Based RL,Immediate Omission Sensitive Q Learning ,I-OS-QL,acceptreject,weight,policy,Q-value weight,Normal,"Normal(0,1)",OSQLearner_acceptreject,OSQBR,None,NUTS,modelfits/acceptreject/OSQBR_2022_04_09_19_41_05.nc,+,-,-,+,-
Value-Based RL,Immediate Omission Sensitive Q Learning ,I-OS-QL,acceptreject,intercept,policy,Q-value intercept,Normal,"Normal(0,1)",OSQLearner_acceptreject,OSQBR,None,NUTS,modelfits/acceptreject/OSQBR_2022_04_09_19_41_05.nc,+,-,-,+,-
Value-Based RL, Long-Term Omission Sensitive Q Learning ,LT-OS-QL,e-greedy,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",OSCQLearner_egreedy,OSCQE,None,NUTS,None,+,-,+,+,-
Value-Based RL, Long-Term Omission Sensitive Q Learning ,LT-OS-QL,e-greedy,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",OSCQLearner_egreedy,OSCQE,None,NUTS,None,+,-,+,+,-
Value-Based RL, Long-Term Omission Sensitive Q Learning ,LT-OS-QL,e-greedy,theta,learningrule,Omission Sensitivity,Normal,"Normal(0,1)",OSCQLearner_egreedy,OSCQE,None,NUTS,None,+,-,+,+,-
Value-Based RL, Long-Term Omission Sensitive Q Learning ,LT-OS-QL,e-greedy,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",OSCQLearner_egreedy,OSCQE,None,NUTS,None,+,-,+,+,-
Value-Based RL, Long-Term Omission Sensitive Q Learning ,LT-OS-QL,softmax,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",OSCQLearner_softmax,OSCQS,None,NUTS,None,+,-,+,+,-
Value-Based RL, Long-Term Omission Sensitive Q Learning ,LT-OS-QL,softmax,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",OSCQLearner_softmax,OSCQE,None,NUTS,None,+,-,+,+,-
Value-Based RL, Long-Term Omission Sensitive Q Learning ,LT-OS-QL,softmax,theta,learningrule,Omission Sensitivity,Normal,"Normal(0,1)",OSCQLearner_softmax,OSCQS,None,NUTS,None,+,-,+,+,-
Value-Based RL, Long-Term Omission Sensitive Q Learning ,LT-OS-QL,softmax,beta,policy,Softmax Temperature,HalfNormal,Halfnormal(1),OSCQLearner_softmax,OSCQS,None,NUTS,None,+,-,+,+,-
Value-Based RL, Long-Term Omission Sensitive Q Learning ,LT-OS-QL,e-softmax,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",OSCQLearner_esoftmax,OSCQES,None,NUTS,modelfits/OSCQES_2022_03_09_19_21_23.nc,+,-,+,+,-
Value-Based RL, Long-Term Omission Sensitive Q Learning ,LT-OS-QL,e-softmax,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",OSCQLearner_esoftmax,OSCQES,None,NUTS,modelfits/OSCQES_2022_03_09_19_21_23.nc,+,-,+,+,-
Value-Based RL, Long-Term Omission Sensitive Q Learning ,LT-OS-QL,e-softmax,theta,learningrule,Omission Sensitivity,Normal,"Normal(0,1)",OSCQLearner_esoftmax,OSCQES,None,NUTS,modelfits/OSCQES_2022_03_09_19_21_23.nc,+,-,+,+,-
Value-Based RL, Long-Term Omission Sensitive Q Learning ,LT-OS-QL,e-softmax,beta,policy,Softmax Temperature,HalfNormal,Halfnormal(1),OSCQLearner_esoftmax,OSCQES,None,NUTS,modelfits/OSCQES_2022_03_09_19_21_23.nc,+,-,+,+,-
Value-Based RL, Long-Term Omission Sensitive Q Learning ,LT-OS-QL,e-softmax,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",OSCQLearner_esoftmax,OSCQES,None,NUTS,modelfits/OSCQES_2022_03_09_19_21_23.nc,+,-,+,+,-
Value-Based RL, Long-Term Omission Sensitive Q Learning ,LT-OS-QL,acceptreject,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",OSCQLearner_acceptreject,OSCQBR,None,NUTS,modelfits/acceptreject/OSCQBR_2022_04_09_19_41_05.nc,+,-,+,+,-
Value-Based RL, Long-Term Omission Sensitive Q Learning ,LT-OS-QL,acceptreject,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",OSCQLearner_acceptreject,OSCQBR,None,NUTS,modelfits/acceptreject/OSCQBR_2022_04_09_19_41_05.nc,+,-,+,+,-
Value-Based RL, Long-Term Omission Sensitive Q Learning ,LT-OS-QL,acceptreject,theta,learningrule,Omission Sensitivity,Normal,"Normal(0,1)",OSCQLearner_acceptreject,OSCQBR,None,NUTS,modelfits/acceptreject/OSCQBR_2022_04_09_19_41_05.nc,+,-,+,+,-
Value-Based RL, Long-Term Omission Sensitive Q Learning ,LT-OS-QL,acceptreject,weight,policy,Q-value weight,Normal,"Normal(0,1)",OSCQLearner_acceptreject,OSCQBR,None,NUTS,modelfits/acceptreject/OSCQBR_2022_04_09_19_41_05.nc,+,-,+,+,-
Value-Based RL, Long-Term Omission Sensitive Q Learning ,LT-OS-QL,acceptreject,intercept,policy,Q-value intercept,Normal,"Normal(0,1)",OSCQLearner_acceptreject,OSCQBR,None,NUTS,modelfits/acceptreject/OSCQBR_2022_04_09_19_41_05.nc,+,-,+,+,-
Value-Based RL,Forgetting Immediate Omission Sensitive Q Learning ,F-I-OS-QL,e-greedy,alpha,learningrule,Learning/Forgetting Rate,Beta,"Beta(1,1)",FOSQLearner_egreedy,FOSQE,None,NUTS,None,+,+,-,+,-
Value-Based RL,Forgetting Immediate Omission Sensitive Q Learning ,F-I-OS-QL,e-greedy,theta,learningrule,Omission Sensitivity,Normal,"Normal(0,1)",FOSQLearner_egreedy,FOSQE,None,NUTS,None,+,+,-,+,-
Value-Based RL,Forgetting Immediate Omission Sensitive Q Learning ,F-I-OS-QL,e-greedy,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",FOSQLearner_egreedy,FOSQE,None,NUTS,None,+,+,-,+,-
Value-Based RL,Forgetting Immediate Omission Sensitive Q Learning ,F-I-OS-QL,softmax,alpha,learningrule,Learning/Forgetting Rate,Beta,"Beta(1,1)",FOSQLearner_softmax,FOSQS,None,NUTS,None,+,+,-,+,-
Value-Based RL,Forgetting Immediate Omission Sensitive Q Learning ,F-I-OS-QL,softmax,theta,learningrule,Omission Sensitivity,Normal,"Normal(0,1)",FOSQLearner_softmax,FOSQS,None,NUTS,None,+,+,-,+,-
Value-Based RL,Forgetting Immediate Omission Sensitive Q Learning ,F-I-OS-QL,softmax,beta,policy,Softmax Temperature,HalfNormal,Halfnormal(1),FOSQLearner_softmax,FOSQS,None,NUTS,None,+,+,-,+,-
Value-Based RL,Forgetting Immediate Omission Sensitive Q Learning ,F-I-OS-QL,e-softmax,alpha,learningrule,Learning/Forgetting Rate,Beta,"Beta(1,1)",FOSQLearner_esoftmax,FOSQES,None,NUTS,None,+,+,-,+,-
Value-Based RL,Forgetting Immediate Omission Sensitive Q Learning ,F-I-OS-QL,e-softmax,theta,learningrule,Omission Sensitivity,Normal,"Normal(0,1)",FOSQLearner_esoftmax,FOSQES,None,NUTS,None,+,+,-,+,-
Value-Based RL,Forgetting Immediate Omission Sensitive Q Learning ,F-I-OS-QL,e-softmax,beta,policy,Softmax Temperature,HalfNormal,Halfnormal(1),FOSQLearner_esoftmax,FOSQES,None,NUTS,None,+,+,-,+,-
Value-Based RL,Forgetting Immediate Omission Sensitive Q Learning ,F-I-OS-QL,e-softmax,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",FOSQLearner_esoftmax,FOSQES,None,NUTS,None,+,+,-,+,-
Value-Based RL,Forgetting Immediate Omission Sensitive Q Learning ,F-I-OS-QL,acceptreject,alpha,learningrule,Learning/Forgetting Rate,Beta,"Beta(1,1)",FOSQLearner_acceptreject,FOSQBR,None,NUTS,modelfits/acceptreject/FOSQBR_2022_04_12_14_09_52.nc,+,+,-,+,-
Value-Based RL,Forgetting Immediate Omission Sensitive Q Learning ,F-I-OS-QL,acceptreject,theta,learningrule,Omission Sensitivity,Normal,"Normal(0,1)",FOSQLearner_acceptreject,FOSQBR,None,NUTS,modelfits/acceptreject/FOSQBR_2022_04_12_14_09_52.nc,+,+,-,+,-
Value-Based RL,Forgetting Immediate Omission Sensitive Q Learning ,F-I-OS-QL,acceptreject,weight,policy,Q-value weight,Normal,"Normal(0,1)",FOSQLearner_acceptreject,FOSQBR,None,NUTS,modelfits/acceptreject/FOSQBR_2022_04_12_14_09_52.nc,+,+,-,+,-
Value-Based RL,Forgetting Immediate Omission Sensitive Q Learning ,F-I-OS-QL,acceptreject,intercept,policy,Q-value intercept,Normal,"Normal(0,1)",FOSQLearner_acceptreject,FOSQBR,None,NUTS,modelfits/acceptreject/FOSQBR_2022_04_12_14_09_52.nc,+,+,-,+,-
Value-Based RL,Forgetting Long-Term Omission Sensitive Q Learning ,F-LT-OS-QL,e-greedy,alpha,learningrule,Learning/Forgetting Rate,Beta,"Beta(1,1)",FOSCQLearner_egreedy,FOSCQE,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Omission Sensitive Q Learning ,F-LT-OS-QL,e-greedy,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",FOSCQLearner_egreedy,FOSCQE,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Omission Sensitive Q Learning ,F-LT-OS-QL,e-greedy,theta,learningrule,Omission Sensitivity,Normal,"Normal(0,1)",FOSCQLearner_egreedy,FOSCQE,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Omission Sensitive Q Learning ,F-LT-OS-QL,e-greedy,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",FOSCQLearner_egreedy,FOSCQE,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Omission Sensitive Q Learning ,F-LT-OS-QL,softmax,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",FOSCQLearner_softmax,FOSCQS,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Omission Sensitive Q Learning ,F-LT-OS-QL,softmax,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",FOSCQLearner_softmax,FOSCQS,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Omission Sensitive Q Learning ,F-LT-OS-QL,softmax,theta,learningrule,Omission Sensitivity,Normal,"Normal(0,1)",FOSCQLearner_softmax,FOSCQS,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Omission Sensitive Q Learning ,F-LT-OS-QL,softmax,beta,policy,Softmax Temperature,HalfNormal,Halfnormal(1),FOSCQLearner_softmax,FOSCQS,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Omission Sensitive Q Learning ,F-LT-OS-QL,e-softmax,alpha,learningrule,Learning/Forgetting Rate,Beta,"Beta(1,1)",FOSCQLearner_esoftmax,FOSCQES,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Omission Sensitive Q Learning ,F-LT-OS-QL,e-softmax,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",FOSCQLearner_esoftmax,FOSCQES,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Omission Sensitive Q Learning ,F-LT-OS-QL,e-softmax,theta,learningrule,Omission Sensitivity,Normal,"Normal(0,1)",FOSCQLearner_esoftmax,FOSCQES,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Omission Sensitive Q Learning ,F-LT-OS-QL,e-softmax,beta,policy,Softmax Temperature,HalfNormal,Halfnormal(1),FOSCQLearner_esoftmax,FOSCQES,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Omission Sensitive Q Learning ,F-LT-OS-QL,e-softmax,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",FOSCQLearner_esoftmax,FOSCQES,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Omission Sensitive Q Learning ,F-LT-OS-QL,acceptreject,alpha,learningrule,Learning/Forgetting Rate,Beta,"Beta(1,1)",FOSCQLearner_acceptreject,FOSCQBR,None,NUTS,modelfits/acceptreject/FOSCQBR_2022_04_12_14_09_37.nc,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Omission Sensitive Q Learning ,F-LT-OS-QL,acceptreject,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",FOSCQLearner_acceptreject,FOSCQBR,None,NUTS,modelfits/acceptreject/FOSCQBR_2022_04_12_14_09_37.nc,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Omission Sensitive Q Learning ,F-LT-OS-QL,acceptreject,theta,learningrule,Omission Sensitivity,Normal,"Normal(0,1)",FOSCQLearner_acceptreject,FOSCQBR,None,NUTS,modelfits/acceptreject/FOSCQBR_2022_04_12_14_09_37.nc,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Omission Sensitive Q Learning ,F-LT-OS-QL,acceptreject,weight,policy,Q-value weight,Normal,"Normal(0,1)",FOSCQLearner_acceptreject,FOSCQBR,None,NUTS,modelfits/acceptreject/FOSCQBR_2022_04_12_14_09_37.nc,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Omission Sensitive Q Learning ,F-LT-OS-QL,acceptreject,intercept,policy,Q-value intercept,Normal,"Normal(0,1)",FOSCQLearner_acceptreject,FOSCQBR,None,NUTS,modelfits/acceptreject/FOSCQBR_2022_04_12_14_09_37.nc,+,+,+,+,-
Value-Based RL,Differential Forgetting Immediate Omission Sensitive Q Learning ,DF-I-OS-QL,e-greedy,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",DFOSQLearner_egreedy,DFOSQE,None,NUTS,None,+,+,-,+,-
Value-Based RL,Differential Forgetting Immediate Omission Sensitive Q Learning ,DF-I-OS-QL,e-greedy,kappa,learningrule,Forgetting Rate,Beta,"Beta(1,1)",DFOSQLearner_egreedy,DFOSQE,None,NUTS,None,+,+,-,+,-
Value-Based RL,Differential Forgetting Immediate Omission Sensitive Q Learning ,DF-I-OS-QL,e-greedy,theta,learningrule,Omission Sensitivity,Normal,"Normal(0,1)",DFOSQLearner_egreedy,DFOSQE,None,NUTS,None,+,+,-,+,-
Value-Based RL,Differential Forgetting Immediate Omission Sensitive Q Learning ,DF-I-OS-QL,e-greedy,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",DFOSQLearner_egreedy,DFOSQE,None,NUTS,None,+,+,-,+,-
Value-Based RL,Differential Forgetting Immediate Omission Sensitive Q Learning ,DF-I-OS-QL,softmax,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",DFOSQLearner_softmax,DFOSQS,None,NUTS,None,+,+,-,+,-
Value-Based RL,Differential Forgetting Immediate Omission Sensitive Q Learning ,DF-I-OS-QL,softmax,kappa,learningrule,Forgetting Rate,Beta,"Beta(1,1)",DFOSQLearner_softmax,DFOSQS,None,NUTS,None,+,+,-,+,-
Value-Based RL,Differential Forgetting Immediate Omission Sensitive Q Learning ,DF-I-OS-QL,softmax,theta,learningrule,Omission Sensitivity,Normal,"Normal(0,1)",DFOSQLearner_softmax,DFOSQS,None,NUTS,None,+,+,-,+,-
Value-Based RL,Differential Forgetting Immediate Omission Sensitive Q Learning ,DF-I-OS-QL,softmax,beta,policy,Softmax Temperature,HalfNormal,Halfnormal(1),DFOSQLearner_softmax,DFOSQS,None,NUTS,None,+,+,-,+,-
Value-Based RL,Differential Forgetting Immediate Omission Sensitive Q Learning ,DF-I-OS-QL,e-softmax,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",DFOSQLearner_esoftmax,DFOSQES,None,NUTS,None,+,+,-,+,-
Value-Based RL,Differential Forgetting Immediate Omission Sensitive Q Learning ,DF-I-OS-QL,e-softmax,kappa,learningrule,Forgetting Rate,Beta,"Beta(1,1)",DFOSQLearner_esoftmax,DFOSQES,None,NUTS,None,+,+,-,+,-
Value-Based RL,Differential Forgetting Immediate Omission Sensitive Q Learning ,DF-I-OS-QL,e-softmax,theta,learningrule,Omission Sensitivity,Normal,"Normal(0,1)",DFOSQLearner_esoftmax,DFOSQES,None,NUTS,None,+,+,-,+,-
Value-Based RL,Differential Forgetting Immediate Omission Sensitive Q Learning ,DF-I-OS-QL,e-softmax,beta,policy,Softmax Temperature,HalfNormal,Halfnormal(1),DFOSQLearner_esoftmax,DFOSQES,None,NUTS,None,+,+,-,+,-
Value-Based RL,Differential Forgetting Immediate Omission Sensitive Q Learning ,DF-I-OS-QL,e-softmax,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",DFOSQLearner_esoftmax,DFOSQES,None,NUTS,None,+,+,-,+,-
Value-Based RL,Differential Forgetting Immediate Omission Sensitive Q Learning ,DF-I-OS-QL,acceptreject,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",DFOSQLearner_acceptreject,DFOSQBR,None,NUTS,modelfits/acceptreject/DFOSQBR_2022_04_20_17_01_19.nc,+,+,-,+,-
Value-Based RL,Differential Forgetting Immediate Omission Sensitive Q Learning ,DF-I-OS-QL,acceptreject,kappa,learningrule,Forgetting Rate,Beta,"Beta(1,1)",DFOSQLearner_acceptreject,DFOSQBR,None,NUTS,modelfits/acceptreject/DFOSQBR_2022_04_20_17_01_19.nc,+,+,-,+,-
Value-Based RL,Differential Forgetting Immediate Omission Sensitive Q Learning ,DF-I-OS-QL,acceptreject,theta,learningrule,Omission Sensitivity,Normal,"Normal(0,1)",DFOSQLearner_acceptreject,DFOSQBR,None,NUTS,modelfits/acceptreject/DFOSQBR_2022_04_20_17_01_19.nc,+,+,-,+,-
Value-Based RL,Differential Forgetting Immediate Omission Sensitive Q Learning ,DF-I-OS-QL,acceptreject,weight,policy,Q-value weight,Normal,"Normal(0,1)",DFOSQLearner_acceptreject,DFOSQBR,None,NUTS,modelfits/acceptreject/DFOSQBR_2022_04_20_17_01_19.nc,+,+,-,+,-
Value-Based RL,Differential Forgetting Immediate Omission Sensitive Q Learning ,DF-I-OS-QL,acceptreject,intercept,policy,Q-value intercept,Normal,"Normal(0,1)",DFOSQLearner_acceptreject,DFOSQBR,None,NUTS,modelfits/acceptreject/DFOSQBR_2022_04_20_17_01_19.nc,+,+,-,+,-
Value-Based RL,Differential Forgetting Long-Term Omission Sensitive Q Learning ,DF-LT-OS-QL,e-greedy,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",DFOSCQLearner_egreedy,DFOSCQE,None,NUTS,None,+,+,+,+,-
Value-Based RL,Differential Forgetting Long-Term Omission Sensitive Q Learning ,DF-LT-OS-QL,e-greedy,kappa,learningrule,Forgetting Rate,Beta,"Beta(1,1)",DFOSCQLearner_egreedy,DFOSCQE,None,NUTS,None,+,+,+,+,-
Value-Based RL,Differential Forgetting Long-Term Omission Sensitive Q Learning ,DF-LT-OS-QL,e-greedy,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",DFOSCQLearner_egreedy,DFOSCQE,None,NUTS,None,+,+,+,+,-
Value-Based RL,Differential Forgetting Long-Term Omission Sensitive Q Learning ,DF-LT-OS-QL,e-greedy,theta,learningrule,Omission Sensitivity,Normal,"Normal(0,1)",DFOSCQLearner_egreedy,DFOSCQE,None,NUTS,None,+,+,+,+,-
Value-Based RL,Differential Forgetting Long-Term Omission Sensitive Q Learning ,DF-LT-OS-QL,e-greedy,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",DFOSCQLearner_egreedy,DFOSCQE,None,NUTS,None,+,+,+,+,-
Value-Based RL,Differential Forgetting Long-Term Omission Sensitive Q Learning ,DF-LT-OS-QL,softmax,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",DFOSCQLearner_softmax,DFOSCQE,None,NUTS,None,+,+,+,+,-
Value-Based RL,Differential Forgetting Long-Term Omission Sensitive Q Learning ,DF-LT-OS-QL,softmax,kappa,learningrule,Forgetting Rate,Beta,"Beta(1,1)",DFOSCQLearner_softmax,DFOSCQE,None,NUTS,None,+,+,+,+,-
Value-Based RL,Differential Forgetting Long-Term Omission Sensitive Q Learning ,DF-LT-OS-QL,softmax,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",DFOSCQLearner_softmax,DFOSCQE,None,NUTS,None,+,+,+,+,-
Value-Based RL,Differential Forgetting Long-Term Omission Sensitive Q Learning ,DF-LT-OS-QL,softmax,theta,learningrule,Omission Sensitivity,Normal,"Normal(0,1)",DFOSCQLearner_softmax,DFOSCQE,None,NUTS,None,+,+,+,+,-
Value-Based RL,Differential Forgetting Long-Term Omission Sensitive Q Learning ,DF-LT-OS-QL,softmax,beta,policy,Softmax Temperature,HalfNormal,Halfnormal(1),DFOSCQLearner_softmax,DFOSCQE,None,NUTS,None,+,+,+,+,-
Value-Based RL,Differential Forgetting Long-Term Omission Sensitive Q Learning ,DF-LT-OS-QL,e-softmax,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",DFOSCQLearner_esoftmax,DFOSCQES,None,NUTS,None,+,+,+,+,-
Value-Based RL,Differential Forgetting Long-Term Omission Sensitive Q Learning ,DF-LT-OS-QL,e-softmax,kappa,learningrule,Forgetting Rate,Beta,"Beta(1,1)",DFOSCQLearner_esoftmax,DFOSCQES,None,NUTS,None,+,+,+,+,-
Value-Based RL,Differential Forgetting Long-Term Omission Sensitive Q Learning ,DF-LT-OS-QL,e-softmax,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",DFOSCQLearner_esoftmax,DFOSCQES,None,NUTS,None,+,+,+,+,-
Value-Based RL,Differential Forgetting Long-Term Omission Sensitive Q Learning ,DF-LT-OS-QL,e-softmax,theta,learningrule,Omission Sensitivity,Normal,"Normal(0,1)",DFOSCQLearner_esoftmax,DFOSCQES,None,NUTS,None,+,+,+,+,-
Value-Based RL,Differential Forgetting Long-Term Omission Sensitive Q Learning ,DF-LT-OS-QL,e-softmax,beta,policy,Softmax Temperature,HalfNormal,Halfnormal(1),DFOSCQLearner_esoftmax,DFOSCQES,None,NUTS,None,+,+,+,+,-
Value-Based RL,Differential Forgetting Long-Term Omission Sensitive Q Learning ,DF-LT-OS-QL,e-softmax,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",DFOSCQLearner_esoftmax,DFOSCQES,None,NUTS,None,+,+,+,+,-
Value-Based RL,Differential Forgetting Long-Term Omission Sensitive Q Learning ,DF-LT-OS-QL,acceptreject,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",DFOSCQLearner_acceptreject,DFOSCQBR,None,NUTS,modelfits/acceptreject/DFOSCQBR_2022_04_20_17_01_19.nc,+,+,+,+,-
Value-Based RL,Differential Forgetting Long-Term Omission Sensitive Q Learning ,DF-LT-OS-QL,acceptreject,kappa,learningrule,Forgetting Rate,Beta,"Beta(1,1)",DFOSCQLearner_acceptreject,DFOSCQBR,None,NUTS,modelfits/acceptreject/DFOSCQBR_2022_04_20_17_01_19.nc,+,+,+,+,-
Value-Based RL,Differential Forgetting Long-Term Omission Sensitive Q Learning ,DF-LT-OS-QL,acceptreject,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",DFOSCQLearner_acceptreject,DFOSCQBR,None,NUTS,modelfits/acceptreject/DFOSCQBR_2022_04_20_17_01_19.nc,+,+,+,+,-
Value-Based RL,Differential Forgetting Long-Term Omission Sensitive Q Learning ,DF-LT-OS-QL,acceptreject,theta,learningrule,Omission Sensitivity,Normal,"Normal(0,1)",DFOSCQLearner_acceptreject,DFOSCQBR,None,NUTS,modelfits/acceptreject/DFOSCQBR_2022_04_20_17_01_19.nc,+,+,+,+,-
Value-Based RL,Differential Forgetting Long-Term Omission Sensitive Q Learning ,DF-LT-OS-QL,acceptreject,weight,policy,Q-value weight,Normal,"Normal(0,1)",DFOSCQLearner_acceptreject,DFOSCQBR,None,NUTS,modelfits/acceptreject/DFOSCQBR_2022_04_20_17_01_19.nc,+,+,+,+,-
Value-Based RL,Differential Forgetting Long-Term Omission Sensitive Q Learning ,DF-LT-OS-QL,acceptreject,intercept,policy,Q-value intercept,Normal,"Normal(0,1)",DFOSCQLearner_acceptreject,DFOSCQBR,None,NUTS,modelfits/acceptreject/DFOSCQBR_2022_04_20_17_01_19.nc,+,+,+,+,-
Value-Based RL,SARSA,SARSA,e-greedy,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",SARSALearner_egreedy,SE,None,NUTS,None,+,-,+,-,+
Value-Based RL,SARSA,SARSA,e-greedy,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",SARSALearner_egreedy,SE,None,NUTS,None,+,-,+,-,+
Value-Based RL,SARSA,SARSA,e-greedy,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",SARSALearner_egreedy,SE,None,NUTS,None,+,-,+,-,+
Value-Based RL,SARSA,SARSA,softmax,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",SARSALearner_softmax,SS,None,NUTS,None,+,-,+,-,+
Value-Based RL,SARSA,SARSA,softmax,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",SARSALearner_softmax,SS,None,NUTS,None,+,-,+,-,+
Value-Based RL,SARSA,SARSA,softmax,beta,policy,Softmax Temperature,HalfNormal,Halfnormal(1),SARSALearner_softmax,SS,None,NUTS,None,+,-,+,-,+
Value-Based RL,SARSA,SARSA,e-softmax,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",SARSALearner_esoftmax,SES,None,NUTS,modelfits/SES_2022_02_27_10_02_01.nc,+,-,+,-,+
Value-Based RL,SARSA,SARSA,e-softmax,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",SARSALearner_esoftmax,SES,None,NUTS,modelfits/SES_2022_02_27_10_02_01.nc,+,-,+,-,+
Value-Based RL,SARSA,SARSA,e-softmax,beta,policy,Softmax Temperature,HalfNormal,Halfnormal(1),SARSALearner_esoftmax,SES,None,NUTS,modelfits/SES_2022_02_27_10_02_01.nc,+,-,+,-,+
Value-Based RL,SARSA,SARSA,e-softmax,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",SARSALearner_esoftmax,SES,None,NUTS,modelfits/SES_2022_02_27_10_02_01.nc,+,-,+,-,+
Value-Based RL,SARSA,SARSA,acceptreject,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",SARSALearner_acceptreject,SBR,None,NUTS,modelfits/acceptreject/SBR_2022_04_11_11_01_06.nc,+,-,+,-,+
Value-Based RL,SARSA,SARSA,acceptreject,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",SARSALearner_acceptreject,SBR,None,NUTS,modelfits/acceptreject/SBR_2022_04_11_11_01_06.nc,+,-,+,-,+
Value-Based RL,SARSA,SARSA,acceptreject,weight,policy,Q-value weight,Normal,"Normal(0,1)",SARSALearner_acceptreject,SBR,None,NUTS,modelfits/acceptreject/SBR_2022_04_11_11_01_06.nc,+,-,+,-,+
Value-Based RL,SARSA,SARSA,acceptreject,intercept,policy,Q-value intercept,Normal,"Normal(0,1)",SARSALearner_acceptreject,SBR,None,NUTS,modelfits/acceptreject/SBR_2022_04_11_11_01_06.nc,+,-,+,-,+
Value-Based RL,Expected SARSA,ESARSA,e-greedy,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",ESARSALearner_egreedy,ESE,None,NUTS,None,+,-,+,-,+
Value-Based RL,Expected SARSA,ESARSA,e-greedy,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",ESARSALearner_egreedy,ESE,None,NUTS,None,+,-,+,-,+
Value-Based RL,Expected SARSA,ESARSA,e-greedy,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",ESARSALearner_egreedy,ESE,None,NUTS,None,+,-,+,-,+
Value-Based RL,Expected SARSA,ESARSA,softmax,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",ESARSALearner_softmax,ESS,None,NUTS,None,+,-,+,-,+
Value-Based RL,Expected SARSA,ESARSA,softmax,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",ESARSALearner_softmax,ESS,None,NUTS,None,+,-,+,-,+
Value-Based RL,Expected SARSA,ESARSA,softmax,beta,policy,Softmax Temperature,HalfNormal,Halfnormal(1),ESARSALearner_softmax,ESS,None,NUTS,None,+,-,+,-,+
Value-Based RL,Expected SARSA,ESARSA,e-softmax,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",ESARSALearner_esoftmax,ESES,None,NUTS,modelfits/ESES_2022_02_27_10_31_40.nc,+,-,+,-,+
Value-Based RL,Expected SARSA,ESARSA,e-softmax,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",ESARSALearner_esoftmax,ESES,None,NUTS,modelfits/ESES_2022_02_27_10_31_40.nc,+,-,+,-,+
Value-Based RL,Expected SARSA,ESARSA,e-softmax,beta,policy,Softmax Temperature,HalfNormal,Halfnormal(1),ESARSALearner_esoftmax,ESES,None,NUTS,modelfits/ESES_2022_02_27_10_31_40.nc,+,-,+,-,+
Value-Based RL,Expected SARSA,ESARSA,e-softmax,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",ESARSALearner_esoftmax,ESES,None,NUTS,modelfits/ESES_2022_02_27_10_31_40.nc,+,-,+,-,+
Value-Based RL,Expected SARSA,ESARSA,acceptreject,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",ESARSALearner_acceptreject,ESBR,None,NUTS,modelfits/acceptreject/ESBR_2022_04_11_15_43_12.nc,+,-,+,-,+
Value-Based RL,Expected SARSA,ESARSA,acceptreject,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",ESARSALearner_acceptreject,ESBR,None,NUTS,modelfits/acceptreject/ESBR_2022_04_11_15_43_12.nc,+,-,+,-,+
Value-Based RL,Expected SARSA,ESARSA,acceptreject,weight,policy,Q-value weight,Normal,"Normal(0,1)",ESARSALearner_acceptreject,ESBR,None,NUTS,modelfits/acceptreject/ESBR_2022_04_11_15_43_12.nc,+,-,+,-,+
Value-Based RL,Expected SARSA,ESARSA,acceptreject,intercept,policy,Q-value intercept,Normal,"Normal(0,1)",ESARSALearner_acceptreject,ESBR,None,NUTS,modelfits/acceptreject/ESBR_2022_04_11_15_43_12.nc,+,-,+,-,+
Value-Based RL,Immediate Habit-Value Arbiter Q Learning,I-HV-QL,e-greedy,alpha_r,learningrule,Reward Learning Rate,Beta,"Beta(1,1)",HQLearner_egreedy,HQE,None,NUTS,None,+,-,-,+,-
Value-Based RL,Immediate Habit-Value Arbiter Q Learning,I-HV-QL,e-greedy,alpha_h,learningrule,Habit Learning Rate,Beta,"Beta(1,1)",HQLearner_egreedy,HQE,None,NUTS,None,+,-,-,+,-
Value-Based RL,Immediate Habit-Value Arbiter Q Learning,I-HV-QL,e-greedy,weight_r,learningrule,Reward weightage,Beta,"Beta(1,1)",HQLearner_egreedy,HQE,None,NUTS,None,+,-,-,+,-
Value-Based RL,Immediate Habit-Value Arbiter Q Learning,I-HV-QL,e-greedy,weight_h,learningrule,Habit weightage,Beta,"Beta(1,1)",HQLearner_egreedy,HQE,None,NUTS,None,+,-,-,+,-
Value-Based RL,Immediate Habit-Value Arbiter Q Learning,I-HV-QL,e-greedy,weight_b,learningrule,Bias,Beta,"Beta(1,1)",HQLearner_egreedy,HQE,None,NUTS,None,+,-,-,+,-
Value-Based RL,Immediate Habit-Value Arbiter Q Learning,I-HV-QL,e-greedy,theta_r,policy,Reward scaling factor,Beta,"Beta(1,1)",HQLearner_egreedy,HQE,None,NUTS,None,+,-,-,+,-
Value-Based RL,Immediate Habit-Value Arbiter Q Learning,I-HV-QL,e-greedy,theta_h,policy,Habit scaling factor,Beta,"Beta(1,1)",HQLearner_egreedy,HQE,None,NUTS,None,+,-,-,+,-
Value-Based RL,Immediate Habit-Value Arbiter Q Learning,I-HV-QL,e-greedy,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",HQLearner_egreedy,HQE,None,NUTS,None,+,-,-,+,-
Value-Based RL,Immediate Habit-Value Arbiter Q Learning,I-HV-QL,softmax,alpha_r,learningrule,Reward Learning Rate,Beta,"Beta(1,1)",HQLearner_softmax,HQS,None,NUTS,None,+,-,-,+,-
Value-Based RL,Immediate Habit-Value Arbiter Q Learning,I-HV-QL,softmax,alpha_h,learningrule,Habit Learning Rate,Beta,"Beta(1,1)",HQLearner_softmax,HQS,None,NUTS,None,+,-,-,+,-
Value-Based RL,Immediate Habit-Value Arbiter Q Learning,I-HV-QL,softmax,weight_r,learningrule,Reward weightage,Beta,"Beta(1,1)",HQLearner_softmax,HQS,None,NUTS,None,+,-,-,+,-
Value-Based RL,Immediate Habit-Value Arbiter Q Learning,I-HV-QL,softmax,weight_h,learningrule,Habit weightage,Beta,"Beta(1,1)",HQLearner_softmax,HQS,None,NUTS,None,+,-,-,+,-
Value-Based RL,Immediate Habit-Value Arbiter Q Learning,I-HV-QL,softmax,weight_b,learningrule,Bias,Beta,"Beta(1,1)",HQLearner_softmax,HQS,None,NUTS,None,+,-,-,+,-
Value-Based RL,Immediate Habit-Value Arbiter Q Learning,I-HV-QL,softmax,theta_r,policy,Reward scaling factor,Beta,"Beta(1,1)",HQLearner_softmax,HQS,None,NUTS,None,+,-,-,+,-
Value-Based RL,Immediate Habit-Value Arbiter Q Learning,I-HV-QL,softmax,theta_h,policy,Habit scaling factor,Beta,"Beta(1,1)",HQLearner_softmax,HQS,None,NUTS,None,+,-,-,+,-
Value-Based RL,Immediate Habit-Value Arbiter Q Learning,I-HV-QL,softmax,beta,policy,Softmax Temperature,HalfNormal,HalfNormal(1),HQLearner_softmax,HQS,None,NUTS,None,+,-,-,+,-
Value-Based RL,Immediate Habit-Value Arbiter Q Learning,I-HV-QL,e-softmax,alpha_r,learningrule,Reward Learning Rate,Beta,"Beta(1,1)",HQLearner_esoftmax,HQES,None,NUTS,modelfits/HQES_2022_03_09_13_41_27.nc,+,-,-,+,-
Value-Based RL,Immediate Habit-Value Arbiter Q Learning,I-HV-QL,e-softmax,alpha_h,learningrule,Habit Learning Rate,Beta,"Beta(1,1)",HQLearner_esoftmax,HQES,None,NUTS,modelfits/HQES_2022_03_09_13_41_27.nc,+,-,-,+,-
Value-Based RL,Immediate Habit-Value Arbiter Q Learning,I-HV-QL,e-softmax,weight_r,learningrule,Reward weightage,Beta,"Beta(1,1)",HQLearner_esoftmax,HQES,None,NUTS,modelfits/HQES_2022_03_09_13_41_27.nc,+,-,-,+,-
Value-Based RL,Immediate Habit-Value Arbiter Q Learning,I-HV-QL,e-softmax,weight_h,learningrule,Habit weightage,Beta,"Beta(1,1)",HQLearner_esoftmax,HQES,None,NUTS,modelfits/HQES_2022_03_09_13_41_27.nc,+,-,-,+,-
Value-Based RL,Immediate Habit-Value Arbiter Q Learning,I-HV-QL,e-softmax,weight_b,learningrule,Bias,Beta,"Beta(1,1)",HQLearner_esoftmax,HQES,None,NUTS,modelfits/HQES_2022_03_09_13_41_27.nc,+,-,-,+,-
Value-Based RL,Immediate Habit-Value Arbiter Q Learning,I-HV-QL,e-softmax,theta_r,policy,Reward scaling factor,Beta,"Beta(1,1)",HQLearner_esoftmax,HQES,None,NUTS,modelfits/HQES_2022_03_09_13_41_27.nc,+,-,-,+,-
Value-Based RL,Immediate Habit-Value Arbiter Q Learning,I-HV-QL,e-softmax,theta_h,policy,Habit scaling factor,Beta,"Beta(1,1)",HQLearner_esoftmax,HQES,None,NUTS,modelfits/HQES_2022_03_09_13_41_27.nc,+,-,-,+,-
Value-Based RL,Immediate Habit-Value Arbiter Q Learning,I-HV-QL,e-softmax,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",HQLearner_esoftmax,HQES,None,NUTS,modelfits/HQES_2022_03_09_13_41_27.nc,+,-,-,+,-
Value-Based RL,Immediate Habit-Value Arbiter Q Learning,I-HV-QL,e-softmax,beta,policy,Softmax Temperature,HalfNormal,HalfNormal(1),HQLearner_esoftmax,HQES,None,NUTS,modelfits/HQES_2022_03_09_13_41_27.nc,+,-,-,+,-
Value-Based RL,Immediate Habit-Value Arbiter Q Learning,I-HV-QL,acceptreject,alpha_r,learningrule,Reward Learning Rate,Beta,"Beta(1,1)",HQLearner_acceptreject,HQBR,None,NUTS,modelfits/acceptreject/HQBR_2022_04_11_16_15_55.nc,+,-,-,+,-
Value-Based RL,Immediate Habit-Value Arbiter Q Learning,I-HV-QL,acceptreject,alpha_h,learningrule,Habit Learning Rate,Beta,"Beta(1,1)",HQLearner_acceptreject,HQBR,None,NUTS,modelfits/acceptreject/HQBR_2022_04_11_16_15_55.nc,+,-,-,+,-
Value-Based RL,Immediate Habit-Value Arbiter Q Learning,I-HV-QL,acceptreject,weight_r,learningrule,Reward weightage,Beta,"Beta(1,1)",HQLearner_acceptreject,HQBR,None,NUTS,modelfits/acceptreject/HQBR_2022_04_11_16_15_55.nc,+,-,-,+,-
Value-Based RL,Immediate Habit-Value Arbiter Q Learning,I-HV-QL,acceptreject,weight_h,learningrule,Habit weightage,Beta,"Beta(1,1)",HQLearner_acceptreject,HQBR,None,NUTS,modelfits/acceptreject/HQBR_2022_04_11_16_15_55.nc,+,-,-,+,-
Value-Based RL,Immediate Habit-Value Arbiter Q Learning,I-HV-QL,acceptreject,weight_b,learningrule,Bias,Beta,"Beta(1,1)",HQLearner_acceptreject,HQBR,None,NUTS,modelfits/acceptreject/HQBR_2022_04_11_16_15_55.nc,+,-,-,+,-
Value-Based RL,Immediate Habit-Value Arbiter Q Learning,I-HV-QL,acceptreject,theta_r,policy,Reward scaling factor,Beta,"Beta(1,1)",HQLearner_acceptreject,HQBR,None,NUTS,modelfits/acceptreject/HQBR_2022_04_11_16_15_55.nc,+,-,-,+,-
Value-Based RL,Immediate Habit-Value Arbiter Q Learning,I-HV-QL,acceptreject,theta_h,policy,Habit scaling factor,Beta,"Beta(1,1)",HQLearner_acceptreject,HQBR,None,NUTS,modelfits/acceptreject/HQBR_2022_04_11_16_15_55.nc,+,-,-,+,-
Value-Based RL,Immediate Habit-Value Arbiter Q Learning,I-HV-QL,acceptreject,weight,policy,Q-value weight,Normal,"Normal(0,1)",HQLearner_acceptreject,HQBR,None,NUTS,modelfits/acceptreject/HQBR_2022_04_11_16_15_55.nc,+,-,-,+,-
Value-Based RL,Immediate Habit-Value Arbiter Q Learning,I-HV-QL,acceptreject,intercept,policy,Q-value intercept,Normal,"Normal(0,1)",HQLearner_acceptreject,HQBR,None,NUTS,modelfits/acceptreject/HQBR_2022_04_11_16_15_55.nc,+,-,-,+,-
Value-Based RL,Forgetting Immediate Habit-Value Arbiter Q-Learning,F-I-HV-QL,e-greedy,alpha_r,learningrule,Reward Learning Rate,Beta,"Beta(1,1)",FHQLearner_egreedy,FHQE,None,NUTS,None,+,+,-,+,-
Value-Based RL,Forgetting Immediate Habit-Value Arbiter Q-Learning,F-I-HV-QL,e-greedy,alpha_h,learningrule,Habit Learning Rate,Beta,"Beta(1,1)",FHQLearner_egreedy,FHQE,None,NUTS,None,+,+,-,+,-
Value-Based RL,Forgetting Immediate Habit-Value Arbiter Q-Learning,F-I-HV-QL,e-greedy,weight_r,learningrule,Reward weightage,Beta,"Beta(1,1)",FHQLearner_egreedy,FHQE,None,NUTS,None,+,+,-,+,-
Value-Based RL,Forgetting Immediate Habit-Value Arbiter Q-Learning,F-I-HV-QL,e-greedy,weight_h,learningrule,Habit weightage,Beta,"Beta(1,1)",FHQLearner_egreedy,FHQE,None,NUTS,None,+,+,-,+,-
Value-Based RL,Forgetting Immediate Habit-Value Arbiter Q-Learning,F-I-HV-QL,e-greedy,weight_b,learningrule,Bias,Beta,"Beta(1,1)",FHQLearner_egreedy,FHQE,None,NUTS,None,+,+,-,+,-
Value-Based RL,Forgetting Immediate Habit-Value Arbiter Q-Learning,F-I-HV-QL,e-greedy,theta_r,policy,Reward scaling factor,Beta,"Beta(1,1)",FHQLearner_egreedy,FHQE,None,NUTS,None,+,+,-,+,-
Value-Based RL,Forgetting Immediate Habit-Value Arbiter Q-Learning,F-I-HV-QL,e-greedy,theta_h,policy,Habit scaling factor,Beta,"Beta(1,1)",FHQLearner_egreedy,FHQE,None,NUTS,None,+,+,-,+,-
Value-Based RL,Forgetting Immediate Habit-Value Arbiter Q-Learning,F-I-HV-QL,e-greedy,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",FHQLearner_egreedy,FHQE,None,NUTS,None,+,+,-,+,-
Value-Based RL,Forgetting Immediate Habit-Value Arbiter Q-Learning,F-I-HV-QL,softmax,alpha_r,learningrule,Reward Learning Rate,Beta,"Beta(1,1)",FHQLearner_softmax,FHQS,None,NUTS,None,+,+,-,+,-
Value-Based RL,Forgetting Immediate Habit-Value Arbiter Q-Learning,F-I-HV-QL,softmax,alpha_h,learningrule,Habit Learning Rate,Beta,"Beta(1,1)",FHQLearner_softmax,FHQS,None,NUTS,None,+,+,-,+,-
Value-Based RL,Forgetting Immediate Habit-Value Arbiter Q-Learning,F-I-HV-QL,softmax,weight_r,learningrule,Reward weightage,Beta,"Beta(1,1)",FHQLearner_softmax,FHQS,None,NUTS,None,+,+,-,+,-
Value-Based RL,Forgetting Immediate Habit-Value Arbiter Q-Learning,F-I-HV-QL,softmax,weight_h,learningrule,Habit weightage,Beta,"Beta(1,1)",FHQLearner_softmax,FHQS,None,NUTS,None,+,+,-,+,-
Value-Based RL,Forgetting Immediate Habit-Value Arbiter Q-Learning,F-I-HV-QL,softmax,weight_b,learningrule,Bias,Beta,"Beta(1,1)",FHQLearner_softmax,FHQS,None,NUTS,None,+,+,-,+,-
Value-Based RL,Forgetting Immediate Habit-Value Arbiter Q-Learning,F-I-HV-QL,softmax,theta_r,policy,Reward scaling factor,Beta,"Beta(1,1)",FHQLearner_softmax,FHQS,None,NUTS,None,+,+,-,+,-
Value-Based RL,Forgetting Immediate Habit-Value Arbiter Q-Learning,F-I-HV-QL,softmax,theta_h,policy,Habit scaling factor,Beta,"Beta(1,1)",FHQLearner_softmax,FHQS,None,NUTS,None,+,+,-,+,-
Value-Based RL,Forgetting Immediate Habit-Value Arbiter Q-Learning,F-I-HV-QL,softmax,beta,policy,Softmax Temperature,HalfNormal,HalfNormal(1),FHQLearner_softmax,FHQS,None,NUTS,None,+,+,-,+,-
Value-Based RL,Forgetting Immediate Habit-Value Arbiter Q-Learning,F-I-HV-QL,e-softmax,alpha_r,learningrule,Reward Learning Rate,Beta,"Beta(1,1)",FHQLearner_esoftmax,FHQES,None,NUTS,None,+,+,-,+,-
Value-Based RL,Forgetting Immediate Habit-Value Arbiter Q-Learning,F-I-HV-QL,e-softmax,alpha_h,learningrule,Habit Learning Rate,Beta,"Beta(1,1)",FHQLearner_esoftmax,FHQES,None,NUTS,None,+,+,-,+,-
Value-Based RL,Forgetting Immediate Habit-Value Arbiter Q-Learning,F-I-HV-QL,e-softmax,weight_r,learningrule,Reward weightage,Beta,"Beta(1,1)",FHQLearner_esoftmax,FHQES,None,NUTS,None,+,+,-,+,-
Value-Based RL,Forgetting Immediate Habit-Value Arbiter Q-Learning,F-I-HV-QL,e-softmax,weight_h,learningrule,Habit weightage,Beta,"Beta(1,1)",FHQLearner_esoftmax,FHQES,None,NUTS,None,+,+,-,+,-
Value-Based RL,Forgetting Immediate Habit-Value Arbiter Q-Learning,F-I-HV-QL,e-softmax,weight_b,learningrule,Bias,Beta,"Beta(1,1)",FHQLearner_esoftmax,FHQES,None,NUTS,None,+,+,-,+,-
Value-Based RL,Forgetting Immediate Habit-Value Arbiter Q-Learning,F-I-HV-QL,e-softmax,theta_r,policy,Reward scaling factor,Beta,"Beta(1,1)",FHQLearner_esoftmax,FHQES,None,NUTS,None,+,+,-,+,-
Value-Based RL,Forgetting Immediate Habit-Value Arbiter Q-Learning,F-I-HV-QL,e-softmax,theta_h,policy,Habit scaling factor,Beta,"Beta(1,1)",FHQLearner_esoftmax,FHQES,None,NUTS,None,+,+,-,+,-
Value-Based RL,Forgetting Immediate Habit-Value Arbiter Q-Learning,F-I-HV-QL,e-softmax,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",FHQLearner_esoftmax,FHQES,None,NUTS,None,+,+,-,+,-
Value-Based RL,Forgetting Immediate Habit-Value Arbiter Q-Learning,F-I-HV-QL,e-softmax,beta,policy,Softmax Temperature,HalfNormal,HalfNormal(1),FHQLearner_esoftmax,FHQES,None,NUTS,None,+,+,-,+,-
Value-Based RL,Forgetting Immediate Habit-Value Arbiter Q-Learning,F-I-HV-QL,acceptreject,alpha_r,learningrule,Reward Learning Rate,Beta,"Beta(1,1)",FHQLearner_acceptreject,FHQBR,None,NUTS,modelfits/acceptreject/FHQBR_2022_04_22_22_09_26.nc,+,+,-,+,-
Value-Based RL,Forgetting Immediate Habit-Value Arbiter Q-Learning,F-I-HV-QL,acceptreject,alpha_h,learningrule,Habit Learning Rate,Beta,"Beta(1,1)",FHQLearner_acceptreject,FHQBR,None,NUTS,modelfits/acceptreject/FHQBR_2022_04_22_22_09_26.nc,+,+,-,+,-
Value-Based RL,Forgetting Immediate Habit-Value Arbiter Q-Learning,F-I-HV-QL,acceptreject,weight_r,learningrule,Reward weightage,Beta,"Beta(1,1)",FHQLearner_acceptreject,FHQBR,None,NUTS,modelfits/acceptreject/FHQBR_2022_04_22_22_09_26.nc,+,+,-,+,-
Value-Based RL,Forgetting Immediate Habit-Value Arbiter Q-Learning,F-I-HV-QL,acceptreject,weight_h,learningrule,Habit weightage,Beta,"Beta(1,1)",FHQLearner_acceptreject,FHQBR,None,NUTS,modelfits/acceptreject/FHQBR_2022_04_22_22_09_26.nc,+,+,-,+,-
Value-Based RL,Forgetting Immediate Habit-Value Arbiter Q-Learning,F-I-HV-QL,acceptreject,weight_b,learningrule,Bias,Beta,"Beta(1,1)",FHQLearner_acceptreject,FHQBR,None,NUTS,modelfits/acceptreject/FHQBR_2022_04_22_22_09_26.nc,+,+,-,+,-
Value-Based RL,Forgetting Immediate Habit-Value Arbiter Q-Learning,F-I-HV-QL,acceptreject,theta_r,policy,Reward scaling factor,Beta,"Beta(1,1)",FHQLearner_acceptreject,FHQBR,None,NUTS,modelfits/acceptreject/FHQBR_2022_04_22_22_09_26.nc,+,+,-,+,-
Value-Based RL,Forgetting Immediate Habit-Value Arbiter Q-Learning,F-I-HV-QL,acceptreject,theta_h,policy,Habit scaling factor,Beta,"Beta(1,1)",FHQLearner_acceptreject,FHQBR,None,NUTS,modelfits/acceptreject/FHQBR_2022_04_22_22_09_26.nc,+,+,-,+,-
Value-Based RL,Forgetting Immediate Habit-Value Arbiter Q-Learning,F-I-HV-QL,acceptreject,weight,policy,Q-value weight,Normal,"Normal(0,1)",FHQLearner_acceptreject,FHQBR,None,NUTS,modelfits/acceptreject/FHQBR_2022_04_22_22_09_26.nc,+,+,-,+,-
Value-Based RL,Forgetting Immediate Habit-Value Arbiter Q-Learning,F-I-HV-QL,acceptreject,intercept,policy,Q-value intercept,Normal,"Normal(0,1)",FHQLearner_acceptreject,FHQBR,None,NUTS,modelfits/acceptreject/FHQBR_2022_04_22_22_09_26.nc,+,+,-,+,-
Value-Based RL,Long-Term Habit-Value Arbiter Q-Learning,LT-HV-QL,e-greedy,alpha_r,learningrule,Reward Learning Rate,Beta,"Beta(1,1)",HCQLearner_egreedy,HCQE,None,NUTS,None,+,-,+,+,-
Value-Based RL,Long-Term Habit-Value Arbiter Q-Learning,LT-HV-QL,e-greedy,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",HCQLearner_egreedy,HCQE,None,NUTS,None,+,-,+,+,-
Value-Based RL,Long-Term Habit-Value Arbiter Q-Learning,LT-HV-QL,e-greedy,alpha_h,learningrule,Habit Learning Rate,Beta,"Beta(1,1)",HCQLearner_egreedy,HCQE,None,NUTS,None,+,-,+,+,-
Value-Based RL,Long-Term Habit-Value Arbiter Q-Learning,LT-HV-QL,e-greedy,weight_r,learningrule,Reward weightage,Beta,"Beta(1,1)",HCQLearner_egreedy,HCQE,None,NUTS,None,+,-,+,+,-
Value-Based RL,Long-Term Habit-Value Arbiter Q-Learning,LT-HV-QL,e-greedy,weight_h,learningrule,Habit weightage,Beta,"Beta(1,1)",HCQLearner_egreedy,HCQE,None,NUTS,None,+,-,+,+,-
Value-Based RL,Long-Term Habit-Value Arbiter Q-Learning,LT-HV-QL,e-greedy,weight_b,learningrule,Bias,Beta,"Beta(1,1)",HCQLearner_egreedy,HCQE,None,NUTS,None,+,-,+,+,-
Value-Based RL,Long-Term Habit-Value Arbiter Q-Learning,LT-HV-QL,e-greedy,theta_r,policy,Reward scaling factor,Beta,"Beta(1,1)",HCQLearner_egreedy,HCQE,None,NUTS,None,+,-,+,+,-
Value-Based RL,Long-Term Habit-Value Arbiter Q-Learning,LT-HV-QL,e-greedy,theta_h,policy,Habit scaling factor,Beta,"Beta(1,1)",HCQLearner_egreedy,HCQE,None,NUTS,None,+,-,+,+,-
Value-Based RL,Long-Term Habit-Value Arbiter Q-Learning,LT-HV-QL,e-greedy,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",HCQLearner_egreedy,HCQE,None,NUTS,None,+,-,+,+,-
Value-Based RL,Long-Term Habit-Value Arbiter Q-Learning,LT-HV-QL,softmax,alpha_r,learningrule,Reward Learning Rate,Beta,"Beta(1,1)",HCQLearner_softmax,HCQS,None,NUTS,None,+,-,+,+,-
Value-Based RL,Long-Term Habit-Value Arbiter Q-Learning,LT-HV-QL,softmax,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",HCQLearner_softmax,HCQS,None,NUTS,None,+,-,+,+,-
Value-Based RL,Long-Term Habit-Value Arbiter Q-Learning,LT-HV-QL,softmax,alpha_h,learningrule,Habit Learning Rate,Beta,"Beta(1,1)",HCQLearner_softmax,HCQS,None,NUTS,None,+,-,+,+,-
Value-Based RL,Long-Term Habit-Value Arbiter Q-Learning,LT-HV-QL,softmax,weight_r,learningrule,Reward weightage,Beta,"Beta(1,1)",HCQLearner_softmax,HCQS,None,NUTS,None,+,-,+,+,-
Value-Based RL,Long-Term Habit-Value Arbiter Q-Learning,LT-HV-QL,softmax,weight_h,learningrule,Habit weightage,Beta,"Beta(1,1)",HCQLearner_softmax,HCQS,None,NUTS,None,+,-,+,+,-
Value-Based RL,Long-Term Habit-Value Arbiter Q-Learning,LT-HV-QL,softmax,weight_b,learningrule,Bias,Beta,"Beta(1,1)",HCQLearner_softmax,HCQS,None,NUTS,None,+,-,+,+,-
Value-Based RL,Long-Term Habit-Value Arbiter Q-Learning,LT-HV-QL,softmax,theta_r,policy,Reward scaling factor,Beta,"Beta(1,1)",HCQLearner_softmax,HCQS,None,NUTS,None,+,-,+,+,-
Value-Based RL,Long-Term Habit-Value Arbiter Q-Learning,LT-HV-QL,softmax,theta_h,policy,Habit scaling factor,Beta,"Beta(1,1)",HCQLearner_softmax,HCQS,None,NUTS,None,+,-,+,+,-
Value-Based RL,Long-Term Habit-Value Arbiter Q-Learning,LT-HV-QL,softmax,beta,policy,Softmax Temperature,HalfNormal,HalfNormal(1),HCQLearner_softmax,HCQS,None,NUTS,None,+,-,+,+,-
Value-Based RL,Long-Term Habit-Value Arbiter Q-Learning,LT-HV-QL,e-softmax,alpha_r,learningrule,Reward Learning Rate,Beta,"Beta(1,1)",HCQLearner_esoftmax,HCQES,None,NUTS,modelfits/HCQES_2022_03_14_11_23_44.nc,+,-,+,+,-
Value-Based RL,Long-Term Habit-Value Arbiter Q-Learning,LT-HV-QL,e-softmax,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",HCQLearner_esoftmax,HCQES,None,NUTS,modelfits/HCQES_2022_03_14_11_23_44.nc,+,-,+,+,-
Value-Based RL,Long-Term Habit-Value Arbiter Q-Learning,LT-HV-QL,e-softmax,alpha_h,learningrule,Habit Learning Rate,Beta,"Beta(1,1)",HCQLearner_esoftmax,HCQES,None,NUTS,modelfits/HCQES_2022_03_14_11_23_44.nc,+,-,+,+,-
Value-Based RL,Long-Term Habit-Value Arbiter Q-Learning,LT-HV-QL,e-softmax,weight_r,learningrule,Reward weightage,Beta,"Beta(1,1)",HCQLearner_esoftmax,HCQES,None,NUTS,modelfits/HCQES_2022_03_14_11_23_44.nc,+,-,+,+,-
Value-Based RL,Long-Term Habit-Value Arbiter Q-Learning,LT-HV-QL,e-softmax,weight_h,learningrule,Habit weightage,Beta,"Beta(1,1)",HCQLearner_esoftmax,HCQES,None,NUTS,modelfits/HCQES_2022_03_14_11_23_44.nc,+,-,+,+,-
Value-Based RL,Long-Term Habit-Value Arbiter Q-Learning,LT-HV-QL,e-softmax,weight_b,learningrule,Bias,Beta,"Beta(1,1)",HCQLearner_esoftmax,HCQES,None,NUTS,modelfits/HCQES_2022_03_14_11_23_44.nc,+,-,+,+,-
Value-Based RL,Long-Term Habit-Value Arbiter Q-Learning,LT-HV-QL,e-softmax,theta_r,policy,Reward scaling factor,Beta,"Beta(1,1)",HCQLearner_esoftmax,HCQES,None,NUTS,modelfits/HCQES_2022_03_14_11_23_44.nc,+,-,+,+,-
Value-Based RL,Long-Term Habit-Value Arbiter Q-Learning,LT-HV-QL,e-softmax,theta_h,policy,Habit scaling factor,Beta,"Beta(1,1)",HCQLearner_esoftmax,HCQES,None,NUTS,modelfits/HCQES_2022_03_14_11_23_44.nc,+,-,+,+,-
Value-Based RL,Long-Term Habit-Value Arbiter Q-Learning,LT-HV-QL,e-softmax,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",HCQLearner_esoftmax,HCQES,None,NUTS,modelfits/HCQES_2022_03_14_11_23_44.nc,+,-,+,+,-
Value-Based RL,Long-Term Habit-Value Arbiter Q-Learning,LT-HV-QL,e-softmax,beta,policy,Softmax Temperature,HalfNormal,HalfNormal(1),HCQLearner_esoftmax,HCQES,None,NUTS,modelfits/HCQES_2022_03_14_11_23_44.nc,+,-,+,+,-
Value-Based RL,Long-Term Habit-Value Arbiter Q-Learning,LT-HV-QL,acceptreject,alpha_r,learningrule,Reward Learning Rate,Beta,"Beta(1,1)",HCQLearner_acceptreject,HCQBR,None,NUTS,modelfits/acceptreject/HCQBR_2022_04_11_16_15_56.nc,+,-,+,+,-
Value-Based RL,Long-Term Habit-Value Arbiter Q-Learning,LT-HV-QL,acceptreject,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",HCQLearner_acceptreject,HCQBR,None,NUTS,modelfits/acceptreject/HCQBR_2022_04_11_16_15_56.nc,+,-,+,+,-
Value-Based RL,Long-Term Habit-Value Arbiter Q-Learning,LT-HV-QL,acceptreject,alpha_h,learningrule,Habit Learning Rate,Beta,"Beta(1,1)",HCQLearner_acceptreject,HCQBR,None,NUTS,modelfits/acceptreject/HCQBR_2022_04_11_16_15_56.nc,+,-,+,+,-
Value-Based RL,Long-Term Habit-Value Arbiter Q-Learning,LT-HV-QL,acceptreject,weight_r,learningrule,Reward weightage,Beta,"Beta(1,1)",HCQLearner_acceptreject,HCQBR,None,NUTS,modelfits/acceptreject/HCQBR_2022_04_11_16_15_56.nc,+,-,+,+,-
Value-Based RL,Long-Term Habit-Value Arbiter Q-Learning,LT-HV-QL,acceptreject,weight_h,learningrule,Habit weightage,Beta,"Beta(1,1)",HCQLearner_acceptreject,HCQBR,None,NUTS,modelfits/acceptreject/HCQBR_2022_04_11_16_15_56.nc,+,-,+,+,-
Value-Based RL,Long-Term Habit-Value Arbiter Q-Learning,LT-HV-QL,acceptreject,weight_b,learningrule,Bias,Beta,"Beta(1,1)",HCQLearner_acceptreject,HCQBR,None,NUTS,modelfits/acceptreject/HCQBR_2022_04_11_16_15_56.nc,+,-,+,+,-
Value-Based RL,Long-Term Habit-Value Arbiter Q-Learning,LT-HV-QL,acceptreject,theta_r,policy,Reward scaling factor,Beta,"Beta(1,1)",HCQLearner_acceptreject,HCQBR,None,NUTS,modelfits/acceptreject/HCQBR_2022_04_11_16_15_56.nc,+,-,+,+,-
Value-Based RL,Long-Term Habit-Value Arbiter Q-Learning,LT-HV-QL,acceptreject,theta_h,policy,Habit scaling factor,Beta,"Beta(1,1)",HCQLearner_acceptreject,HCQBR,None,NUTS,modelfits/acceptreject/HCQBR_2022_04_11_16_15_56.nc,+,-,+,+,-
Value-Based RL,Long-Term Habit-Value Arbiter Q-Learning,LT-HV-QL,acceptreject,weight,policy,Q-value weight,Normal,"Normal(0,1)",HCQLearner_acceptreject,HCQBR,None,NUTS,modelfits/acceptreject/HCQBR_2022_04_11_16_15_56.nc,+,-,+,+,-
Value-Based RL,Long-Term Habit-Value Arbiter Q-Learning,LT-HV-QL,acceptreject,intercept,policy,Q-value intercept,Normal,"Normal(0,1)",HCQLearner_acceptreject,HCQBR,None,NUTS,modelfits/acceptreject/HCQBR_2022_04_11_16_15_56.nc,+,-,+,+,-
Value-Based RL,Forgetting Long-Term Habit-Value Arbiter Q-Learning,F-LT-HV-QL,e-greedy,alpha_r,learningrule,Reward Learning Rate,Beta,"Beta(1,1)",FHCQLearner_egreedy,FHCQE,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Habit-Value Arbiter Q-Learning,F-LT-HV-QL,e-greedy,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",FHCQLearner_egreedy,FHCQE,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Habit-Value Arbiter Q-Learning,F-LT-HV-QL,e-greedy,alpha_h,learningrule,Habit Learning Rate,Beta,"Beta(1,1)",FHCQLearner_egreedy,FHCQE,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Habit-Value Arbiter Q-Learning,F-LT-HV-QL,e-greedy,weight_r,learningrule,Reward weightage,Beta,"Beta(1,1)",FHCQLearner_egreedy,FHCQE,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Habit-Value Arbiter Q-Learning,F-LT-HV-QL,e-greedy,weight_h,learningrule,Habit weightage,Beta,"Beta(1,1)",FHCQLearner_egreedy,FHCQE,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Habit-Value Arbiter Q-Learning,F-LT-HV-QL,e-greedy,weight_b,learningrule,Bias,Beta,"Beta(1,1)",FHCQLearner_egreedy,FHCQE,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Habit-Value Arbiter Q-Learning,F-LT-HV-QL,e-greedy,theta_r,policy,Reward scaling factor,Beta,"Beta(1,1)",FHCQLearner_egreedy,FHCQE,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Habit-Value Arbiter Q-Learning,F-LT-HV-QL,e-greedy,theta_h,policy,Habit scaling factor,Beta,"Beta(1,1)",FHCQLearner_egreedy,FHCQE,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Habit-Value Arbiter Q-Learning,F-LT-HV-QL,e-greedy,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",FHCQLearner_egreedy,FHCQE,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Habit-Value Arbiter Q-Learning,F-LT-HV-QL,softmax,alpha_r,learningrule,Reward Learning Rate,Beta,"Beta(1,1)",FHCQLearner_softmax,FHCQS,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Habit-Value Arbiter Q-Learning,F-LT-HV-QL,softmax,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",FHCQLearner_softmax,FHCQS,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Habit-Value Arbiter Q-Learning,F-LT-HV-QL,softmax,alpha_h,learningrule,Habit Learning Rate,Beta,"Beta(1,1)",FHCQLearner_softmax,FHCQS,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Habit-Value Arbiter Q-Learning,F-LT-HV-QL,softmax,weight_r,learningrule,Reward weightage,Beta,"Beta(1,1)",FHCQLearner_softmax,FHCQS,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Habit-Value Arbiter Q-Learning,F-LT-HV-QL,softmax,weight_h,learningrule,Habit weightage,Beta,"Beta(1,1)",FHCQLearner_softmax,FHCQS,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Habit-Value Arbiter Q-Learning,F-LT-HV-QL,softmax,weight_b,learningrule,Bias,Beta,"Beta(1,1)",FHCQLearner_softmax,FHCQS,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Habit-Value Arbiter Q-Learning,F-LT-HV-QL,softmax,theta_r,policy,Reward scaling factor,Beta,"Beta(1,1)",FHCQLearner_softmax,FHCQS,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Habit-Value Arbiter Q-Learning,F-LT-HV-QL,softmax,theta_h,policy,Habit scaling factor,Beta,"Beta(1,1)",FHCQLearner_softmax,FHCQS,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Habit-Value Arbiter Q-Learning,F-LT-HV-QL,softmax,beta,policy,Softmax Temperature,HalfNormal,HalfNormal(1),FHCQLearner_softmax,FHCQS,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Habit-Value Arbiter Q-Learning,F-LT-HV-QL,e-softmax,alpha_r,learningrule,Reward Learning Rate,Beta,"Beta(1,1)",FHCQLearner_softmax,FHCQES,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Habit-Value Arbiter Q-Learning,F-LT-HV-QL,e-softmax,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",FHCQLearner_softmax,FHCQES,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Habit-Value Arbiter Q-Learning,F-LT-HV-QL,e-softmax,alpha_h,learningrule,Habit Learning Rate,Beta,"Beta(1,1)",FHCQLearner_softmax,FHCQES,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Habit-Value Arbiter Q-Learning,F-LT-HV-QL,e-softmax,weight_r,learningrule,Reward weightage,Beta,"Beta(1,1)",FHCQLearner_softmax,FHCQES,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Habit-Value Arbiter Q-Learning,F-LT-HV-QL,e-softmax,weight_h,learningrule,Habit weightage,Beta,"Beta(1,1)",FHCQLearner_softmax,FHCQES,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Habit-Value Arbiter Q-Learning,F-LT-HV-QL,e-softmax,weight_b,learningrule,Bias,Beta,"Beta(1,1)",FHCQLearner_softmax,FHCQES,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Habit-Value Arbiter Q-Learning,F-LT-HV-QL,e-softmax,theta_r,policy,Reward scaling factor,Beta,"Beta(1,1)",FHCQLearner_softmax,FHCQES,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Habit-Value Arbiter Q-Learning,F-LT-HV-QL,e-softmax,theta_h,policy,Habit scaling factor,Beta,"Beta(1,1)",FHCQLearner_softmax,FHCQES,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Habit-Value Arbiter Q-Learning,F-LT-HV-QL,e-softmax,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",FHCQLearner_softmax,FHCQES,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Habit-Value Arbiter Q-Learning,F-LT-HV-QL,e-softmax,beta,policy,Softmax Temperature,HalfNormal,HalfNormal(1),FHCQLearner_softmax,FHCQES,None,NUTS,None,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Habit-Value Arbiter Q-Learning,F-LT-HV-QL,acceptreject,alpha_r,learningrule,Reward Learning Rate,Beta,"Beta(1,1)",FHCQLearner_acceptreject,FHCQBR,None,NUTS,modelfits/acceptreject/FHCQBR_2022_04_22_22_09_23.nc,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Habit-Value Arbiter Q-Learning,F-LT-HV-QL,acceptreject,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",FHCQLearner_acceptreject,FHCQBR,None,NUTS,modelfits/acceptreject/FHCQBR_2022_04_22_22_09_23.nc,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Habit-Value Arbiter Q-Learning,F-LT-HV-QL,acceptreject,alpha_h,learningrule,Habit Learning Rate,Beta,"Beta(1,1)",FHCQLearner_acceptreject,FHCQBR,None,NUTS,modelfits/acceptreject/FHCQBR_2022_04_22_22_09_23.nc,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Habit-Value Arbiter Q-Learning,F-LT-HV-QL,acceptreject,weight_r,learningrule,Reward weightage,Beta,"Beta(1,1)",FHCQLearner_acceptreject,FHCQBR,None,NUTS,modelfits/acceptreject/FHCQBR_2022_04_22_22_09_23.nc,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Habit-Value Arbiter Q-Learning,F-LT-HV-QL,acceptreject,weight_h,learningrule,Habit weightage,Beta,"Beta(1,1)",FHCQLearner_acceptreject,FHCQBR,None,NUTS,modelfits/acceptreject/FHCQBR_2022_04_22_22_09_23.nc,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Habit-Value Arbiter Q-Learning,F-LT-HV-QL,acceptreject,weight_b,learningrule,Bias,Beta,"Beta(1,1)",FHCQLearner_acceptreject,FHCQBR,None,NUTS,modelfits/acceptreject/FHCQBR_2022_04_22_22_09_23.nc,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Habit-Value Arbiter Q-Learning,F-LT-HV-QL,acceptreject,theta_r,policy,Reward scaling factor,Beta,"Beta(1,1)",FHCQLearner_acceptreject,FHCQBR,None,NUTS,modelfits/acceptreject/FHCQBR_2022_04_22_22_09_23.nc,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Habit-Value Arbiter Q-Learning,F-LT-HV-QL,acceptreject,theta_h,policy,Habit scaling factor,Beta,"Beta(1,1)",FHCQLearner_acceptreject,FHCQBR,None,NUTS,modelfits/acceptreject/FHCQBR_2022_04_22_22_09_23.nc,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Habit-Value Arbiter Q-Learning,F-LT-HV-QL,acceptreject,weight,policy,Q-value weight,Normal,"Normal(0,1)",FHCQLearner_acceptreject,FHCQBR,None,NUTS,modelfits/acceptreject/FHCQBR_2022_04_22_22_09_23.nc,+,+,+,+,-
Value-Based RL,Forgetting Long-Term Habit-Value Arbiter Q-Learning,F-LT-HV-QL,acceptreject,intercept,policy,Q-value intercept,Normal,"Normal(0,1)",FHCQLearner_acceptreject,FHCQBR,None,NUTS,modelfits/acceptreject/FHCQBR_2022_04_22_22_09_23.nc,+,+,+,+,-
Value-Based RL,Double Q Learning,NA,e-greedy,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",DQLearner_egreedy,DQE,None,CG+NUTS,None,,,,,
Value-Based RL,Double Q Learning,NA,e-greedy,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",DQLearner_egreedy,DQE,None,CG+NUTS,None,,,,,
Value-Based RL,Double Q Learning,NA,e-greedy,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",DQLearner_egreedy,DQE,None,CG+NUTS,None,,,,,
Value-Based RL,Double Q Learning,NA,softmax,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",DQLearner_softmax,DQS,None,CG+NUTS,None,,,,,
Value-Based RL,Double Q Learning,NA,softmax,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",DQLearner_softmax,DQS,None,CG+NUTS,None,,,,,
Value-Based RL,Double Q Learning,NA,softmax,beta,policy,Softmax Temperature,HalfNormal,Halfnormal(1),DQLearner_softmax,DQS,None,CG+NUTS,None,,,,,
Value-Based RL,Double Q Learning,NA,e-softmax,alpha,learningrule,Learning Rate,Beta,"Beta(1,1)",DQLearner_esoftmax,DQES,None,CG+NUTS,modelfits/DQES_2022_02_13_15_17_58.nc,,,,,
Value-Based RL,Double Q Learning,NA,e-softmax,gamma,learningrule,Discount Rate,Beta,"Beta(1,1)",DQLearner_esoftmax,DQES,None,CG+NUTS,modelfits/DQES_2022_02_13_15_17_58.nc,,,,,
Value-Based RL,Double Q Learning,NA,e-softmax,beta,policy,Softmax Temperature,HalfNormal,Halfnormal(1),DQLearner_esoftmax,DQES,None,CG+NUTS,modelfits/DQES_2022_02_13_15_17_58.nc,,,,,
Value-Based RL,Double Q Learning,NA,e-softmax,epsilon,policy,Exploration Rate,Beta,"Beta(1,1)",DQLearner_esoftmax,DQES,None,CG+NUTS,modelfits/DQES_2022_02_13_15_17_58.nc,,,,,
Phenomenological,Bayesian Ideal Observer,NA,Beta-Bernoulli,value_weight,learningrule,Weights for Reward Means,Normal,"Normal(0,1)",BayesianIdealObserver,BBBIO,None,NUTS,None,,,,,
Phenomenological,Bayesian Ideal Observer,NA,Beta-Bernoulli,explore_weight,learningrule,Weights for Reward Variances,Normal,"Normal(0,1)",BayesianIdealObserver,BBBIO,None,NUTS,None,,,,,
Phenomenological,Bayesian Ideal Observer,NA,Beta-Bernoulli,bias_weight,learningrule,Bias in preference,Normal,"Normal(0,1)",BayesianIdealObserver,BBBIO,None,NUTS,None,,,,,
Phenomenological,Contingent Average Trend Inertia Exploration (CATIE),NA,K=1,tau,learningrule,P(Trend Mode),Beta,"Beta(1,1)",CATIELearner,CATIE1,fitAgent.K = 1,CMAES,None,,,,,
Phenomenological,Contingent Average Trend Inertia Exploration (CATIE),NA,K=1,epsilon,learningrule,Pmax(Explore),Beta,"Beta(1,1)",CATIELearner,CATIE1,fitAgent.K = 1,CMAES,None,,,,,
Phenomenological,Contingent Average Trend Inertia Exploration (CATIE),NA,K=1,phi,learningrule,P(Inertial Mode),Beta,"Beta(1,1)",CATIELearner,CATIE1,fitAgent.K = 1,CMAES,None,,,,,
Phenomenological,Contingent Average Trend Inertia Exploration (CATIE),NA,K=5,tau,learningrule,P(Trend Mode),Beta,"Beta(1,1)",CATIELearner,CATIE5,fitAgent.K = 5,CMAES,None,,,,,
Phenomenological,Contingent Average Trend Inertia Exploration (CATIE),NA,K=5,epsilon,learningrule,Pmax(Explore),Beta,"Beta(1,1)",CATIELearner,CATIE5,fitAgent.K = 5,CMAES,None,,,,,
Phenomenological,Contingent Average Trend Inertia Exploration (CATIE),NA,K=5,phi,learningrule,P(Inertial Mode),Beta,"Beta(1,1)",CATIELearner,CATIE5,fitAgent.K = 5,CMAES,None,,,,,
Phenomenological,Contingent Average Trend Inertia Exploration (CATIE),NA,K=10,tau,learningrule,P(Trend Mode),Beta,"Beta(1,1)",CATIELearner,CATIE10,fitAgent.K = 10,CMAES,None,,,,,
Phenomenological,Contingent Average Trend Inertia Exploration (CATIE),NA,K=10,epsilon,learningrule,Pmax(Explore),Beta,"Beta(1,1)",CATIELearner,CATIE10,fitAgent.K = 10,CMAES,None,,,,,
Phenomenological,Contingent Average Trend Inertia Exploration (CATIE),NA,K=10,phi,learningrule,P(Inertial Mode),Beta,"Beta(1,1)",CATIELearner,CATIE10,fitAgent.K = 10,CMAES,None,,,,,
Phenomenological,Exploitative Sampler,NA,K=1,epsilon,learningrule,Asymptotic Exploration Rate,Beta,"Beta(1,1)",ESLearner,ES1,fitAgent.K = 1,CMAES,None,,,,,
Phenomenological,Exploitative Sampler,NA,K=1,delta,learningrule,Sensitivity to Experiment Length,HalfNormal,Halfnormal(1.25),ESLearner,ES1,fitAgent.K = 1,CMAES,None,,,,,
Phenomenological,Exploitative Sampler,NA,K=1,w,learningrule,Weighting of the regressive term,Beta,"Beta(1,1)",ESLearner,ES1,fitAgent.K = 1,CMAES,None,,,,,
Phenomenological,Exploitative Sampler,NA,K=1,rho,learningrule,Diminishing sensitivity factor,HalfNormal,Halfnormal(1.25),ESLearner,ES1,fitAgent.K = 1,CMAES,None,,,,,
Phenomenological,Exploitative Sampler,NA,K=5,epsilon,learningrule,Asymptotic Exploration Rate,Beta,"Beta(1,1)",ESLearner,ES5,fitAgent.K = 5,CMAES,None,,,,,
Phenomenological,Exploitative Sampler,NA,K=5,delta,learningrule,Sensitivity to Experiment Length,HalfNormal,Halfnormal(1.25),ESLearner,ES5,fitAgent.K = 5,CMAES,None,,,,,
Phenomenological,Exploitative Sampler,NA,K=5,w,learningrule,Weighting of the regressive term,Beta,"Beta(1,1)",ESLearner,ES5,fitAgent.K = 5,CMAES,None,,,,,
Phenomenological,Exploitative Sampler,NA,K=5,rho,learningrule,Diminishing sensitivity factor,HalfNormal,Halfnormal(1.25),ESLearner,ES5,fitAgent.K = 5,CMAES,None,,,,,
